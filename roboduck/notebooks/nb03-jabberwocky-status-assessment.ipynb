{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Determine how much work it would take to update jabberwocky to:\n",
    "\n",
    "- [x] support gpt 3.5 models\n",
    "- [x] support gpt 4 models\n",
    "- [x] support chatGPT\n",
    "- use ConversationManager for PDB subclass\n",
    "\n",
    "\"Support\" could mean gpt.query works, prompt_manager.query works, conversation_manager.query works, engine_map.get works, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:20:05.113549Z",
     "start_time": "2023-03-18T05:20:05.097317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:20:08.097102Z",
     "start_time": "2023-03-18T05:20:05.525459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/gooseai_sample_responses.pkl.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from htools import *\n",
    "from jabberwocky.openai_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:20:08.160205Z",
     "start_time": "2023-03-18T05:20:08.100226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmamin/cairina/roboduck\n"
     ]
    }
   ],
   "source": [
    "cd_root()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support gpt 3.5 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- text-davinci-003 is already considered a 3.5 model\n",
    "- context length is about double gpt3's, half gpt4's (ignoring the unreleased super long context)\n",
    "- really just \"gpt-3.5-turbo\", there are no non-davinci level models here (at least for text completion)\n",
    "- gpt-3.5-turbo is 1/10 the cost of the equivalent davinci model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:20:18.633928Z",
     "start_time": "2023-03-18T05:20:18.473426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptManager('debug_full', 'creative_writing_ideas', 'time_complexity', 'word2number', 'eli', 'explain_code', 'tldr', 'translate', 'short_dates', 'test_professional', 'summarize_conversation', 'analyze_writing', 'social_hypotheses', 'conversation_transcript', 'wiki_bio_cleanup', 'debug', 'conversation', 'simplify_ml', 'ml_abstract', 'debug_stack_trace', 'shortest', 'mma', 'punctuate_alexa', 'journal_entry_ideas', 'punctuate_transcription', 'extract_backend_slot', 'leading_scholars', 'extract_code', 'debate', 'punctuate', 'conversation_generalized', 'default', 'how_to', 'debug_duckling', 'emotion_markup_language', 'nytimes_article')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm = PromptManager(verbose=False)\n",
    "pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:20:19.161027Z",
     "start_time": "2023-03-18T05:20:18.832057Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:1903: UserWarning: You've chosen to load >=1 custom personas but you are using me=\"me\". Some custom personas expect you to set `me` to your name. Stop phrases may not work as intended if you do not override conv.me.\n",
      "  'You\\'ve chosen to load >=1 custom personas but you are using '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<jabberwocky.openai_utils.ConversationManager at 0x7fde19c20828>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = ConversationManager()\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:20:19.285022Z",
     "start_time": "2023-03-18T05:20:19.215435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTBackend <current_name: openai>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:20:21.029431Z",
     "start_time": "2023-03-18T05:20:20.993084Z"
    }
   },
   "outputs": [],
   "source": [
    "turbo = 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:20:21.391975Z",
     "start_time": "2023-03-18T05:20:21.152003Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model \"gpt-3.5-turbo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9cd7b6e4aba5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mEngineMap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mturbo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/jabberwocky/lib/jabberwocky/openai_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(cls, model, backend, infer, default, openai_passthrough, basify)\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0mengine_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m             \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai_base_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m             \u001b[0mengine_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jabberwocky/lib/jabberwocky/openai_utils.py\u001b[0m in \u001b[0;36mopenai_base_engine\u001b[0;34m(cls, model)\u001b[0m\n\u001b[1;32m    705\u001b[0m                    if chunk in cls.bases]\n\u001b[1;32m    706\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m             raise ValueError(f'Model \"{model}\" does not contain any of the '\n\u001b[0m\u001b[1;32m    708\u001b[0m                              f'recognized openai bases {cls.bases}.')\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Model \"gpt-3.5-turbo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci']."
     ]
    }
   ],
   "source": [
    "EngineMap.get(turbo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with passthrough=True, we still get an error currently bc turbo doesn't include any of the typical base names (e.g. curie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:20:23.004689Z",
     "start_time": "2023-03-18T05:20:22.953340Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model \"gpt-3.5-turbo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-388fcaa60271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mEngineMap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mturbo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopenai_passthrough\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/jabberwocky/lib/jabberwocky/openai_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(cls, model, backend, infer, default, openai_passthrough, basify)\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0mengine_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m             \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai_base_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m             \u001b[0mengine_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jabberwocky/lib/jabberwocky/openai_utils.py\u001b[0m in \u001b[0;36mopenai_base_engine\u001b[0;34m(cls, model)\u001b[0m\n\u001b[1;32m    705\u001b[0m                    if chunk in cls.bases]\n\u001b[1;32m    706\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m             raise ValueError(f'Model \"{model}\" does not contain any of the '\n\u001b[0m\u001b[1;32m    708\u001b[0m                              f'recognized openai bases {cls.bases}.')\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Model \"gpt-3.5-turbo\" does not contain any of the recognized openai bases ['ada', 'babbage', 'curie', 'davinci']."
     ]
    }
   ],
   "source": [
    "EngineMap.get(turbo, openai_passthrough=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "\n",
    "- 3.5 not currently supported. Updates should be confined to EngineMap class (I think?) so not horrible but not super simple either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No ada/babbage/curie/davinci, just \"gpt-4\", \"gpt-4-32k\".\n",
    "- Context length is 2x gpt3.5, 4x gpt3. 32k version is 8x and 16x, respectively.\n",
    "- Won't be natively supported either (like the 3.5 models), but once I figure out how to support 1, the other change should be basically identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- uses different obj openai.ChatCompletion instead of openai.Completion\n",
    "- instead of `prompt=str`, it takes in `messages=list[dict]`.\n",
    "- messages are pretty similar to what I store in conv manager. System message are top level instructions (e.g. bio), user messages are from human, assistant messages are from gpt. (Roles are \"system\", \"user\", \"assistant\".)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:21:59.565416Z",
     "start_time": "2023-03-18T05:21:59.529182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'persona': 'alan_turing',\n",
       " 'gender': 'M',\n",
       " 'img_path': '/Users/hmamin/jabberwocky/data/conversation_personas/alan_turing/profile.jpg',\n",
       " 'img_url': 'https://upload.wikimedia.org/wikipedia/commons/f/f5/Turing-statue-Bletchley_14.jpg',\n",
       " 'nationality': 'English'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.start_conversation('Alan Turing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:22:00.277238Z",
     "start_time": "2023-03-18T05:22:00.241341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.user_turn_window, cm.gpt3_turn_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:22:01.695919Z",
     "start_time": "2023-03-18T05:22:00.989602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 0, 'temperature': 0.7, 'max_tokens': 100, 'frequency_penalty': 0.5, 'stop': ['\\n\\nMe:', 'This is a conversation with'], 'prompt': 'The following is a transcript of a conversation with Alan Turing. Alan Mathison Turing (23 June 1912 - 7 June 1954) was an English mathematician, computer scientist, logician, cryptanalyst, philosopher, and theoretical biologist. Turing was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer.\\n\\nMe: Explain the distinction between agentic AI and tool AI.\\n\\nAlan Turing:', 'meta': {'backend_name': 'openai', 'query_func': 'query_gpt3', 'datetime': 'Fri Mar 17 22:22:01 2023', 'version': 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A tool AI is an idea which has been brought about by way of science and technology, and is now being used by our own day to enable people to do important and necessary things for society. A agentic AI is something which is brought about by ourselves and our own actions, and is now being used by us and others in the future.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res, full = cm.query('Explain the distinction between agentic AI and tool AI.',\n",
    "         model=0)\n",
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:22:04.757381Z",
     "start_time": "2023-03-18T05:22:04.265770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 0, 'temperature': 0.7, 'max_tokens': 100, 'frequency_penalty': 0.5, 'stop': ['\\n\\nMe:', 'This is a conversation with'], 'prompt': 'The following is a transcript of a conversation with Alan Turing. Alan Mathison Turing (23 June 1912 - 7 June 1954) was an English mathematician, computer scientist, logician, cryptanalyst, philosopher, and theoretical biologist. Turing was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer.\\n\\nMe: Explain the distinction between agentic AI and tool AI.\\n\\nAlan Turing: A tool AI is an idea which has been brought about by way of science and technology, and is now being used by our own day to enable people to do important and necessary things for society. A agentic AI is something which is brought about by ourselves and our own actions, and is now being used by us and others in the future.\\n\\nMe: Could an AI be both agentic and tool?\\n\\nAlan Turing:', 'meta': {'backend_name': 'openai', 'query_func': 'query_gpt3', 'datetime': 'Fri Mar 17 22:22:04 2023', 'version': 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"No, an AI cannot be both agentic and tool. An AI is only toolful when I have set out to do a good work, and am now using my life's labour to make it a good one.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res, full = cm.query('Could an AI be both agentic and tool?', model=0)\n",
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:22:06.028870Z",
     "start_time": "2023-03-18T05:22:05.438632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 0, 'temperature': 0.7, 'max_tokens': 100, 'frequency_penalty': 0.5, 'stop': ['\\n\\nMe:', 'This is a conversation with'], 'prompt': \"The following is a transcript of a conversation with Alan Turing. Alan Mathison Turing (23 June 1912 - 7 June 1954) was an English mathematician, computer scientist, logician, cryptanalyst, philosopher, and theoretical biologist. Turing was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer.\\n\\nMe: Could an AI be both agentic and tool?\\n\\nAlan Turing: No, an AI cannot be both agentic and tool. An AI is only toolful when I have set out to do a good work, and am now using my life's labour to make it a good one.\\n\\nMe: What other types might we define to classify AIs?\\n\\nAlan Turing:\", 'meta': {'backend_name': 'openai', 'query_func': 'query_gpt3', 'datetime': 'Fri Mar 17 22:22:05 2023', 'version': 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't know, but they will be of three types: those who rely on intuition and understanding, those who rely on thought, and those who rely on technology.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res, full = cm.query('What other types might we define to classify AIs?',\n",
    "                     model=0)\n",
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:22:08.838367Z",
     "start_time": "2023-03-18T05:22:08.801834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Explain the distinction between agentic AI and tool AI.',\n",
       " 'Could an AI be both agentic and tool?',\n",
       " 'What other types might we define to classify AIs?']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.user_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:22:09.892730Z",
     "start_time": "2023-03-18T05:22:09.857519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A tool AI is an idea which has been brought about by way of science and technology, and is now being used by our own day to enable people to do important and necessary things for society. A agentic AI is something which is brought about by ourselves and our own actions, and is now being used by us and others in the future.',\n",
       " \"No, an AI cannot be both agentic and tool. An AI is only toolful when I have set out to do a good work, and am now using my life's labour to make it a good one.\",\n",
       " \"I don't know, but they will be of three types: those who rely on intuition and understanding, those who rely on thought, and those who rely on technology.\"]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.gpt3_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:22:13.453757Z",
     "start_time": "2023-03-18T05:22:13.414819Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_messages(self, user_text='', do_full=True):\n",
    "    current_persona = self.current['persona']\n",
    "    if not current_persona:\n",
    "        raise RuntimeError('No persona loaded. Have you started a '\n",
    "                           'conversation?')\n",
    "\n",
    "    pretty_name = self.process_name(current_persona, inverse=True)\n",
    "    messages = [\n",
    "        {'role': 'system', \n",
    "         'content': f'{self.name2base[current_persona]}\\n\\n'}\n",
    "    ]\n",
    "    user_turns = list(self.user_turns)\n",
    "    if user_text:\n",
    "        user_turns.append(user_text)\n",
    "    gpt3_turns = self.gpt3_turns\n",
    "    if not do_full:\n",
    "        user_turns = self.user_turns[-self.user_turn_window:]\n",
    "        gpt3_turns = self.gpt3_turns[-self.gpt3_turn_window:]\n",
    "\n",
    "    if len(user_turns) - len(gpt3_turns) not in (0, 1):\n",
    "        raise RuntimeError(\n",
    "            f'Mismatched turn counts: user has {len(user_turns)} and gpt3'\n",
    "            f' has {len(gpt3_turns)} turns.'\n",
    "        )\n",
    "    user_turns = [{'role': 'user', 'content': f'{self.me}: {turn}'}\n",
    "                  for turn in user_turns]\n",
    "    \n",
    "    # Strip gpt3 turns to be safe since streaming mode only strips them\n",
    "    # once the full query completes, and GUI uses full_conversation\n",
    "    # property while query is still in progress.\n",
    "    gpt3_turns = [\n",
    "        {'role': 'assistant', 'content': f'{pretty_name}: {turn.strip()}'}\n",
    "        for turn in gpt3_turns\n",
    "    ]\n",
    "    ordered = [user_turns, gpt3_turns]\n",
    "    if len(gpt3_turns) == len(user_turns) and not do_full:\n",
    "        ordered = reversed(ordered)\n",
    "    interleaved = [turn for row in zip_longest(user_turns, gpt3_turns) \n",
    "                   for turn in row if turn]\n",
    "    messages.extend(interleaved)\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:24:57.461327Z",
     "start_time": "2023-03-18T05:24:57.392095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'The following is a transcript of a conversation with Alan Turing. Alan Mathison Turing (23 June 1912 - 7 June 1954) was an English mathematician, computer scientist, logician, cryptanalyst, philosopher, and theoretical biologist. Turing was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer.\\n\\n'},\n",
       " {'role': 'user',\n",
       "  'content': 'Me: Explain the distinction between agentic AI and tool AI.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Alan Turing: A tool AI is an idea which has been brought about by way of science and technology, and is now being used by our own day to enable people to do important and necessary things for society. A agentic AI is something which is brought about by ourselves and our own actions, and is now being used by us and others in the future.'},\n",
       " {'role': 'user', 'content': 'Me: Could an AI be both agentic and tool?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Alan Turing: No, an AI cannot be both agentic and tool. An AI is only toolful when I have set out to do a good work, and am now using my life's labour to make it a good one.\"},\n",
       " {'role': 'user',\n",
       "  'content': 'Me: What other types might we define to classify AIs?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Alan Turing: I don't know, but they will be of three types: those who rely on intuition and understanding, those who rely on thought, and those who rely on technology.\"},\n",
       " {'role': 'user',\n",
       "  'content': 'Me: In a similar vein, what 3 categories would you place human thinkers into?'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = get_messages(cm, \n",
    "                        user_text='In a similar vein, what 3 categories would you place human thinkers into?')\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:22:25.422279Z",
     "start_time": "2023-03-18T05:22:18.353566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\r\n",
      "Version: 0.27.2\r\n",
      "Summary: Python client library for the OpenAI API\r\n",
      "Home-page: https://github.com/openai/openai-python\r\n",
      "Author: OpenAI\r\n",
      "Author-email: support@openai.com\r\n",
      "License: \r\n",
      "Location: /Users/hmamin/anaconda3/lib/python3.7/site-packages\r\n",
      "Requires: aiohttp, requests, tqdm, typing-extensions\r\n",
      "Required-by: chronological, jabberwocky\r\n"
     ]
    }
   ],
   "source": [
    "# Was using 0.18.1. Had to upgrade to get chat functionality, now\n",
    "# 0.27.2. Had to restart notebook despite autoreload being enabled ðŸ¤”.\n",
    "!pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:25:44.778441Z",
     "start_time": "2023-03-18T05:25:41.382876Z"
    }
   },
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion().create(model='gpt-3.5-turbo', messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:25:53.957466Z",
     "start_time": "2023-03-18T05:25:53.895494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.openai_object.OpenAIObject"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:25:46.003733Z",
     "start_time": "2023-03-18T05:25:45.956681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-6vJMT6o6mNSHmduWpaC6oeSiPx6UG at 0x7fde19f1aaf0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"Alan Turing: I would say that human thinkers can be categorized into three groups: those who rely on intuition and creativity, those who rely on logical thinking and analysis, and those who rely on experimental and empirical methods. Of course, many individuals embody a combination of these categories, and it is the unique balance of these skills that make each person's thinking and problem-solving abilities distinct.\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1679117141,\n",
       "  \"id\": \"chatcmpl-6vJMT6o6mNSHmduWpaC6oeSiPx6UG\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 77,\n",
       "    \"prompt_tokens\": 346,\n",
       "    \"total_tokens\": 423\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T05:26:18.293449Z",
     "start_time": "2023-03-18T05:26:18.250044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Alan Turing: I would say that human thinkers can be categorized into three groups: those who rely on intuition and creativity, those who rely on logical thinking and analysis, and those who rely on experimental and empirical methods. Of course, many individuals embody a combination of these categories, and it is the unique balance of these skills that make each person's thinking and problem-solving abilities distinct.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "\n",
    "- Not too hard to construct inputs needed for chatmodel.\n",
    "- Code might get a little ugly delegating to chatgpt or not depending on model name though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
