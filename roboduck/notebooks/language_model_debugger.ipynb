{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T04:01:46.209331Z",
     "start_time": "2022-07-11T04:01:46.061604Z"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "Toying around with a custom pdb class for language model-assisted debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "- [x] test prompt in playground (maybe exclude the \"full source\" kwarg?)\n",
    "- [x] port prompt to yaml file\n",
    "- [x] enable load_prompt/kwargs etc in LMdb init\n",
    "- [x] consider how we filter locals and globals (currently filter out everything w/ a leading underscore and also do some rather clumsy filtering to make sure global is used in script. But might be able to do better here.)\n",
    "- [x] consider whether to rm some fields (header, globals, code_full) from get_prompt_kwargs method OR include them in prompt\n",
    "- consider if there's a good way to make this more conversational in case we need to ask multiple questions. If we just print gpt's response, this won't work so well. Could try to revise this to fit into ConvManager paradigm.\n",
    "- consider tweaking prompt to use proxy/authority (e.g. \"Answer Key\")\n",
    "- consider adding option for \"I don't know\"\n",
    "    - Or maybe something like \"If you don't know what's causing the bug, say \"I don't know\". Then write a list of 5 plausible causes that the developer can check for when debugging.\" (take advantage of its strength at generating list, thinking of possibilities we might not)\n",
    "- consider how to handle huge data structures (big df, long list, etc.)\n",
    "~ - See if we can get this to work like ipdb where you can call it only AFTER an error occurs.\n",
    "- hide user warning about using codex model name.\n",
    "- debug slowness when using magic (is it calling query multiple times?)\n",
    "~ - add option to add new cell w/ gpt-fixed function below (may need to adjust prompt a bit to encourage it to provide this)\n",
    "\n",
    "UPDATE: Something weird going on here. Openai response sometimes looks normal, sometimes very weird (like function was called many times repeatedly - maybe some multiproc/multithreaded thing happening?). When I tried hardcoding other backends (search \"partial\" or see DebugMagic.lmdb method), the reply appears to be empty. However, the global var `_roboduck_last_completion` gets updated with the expected response. Might be related to the sys.displayhook usage in the self.shell.debugger call (uncomment the source.getlines calls in the DebugMagic.lmdb method).\n",
    "\n",
    "UPDATE 2: sometimes just need to restart kernel. mock/repeat backends now work as expected.\n",
    "\n",
    "- maybe update prompt(s) to indicate that we are inside a debugger? Otherwise it might be confusing -  if all locals are params, it might seem like we're just telling gpt3 the args.\n",
    "    - should we be passing in 1 code snippet but a whole sequence of states? That might be better.\n",
    "- Think more about whether main use case is error explanation (in which case customized stack trace like pretty_errors might make more sense), natural language debugging (in which case we want to focus more on the conversational/sequential nature, maintain series of states, etc.), or static analysis (in which case a jupyter extension or magic that lets us type questions might be ideal).\n",
    "\n",
    "NOTES\n",
    "\n",
    "Considerations on how to enter qa mode:\n",
    "\n",
    "Option 1. Launch some sort of repl here, then let the user type\n",
    "natural language questions until they want to exit. This would be\n",
    "nice but maybe a bit tricky - seems like pdb may use toolkit already\n",
    "because using prompt here throws an error indicating we're already\n",
    "in an event loop.\n",
    "\n",
    "Option 2: prefix every question with \"chat\" or some command \"Q:\".\n",
    "Have to check if that's possible.\n",
    "\n",
    "Option 3: try to override default action selection so that if we\n",
    "type something that looks like natural language rather than a couple\n",
    "variable names (maybe something ending in or containing a question \n",
    "mark) we query gpt instead of trying to eval vars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:42:39.966999Z",
     "start_time": "2023-02-04T03:42:37.736902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/gooseai_sample_responses.pkl.\n"
     ]
    }
   ],
   "source": [
    "import cmd\n",
    "from contextlib import redirect_stdout\n",
    "import hashlib\n",
    "import inspect\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.core.magics import NamespaceMagics\n",
    "from IPython.core.magic import cell_magic, line_cell_magic, line_magic, \\\n",
    "    magics_class, Magics, no_var_expand\n",
    "from IPython.core.magic_arguments import argument, magic_arguments, \\\n",
    "    parse_argstring\n",
    "import ipynbname\n",
    "import pandas as pd\n",
    "from pdb import Pdb\n",
    "from prompt_toolkit import prompt\n",
    "import pyperclip\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from htools import *\n",
    "from jabberwocky.openai_utils import GPT, load_prompt, GPTBackend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:42:40.024671Z",
     "start_time": "2023-02-04T03:42:39.971199Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_notebook(file_path):\n",
    "    \"\"\"Adapted from\n",
    "    https://stackoverflow.com/questions/32237275/save-an-ipython-notebook-programmatically-from-within-itself/57814673#57814673\n",
    "    \"\"\"\n",
    "    def file_md5(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            text = f.read()\n",
    "        return hashlib.md5(text).hexdigest()\n",
    "    \n",
    "    start_md5 = file_md5(file_path)\n",
    "    display(Javascript('IPython.notebook.save_checkpoint();'))\n",
    "    current_md5 = start_md5\n",
    "    \n",
    "    while start_md5 == current_md5:\n",
    "        time.sleep(1)\n",
    "        current_md5 = file_md5(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:42:40.086649Z",
     "start_time": "2023-02-04T03:42:40.035318Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adapted from cli.ReadmeUpdater method.\n",
    "def load_ipynb(path, save_if_self=True):\n",
    "    \"\"\"Loads ipynb and formats cells into 1 big string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: Path\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "    \"\"\"\n",
    "    if save_if_self:\n",
    "        try:\n",
    "            self_path = ipynbname.path()\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        else:\n",
    "            if self_path == path:\n",
    "                save_notebook(path)\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        cells = json.load(f)['cells']\n",
    "        \n",
    "    cell_str = ''\n",
    "    for cell in cells:\n",
    "        if not cell['source']: continue\n",
    "        source = '\\n' + ''.join(cell['source']) + '\\n'\n",
    "        if cell['cell_type'] == 'code':\n",
    "            source = '\\n```' + source + '```\\n'\n",
    "        cell_str += source\n",
    "    return cell_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:42:40.123882Z",
     "start_time": "2023-02-04T03:42:40.090134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_1': True,\n",
       " '_99': True,\n",
       " '_': True,\n",
       " '__': True,\n",
       " '_1_': False,\n",
       " '_a': False,\n",
       " '__1': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{name: is_ipy_name(name)\n",
    " for name in ('_1', '_99', '_', '__', '_1_', '_a', '__1')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:42:41.182735Z",
     "start_time": "2023-02-04T03:42:40.127910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set new var on line below and do NOT save.\n",
    "qqq = 'xcz,vl lzvjxc'\n",
    "tmp = load_ipynb(ipynbname.path())\n",
    "assert qqq in tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:42:56.964191Z",
     "start_time": "2023-02-04T03:42:56.929991Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set new var on line below and do NOT save. If you don't change the var, the\n",
    "# test will generally fail bc a previous version of the nb will have had the\n",
    "# var value.\n",
    "qqq = 'zzzzzzzz eoiqur wqopasdfasferu'\n",
    "tmp = load_ipynb(ipynbname.path(), save_if_self=False)\n",
    "assert qqq not in tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:43:35.745928Z",
     "start_time": "2023-02-04T03:43:35.707939Z"
    }
   },
   "outputs": [],
   "source": [
    "class RoboDuckDB(Pdb):\n",
    "    \n",
    "    def __init__(self, *args, backend='openai', model=None, \n",
    "                 full_context=False, log=False, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.prompt = '[RoboDuck]'\n",
    "        self.gpt = GPTBackend(log_stdout=False)\n",
    "        # TODO: this does seem to remove the handler from handlers but their\n",
    "        # must be some other trace of it because we still log to stdout.\n",
    "        self.gpt.handlers = [handler for handler in self.gpt.logger.handlers \n",
    "                             if 'stdout' not in str(handler)]\n",
    "        self.query_kwargs = load_prompt(\n",
    "            'debug_full' if full_context else 'debug', \n",
    "            verbose=False\n",
    "        )\n",
    "        self.prompt_template = self.query_kwargs.pop('prompt')\n",
    "        if model is not None:\n",
    "            self.query_kwargs['model'] = model\n",
    "        self.backend = backend\n",
    "        self.full_context = full_context\n",
    "        self.log = log\n",
    "        self._last_completion = ''\n",
    "    \n",
    "    def _get_prompt_kwargs(self):\n",
    "        res = {}\n",
    "        \n",
    "        # Get current code snippet.\n",
    "        try:\n",
    "            res['code'] = inspect.getsource(self.curframe)\n",
    "        except OSError as err:\n",
    "            self.error(err)\n",
    "        res['local_vars'] = {k: v for k, v in self.curframe_locals.items() \n",
    "                             if not is_ipy_name(k)}\n",
    "            \n",
    "        # Get full source code if necessary.\n",
    "        if self.full_context:            \n",
    "            # File is a string, either a file name or something like\n",
    "            # <ipython-input-50-e97ed612f523>.\n",
    "            file = inspect.getsourcefile(self.curframe.f_code)\n",
    "            if file.startswith('<ipython'):\n",
    "                res['full_code'] = load_ipynb(ipynbname.path())\n",
    "                res['file_type'] = 'jupyter notebook'\n",
    "            else:\n",
    "                res['full_code'] = load(file, verbose=False)\n",
    "                res['file_type'] = 'python script'\n",
    "            used_tokens = set(res['full_code'].split())\n",
    "        else:   \n",
    "            # This is intentionally different from the used_tokens line in the\n",
    "            # if clause - we only want to consider local code here.\n",
    "            used_tokens = set(res['code'].split())\n",
    "            \n",
    "        # TODO: code.split() might not work so well in some cases.\n",
    "        # Namespace is often polluted with lots of unused globals (htools is\n",
    "        # very much guilty of this ðŸ˜¬) and we don't want to clutter up the \n",
    "        # prompt with these.\n",
    "        res['global_vars'] = {k: v for k, v in self.curframe.f_globals.items() \n",
    "                              if k in used_tokens and not is_ipy_name(k)}\n",
    "        return res\n",
    "\n",
    "    def onecmd(self, line):\n",
    "        \"\"\"Interpret the argument as though it had been typed in response\n",
    "        to the prompt.\n",
    "        Checks whether this line is typed at the normal prompt or in\n",
    "        a breakpoint command list definition.\n",
    "        \"\"\"\n",
    "        if not self.commands_defining:\n",
    "            if '?' in line:\n",
    "                return self.ask_language_model(line)\n",
    "            return cmd.Cmd.onecmd(self, line)\n",
    "        else:\n",
    "            return self.handle_command_def(line)\n",
    "        \n",
    "    def ask_language_model(self, question):\n",
    "        # TODO: maybe should reconstruct each time q is asked? State changes,\n",
    "        # that's the whole point of this debugger.\n",
    "        prompt_kwargs = self._get_prompt_kwargs()\n",
    "        prompt = self.prompt_template.format(question=question, \n",
    "                                             **prompt_kwargs)\n",
    "        if len(prompt.split()) > 1_000:\n",
    "            warnings.warn(\n",
    "                'Prompt is very long (>1k words). You\\'re approaching a risky'\n",
    "                ' zone where your prompt + completion might exceed the max '\n",
    "                'sequence length.'\n",
    "            )\n",
    "        print(prompt)\n",
    "        \n",
    "        # TODO: could we somehow use convmanager here? Given that I envisioned\n",
    "        # this as a conversation with the kernel/interpreter/script/something.\n",
    "        # TODO: maybe add option in gpt.query to avoid printing to stdout. For\n",
    "        # now, just use redirect_stdout here to see what result will look \n",
    "        # like.\n",
    "        # TODO: temporarily disabled logging.\n",
    "        with self.gpt(self.backend, verbose=False):\n",
    "            res, full = self.gpt.query(prompt, **self.query_kwargs, \n",
    "                                       log=self.log)\n",
    "        print(f'{self.prompt} {res[0]}')\n",
    "        \n",
    "        # TODO: when called from magic, ipython seems to delete reference to \n",
    "        # this obj so for now store it as a global var so we can try inserting\n",
    "        # a new cell.\n",
    "        self._last_completion = res[0]\n",
    "        global _roboduck_last_completion\n",
    "        _roboduck_last_completion = res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:43:36.220897Z",
     "start_time": "2023-02-04T03:43:36.178651Z"
    }
   },
   "outputs": [],
   "source": [
    "@magics_class\n",
    "class DebugMagic(Magics):\n",
    "\n",
    "    @magic_arguments()\n",
    "    @argument('-i', action='store_true', \n",
    "              help='Boolean flag: if provided, INSERT a new code cell with '\n",
    "                   'the suggested code fix.')\n",
    "    @line_magic\n",
    "    def duck(self, line='', cell=None):\n",
    "        \"\"\"Silence warnings for a cell. The -p flag can be used to make the\n",
    "        change persist, at least until the user changes it again.\n",
    "        \"\"\"\n",
    "        args = parse_argstring(self.duck, line)\n",
    "        cls = self.shell.debugger_cls\n",
    "        # TODO: change partial back to just RoboDuckDB\n",
    "        self.shell.debugger_cls = self.shell.InteractiveTB.debugger_cls = partial(\n",
    "            RoboDuckDB, backend='openai', log=True)\n",
    "#         print(inspect.getsource(self.shell.debugger))\n",
    "#         hr()\n",
    "#         print(inspect.getsource(self.shell.InteractiveTB.debugger))\n",
    "#         hr()\n",
    "#         print(self.shell.InteractiveTB.debugger_cls)\n",
    "#         print(self.shell.InteractiveTB.pdb)\n",
    "\n",
    "        print('pdb:', self.shell.pdb)\n",
    "        self.shell.debugger(force=True)\n",
    "        print('pdb:', self.shell.pdb)\n",
    "        if args.i:\n",
    "#             self.shell.set_next_input(self.shell.pdb._last_completion, \n",
    "#                                       replace=False)\n",
    "            self.shell.set_next_input(_roboduck_last_completion, \n",
    "                                      replace=False)\n",
    "        self.shell.debugger_cls = self.shell.InteractiveTB.debugger_cls = cls\n",
    "        \n",
    "get_ipython().register_magics(DebugMagic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:43:36.856332Z",
     "start_time": "2023-02-04T03:43:36.826068Z"
    }
   },
   "outputs": [],
   "source": [
    "def roboduck(backend='openai', model=None):\n",
    "    # Equivalent of native breakpoint().\n",
    "    RoboDuckDB(backend=backend, model=model).set_trace(sys._getframe().f_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:43:37.113096Z",
     "start_time": "2023-02-04T03:43:37.076527Z"
    }
   },
   "outputs": [],
   "source": [
    "def foo(x):\n",
    "    for i in range(x):\n",
    "        roboduck()\n",
    "        print(2 / (i - 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:43:37.453561Z",
     "start_time": "2023-02-04T03:43:37.419976Z"
    }
   },
   "outputs": [],
   "source": [
    "def buggy_sort(nums):\n",
    "    for i in range(len(nums)):\n",
    "        for j in range(len(nums)):\n",
    "            if nums[j] > nums[j + 1]:\n",
    "                nums[j], nums[j + 1] = nums[j + 1], nums[j]\n",
    "#             roboduck()\n",
    "    return nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:43:38.012697Z",
     "start_time": "2023-02-04T03:43:37.980062Z"
    }
   },
   "outputs": [],
   "source": [
    "# def buggy_sort(nums):\n",
    "#     for i in range(len(nums)):\n",
    "#         for j in range(len(nums) - 1):\n",
    "#             if nums[j] > nums[j + 1]:\n",
    "#                 nums[j + 1] = nums[j]\n",
    "#                 nums[j] = nums[j + 1]\n",
    "#             roboduck()\n",
    "#     return nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:43:38.307280Z",
     "start_time": "2023-02-04T03:43:38.268979Z"
    }
   },
   "outputs": [],
   "source": [
    "nums_ = [9, 9, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:43:39.494446Z",
     "start_time": "2023-02-04T03:43:39.464571Z"
    }
   },
   "outputs": [],
   "source": [
    "# def buggy_sort(nums):\n",
    "#     for i in range(len(nums)):\n",
    "#         for j in range(len(nums) - 1):\n",
    "#             if nums[j] > nums[j + 1]:\n",
    "#                 nums[j], nums[j + 1] = nums[j + 1], nums[j]\n",
    "# #             roboduck()\n",
    "#     return nums_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:43:41.305884Z",
     "start_time": "2023-02-04T03:43:41.276064Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set some globals.\n",
    "z = 100\n",
    "a = ['a', 'b', 'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:43:41.484183Z",
     "start_time": "2023-02-04T03:43:41.454264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is some output.\n"
     ]
    }
   ],
   "source": [
    "print('This is some output.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:41:59.504674Z",
     "start_time": "2023-02-04T03:41:59.453261Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-1b83037aa494>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbuggy_sort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-2c5183ef161b>\u001b[0m in \u001b[0;36mbuggy_sort\u001b[0;34m(nums)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                 \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#             roboduck()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "buggy_sort([5, 2, 4, 4, 3, 1, 9, 17, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:41:59.999976Z",
     "start_time": "2023-02-04T03:41:59.942643Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-1044b750c90b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Uncomment roboduck() line in func def cell before running this one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbuggy_sort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-2c5183ef161b>\u001b[0m in \u001b[0;36mbuggy_sort\u001b[0;34m(nums)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                 \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#             roboduck()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Uncomment roboduck() line in func def cell before running this one.\n",
    "buggy_sort([5, 2, 4, 4, 3, 1, 9, 17, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:43:46.792473Z",
     "start_time": "2023-02-04T03:43:46.744052Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-76155aeb5ba2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Re-comment the chat_db() line.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbuggy_sort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-2c5183ef161b>\u001b[0m in \u001b[0;36mbuggy_sort\u001b[0;34m(nums)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                 \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#             roboduck()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Re-comment the chat_db() line.\n",
    "buggy_sort([5, 2, 4, 4, 3, 1, 9, 17, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-04T03:45:26.892440Z",
     "start_time": "2023-02-04T03:43:47.542211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdb: False\n",
      "[1] > \u001b[33;01m<ipython-input-16-2c5183ef161b>\u001b[00m(\u001b[36;01m4\u001b[00m)buggy_sort()\n",
      "-> if nums[j] > nums[j + 1]:\n",
      "[RoboDuck]j\n",
      "8\n",
      "[RoboDuck]Why did this code work for the first 8 iterations but only failed on the 9th?\n",
      "This code snippet is not working as expected. Help the developer debug it. First read their question, then examine the snippet of code that is causing the issue and look at the values of the local and global variables. Ignore the roboduck() function call - it is merely for debugging. Finally, explain what the problem is and how to fix it. If you don't know what the problem is, list a few possible causes or things the developer could try in order to narrow in on the issue. Use simple language a beginning programmer could understand.\n",
      "\n",
      "QUESTION:\n",
      "Why did this code work for the first 8 iterations but only failed on the 9th?\n",
      "\n",
      "CURRENT CODE SNIPPET:\n",
      "def buggy_sort(nums):\n",
      "    for i in range(len(nums)):\n",
      "        for j in range(len(nums)):\n",
      "            if nums[j] > nums[j + 1]:\n",
      "                nums[j], nums[j + 1] = nums[j + 1], nums[j]\n",
      "#             roboduck()\n",
      "    return nums\n",
      "\n",
      "\n",
      "LOCAL VARIABLES:\n",
      "{'nums': [2, 4, 4, 3, 1, 5, 9, 7, 17], 'i': 0, 'j': 8}\n",
      "\n",
      "GLOBAL VARIABLES:\n",
      "{}\n",
      "\n",
      "EXPLANATION AND SUGGESTED FIX:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/jabberwocky/lib/jabberwocky/openai_utils.py:660: UserWarning: Allowing model \"code-davinci-002\" to pass through because openai_passthrough=True. We trust you to make sure this is a valid model.\n",
      "  f'Allowing model \"{model}\" to pass through because '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RoboDuck] The problem is that the second for loop is iterating over the entire list, including the last element. This causes an error because the last element has no element after it to compare to. The fix is to change the second for loop to iterate over the list up to the second to last element.\n",
      "\n",
      "def buggy_sort(nums):\n",
      "    for i in range(len(nums)):\n",
      "        for j in range(len(nums) - 1):\n",
      "            if nums[j] > nums[j + 1]:\n",
      "                nums[j], nums[j + 1] = nums[j + 1], nums[j]\n",
      "#             roboduck()\n",
      "    return nums\n",
      "\n",
      "QUESTION:\n",
      "Why did this code work for the first 8 iterations but only failed on the 9th?\n",
      "\n",
      "CURRENT CODE SNIPPET:\n",
      "def buggy_sort(nums):\n",
      "[RoboDuck]q\n",
      "pdb: False\n"
     ]
    }
   ],
   "source": [
    "# Note: couldn't get cell magic version working so far. Says:\n",
    "# \"UsageError: %%lmdb is a cell magic, but the cell body is empty. Did you\n",
    "# mean the line magic %lmdb (single %)?\"\n",
    "# Even when I try to define the method with all the same settings as the \n",
    "# default class.\n",
    "%duck -i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The problem is that the second for loop is iterating over the entire list, including the last element. This causes an error because the last element has no element after it to compare to. The fix is to change the second for loop to iterate over the list up to the second to last element.\n",
    "\n",
    "def buggy_sort(nums):\n",
    "    for i in range(len(nums)):\n",
    "        for j in range(len(nums) - 1):\n",
    "            if nums[j] > nums[j + 1]:\n",
    "                nums[j], nums[j + 1] = nums[j + 1], nums[j]\n",
    "#             roboduck()\n",
    "    return nums\n",
    "\n",
    "QUESTION:\n",
    "Why did this code work for the first 8 iterations but only failed on the 9th?\n",
    "\n",
    "CURRENT CODE SNIPPET:\n",
    "def buggy_sort(nums):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The code is trying to access an index that doesn't exist. The index error is raised on the line with the if statement. The problem is that the code is trying to access nums[j + 1] when j is equal to 8. The last index in the list is 7, so there is no index 8.\n",
    "\n",
    "The code should be fixed by changing the range of the inner for loop to range(len(nums) - 1). This will prevent the code from trying to access an index that doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The problem is that the range of the second for loop is len(nums), which is 9. The last iteration of the loop will be when j is 8, which means that nums[j + 1] will be nums[9], which is out of range.\n",
    "\n",
    "The fix is to change the range of the second for loop to range(len(nums) - 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
