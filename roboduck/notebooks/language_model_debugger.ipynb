{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T04:01:46.209331Z",
     "start_time": "2022-07-11T04:01:46.061604Z"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "Toying around with a custom pdb class for language model-assisted debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "- [x] test prompt in playground (maybe exclude the \"full source\" kwarg?)\n",
    "- [x] port prompt to yaml file\n",
    "- [x] enable load_prompt/kwargs etc in LMdb init\n",
    "- [x] consider how we filter locals and globals (currently filter out everything w/ a leading underscore and also do some rather clumsy filtering to make sure global is used in script. But might be able to do better here.)\n",
    "- [x] consider whether to rm some fields (header, globals, code_full) from get_prompt_kwargs method OR include them in prompt\n",
    "- consider if there's a good way to make this more conversational in case we need to ask multiple questions. If we just print gpt's response, this won't work so well. Could try to revise this to fit into ConvManager paradigm.\n",
    "- consider tweaking prompt to use proxy/authority (e.g. \"Answer Key\")\n",
    "- consider adding option for \"I don't know\"\n",
    "    - Or maybe something like \"If you don't know what's causing the bug, say \"I don't know\". Then write a list of 5 plausible causes that the developer can check for when debugging.\" (take advantage of its strength at generating list, thinking of possibilities we might not)\n",
    "- consider how to handle huge data structures (big df, long list, etc.)\n",
    "~ - See if we can get this to work like ipdb where you can call it only AFTER an error occurs.\n",
    "- hide user warning about using codex model name.\n",
    "- debug slowness when using magic (is it calling query multiple times?)\n",
    "~ - add option to add new cell w/ gpt-fixed function below (may need to adjust prompt a bit to encourage it to provide this)\n",
    "\n",
    "UPDATE: Something weird going on here. Openai response sometimes looks normal, sometimes very weird (like function was called many times repeatedly - maybe some multiproc/multithreaded thing happening?). When I tried hardcoding other backends (search \"partial\" or see DebugMagic.lmdb method), the reply appears to be empty. However, the global var `_roboduck_last_completion` gets updated with the expected response. Might be related to the sys.displayhook usage in the self.shell.debugger call (uncomment the source.getlines calls in the DebugMagic.lmdb method).\n",
    "\n",
    "UPDATE 2: sometimes just need to restart kernel. mock/repeat backends now work as expected.\n",
    "\n",
    "- maybe update prompt(s) to indicate that we are inside a debugger? Otherwise it might be confusing -  if all locals are params, it might seem like we're just telling gpt3 the args.\n",
    "    - should we be passing in 1 code snippet but a whole sequence of states? That might be better.\n",
    "- Think more about whether main use case is error explanation (in which case customized stack trace like pretty_errors might make more sense), natural language debugging (in which case we want to focus more on the conversational/sequential nature, maintain series of states, etc.), or static analysis (in which case a jupyter extension or magic that lets us type questions might be ideal).\n",
    "\n",
    "NOTES\n",
    "\n",
    "Considerations on how to enter qa mode:\n",
    "\n",
    "Option 1. Launch some sort of repl here, then let the user type\n",
    "natural language questions until they want to exit. This would be\n",
    "nice but maybe a bit tricky - seems like pdb may use toolkit already\n",
    "because using prompt here throws an error indicating we're already\n",
    "in an event loop.\n",
    "\n",
    "Option 2: prefix every question with \"chat\" or some command \"Q:\".\n",
    "Have to check if that's possible.\n",
    "\n",
    "Option 3: try to override default action selection so that if we\n",
    "type something that looks like natural language rather than a couple\n",
    "variable names (maybe something ending in or containing a question \n",
    "mark) we query gpt instead of trying to eval vars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T02:53:48.292233Z",
     "start_time": "2023-02-17T02:53:40.130052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/gooseai_sample_responses.pkl.\n"
     ]
    }
   ],
   "source": [
    "import cmd\n",
    "from collections.abc import Iterable\n",
    "from collections import deque\n",
    "from colorama import Fore, Style\n",
    "from contextlib import redirect_stdout\n",
    "import hashlib\n",
    "import inspect\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.core.magics import NamespaceMagics\n",
    "from IPython.core.magic import cell_magic, line_cell_magic, line_magic, \\\n",
    "    magics_class, Magics, no_var_expand\n",
    "from IPython.core.magic_arguments import argument, magic_arguments, \\\n",
    "    parse_argstring\n",
    "import ipynbname\n",
    "import pandas as pd\n",
    "from pdb import Pdb\n",
    "from prompt_toolkit import prompt\n",
    "import pyperclip\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import warnings\n",
    "\n",
    "from htools import *\n",
    "from jabberwocky.openai_utils import GPT, load_prompt, PromptManager, \\\n",
    "    GPTBackend, EngineMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T02:53:48.526505Z",
     "start_time": "2023-02-17T02:53:48.295762Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_notebook(file_path):\n",
    "    \"\"\"Adapted from\n",
    "    https://stackoverflow.com/questions/32237275/save-an-ipython-notebook-programmatically-from-within-itself/57814673#57814673\n",
    "    \"\"\"\n",
    "    def file_md5(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            text = f.read()\n",
    "        return hashlib.md5(text).hexdigest()\n",
    "    \n",
    "    start_md5 = file_md5(file_path)\n",
    "    display(Javascript('IPython.notebook.save_checkpoint();'))\n",
    "    current_md5 = start_md5\n",
    "    \n",
    "    while start_md5 == current_md5:\n",
    "        time.sleep(1)\n",
    "        current_md5 = file_md5(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T02:53:48.591351Z",
     "start_time": "2023-02-17T02:53:48.530103Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adapted from cli.ReadmeUpdater method.\n",
    "def load_ipynb(path, save_if_self=True):\n",
    "    \"\"\"Loads ipynb and formats cells into 1 big string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: Path\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "    \"\"\"\n",
    "    if save_if_self:\n",
    "        try:\n",
    "            self_path = ipynbname.path()\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        else:\n",
    "            if self_path == path:\n",
    "                save_notebook(path)\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        cells = json.load(f)['cells']\n",
    "        \n",
    "    cell_str = ''\n",
    "    for cell in cells:\n",
    "        if not cell['source']: continue\n",
    "        source = '\\n' + ''.join(cell['source']) + '\\n'\n",
    "        if cell['cell_type'] == 'code':\n",
    "            source = '\\n```' + source + '```\\n'\n",
    "        cell_str += source\n",
    "    return cell_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T02:53:48.656464Z",
     "start_time": "2023-02-17T02:53:48.593846Z"
    }
   },
   "outputs": [],
   "source": [
    "def colored(text, color):\n",
    "    color = getattr(Fore, color.upper())\n",
    "    return f'{color}{text}{Style.RESET_ALL}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T02:53:48.724174Z",
     "start_time": "2023-02-17T02:53:48.659566Z"
    }
   },
   "outputs": [],
   "source": [
    "def truncated_repr(obj, max_len=79):\n",
    "    \"\"\"Return an object's repr, truncated to ensure that it doesn't take up\n",
    "    more characters than we want. This is used to reduce our chances of using\n",
    "    up all our available tokens in a gpt prompt simply communicating that a\n",
    "    giant data structure exists, e.g. list(range(1_000_000)). Our use\n",
    "    case doesn't call for anything super precise so the max_len should be \n",
    "    thought of as more of guide than an exact max. I think it's enforced but I\n",
    "    didn't put a whole lot of thought or effort into confirming that.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    obj: any\n",
    "    max_len: int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str: Repr for obj, truncated to approximately max_len characters or fewer.\n",
    "    When possible, we insert ellipses into the repr to show that truncation\n",
    "    occurred. Technically there are some edge cases we don't handle (e.g. if\n",
    "    obj is a class with an insanely long name) but that's not a big deal, at\n",
    "    least at the moment. I can always revisit that later if necessary.\n",
    "    \"\"\"\n",
    "    def qualname(obj):\n",
    "        \"\"\"Similar to type(obj).__qualname__() but that method doesn't always\n",
    "        include the module(s). e.g. pandas Index has __qualname__ \"Index\" but\n",
    "        this funnction returns \"<pandas.core.indexes.base.Index>\".\n",
    "        \"\"\"\n",
    "        text = str(type(obj))\n",
    "        names = re.search(\"<class '([a-zA-Z_.]*)'>\", text).groups()\n",
    "        assert len(names) == 1, f'Should have found only 1 qualname but '\\\n",
    "            f'found: {names}'\n",
    "        return f'<{names[0]}>'\n",
    "      \n",
    "    open2close = {\n",
    "        '[': ']',\n",
    "        '(': ')',\n",
    "        '{': '}'\n",
    "    }\n",
    "    repr_ = repr(obj)\n",
    "    if len(repr_) < max_len:\n",
    "        return repr_\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        cols = truncated_repr(obj.columns.tolist(), max_len - 26)\n",
    "        return f'pd.DataFrame(columns=' \\\n",
    "            f'{truncated_repr(cols, max_len - 22)})'\n",
    "    if isinstance(obj, pd.Series):\n",
    "        return f'pd.Series({truncated_repr(obj.tolist(), max_len - 11)})'\n",
    "    if isinstance(obj, dict):\n",
    "        length = 5\n",
    "        res = ''\n",
    "        for k, v in obj.items():\n",
    "            if length >= max_len - 2:\n",
    "                break\n",
    "            new_str = f'{k!r}: {v!r}, '\n",
    "            length += len(new_str)\n",
    "            res += new_str\n",
    "        return \"{\" + res.rstrip() + \"...}\"\n",
    "    if isinstance(obj, str):\n",
    "        return repr_[:max_len - 4] + \"...'\"\n",
    "    if isinstance(obj, Iterable):\n",
    "        # A bit risky but sort of elegant. Just recursively take smaller\n",
    "        # slices until we get an acceptable length. We may end up going\n",
    "        # slightly over the max length after adding our ellipses but it's\n",
    "        # not that big a deal, this isn't meant to be super precise. We\n",
    "        # can also end up with fewer items than we could have fit - if we\n",
    "        # exhaustively check every possible length one by one until we \n",
    "        # find the max length that fits, we can get a very slow function\n",
    "        # when inputs are long.\n",
    "        # Can't easily pass smaller max_len value into recursive call \n",
    "        # because we always want to compare to the user-specified value.\n",
    "        n = int(max_len / len(repr_) * len(obj))\n",
    "        if n == len(obj):\n",
    "            # Even slicing to just first item is too long, so just revert\n",
    "            # to treating this like a non-iterable object.\n",
    "            return qualname(obj)\n",
    "        # Need to slice set while keeping the original dtype.\n",
    "        if isinstance(obj, set):\n",
    "            slice_ = set(list(obj)[:n])\n",
    "        else:\n",
    "            slice_ = obj[:n]\n",
    "        repr_ = truncated_repr(slice_, max_len)\n",
    "        non_brace_idx = len(repr_) - 1 \n",
    "        while repr_[non_brace_idx] in open2close.values():\n",
    "            non_brace_idx -= 1\n",
    "        if non_brace_idx <= 0 or (non_brace_idx == 3\n",
    "                                  and repr_.startswith('set')):\n",
    "            return repr_[:-1] + '...' + repr_[-1]\n",
    "        return repr_[:non_brace_idx+1] + ',...' + repr_[non_brace_idx+1:]\n",
    "    \n",
    "    # We know it's non-iterable at this point.\n",
    "    if isinstance(obj, type):\n",
    "        return f'<class {obj.__name__}>'\n",
    "    if isinstance(obj, (int, float)):\n",
    "        return truncated_repr(format(obj, '.3e'), max_len)\n",
    "    return qualname(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T02:53:48.787014Z",
     "start_time": "2023-02-17T02:53:48.726677Z"
    }
   },
   "outputs": [],
   "source": [
    "def type_annotated_dict_str(dict_, func=repr):\n",
    "    \"\"\"String representation of a dict, where each line includes an inline\n",
    "    comment showing the type of the value.\n",
    "    \"\"\"\n",
    "    type_strs = [f'\\n    {func(k)}: {func(v)},   # type: {type(v).__name__}'\n",
    "                 for k, v in dict_.items()]\n",
    "    return '{' + ''.join(type_strs) + '\\n}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T02:53:48.841287Z",
     "start_time": "2023-02-17T02:53:48.789482Z"
    }
   },
   "outputs": [],
   "source": [
    "class CodeCompletionCache:\n",
    "    \n",
    "    last_completion = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T02:56:10.965251Z",
     "start_time": "2023-02-18T02:56:10.898445Z"
    }
   },
   "outputs": [],
   "source": [
    "ROBODUCK_GPT = GPTBackend(log_stdout=False)\n",
    "PROMPT_MANAGER = PromptManager(['debug', 'debug_full'],\n",
    "                               verbose=False, \n",
    "                               gpt=ROBODUCK_GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T03:08:59.214665Z",
     "start_time": "2023-02-18T03:08:59.075051Z"
    }
   },
   "outputs": [],
   "source": [
    "# class RoboDuckDB(Pdb):\n",
    "    \n",
    "#     def __init__(self, *args, backend='openai', model=None, \n",
    "#                  full_context=False, log=False, max_len_per_var=79,\n",
    "#                  **kwargs):\n",
    "#         \"\"\"\n",
    "#         max_len_per_var: int\n",
    "#             Limits number of characters per variable when communicating \n",
    "#             current state (local or global depending on `full_context`) to \n",
    "#             gpt. If unbounded, that section of the prompt alone could grow\n",
    "#             very big . I somewhat arbitrarily set 79 as the default, i.e. \n",
    "#             1 line of python per variable. I figure that's usually enough to\n",
    "#             communicate the gist of what's happening.\n",
    "#         \"\"\"\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#         self.prompt = '>>> '\n",
    "#         self.duck_prompt = '[RoboDuck] '\n",
    "#         self.gpt = GPTBackend(log_stdout=False)\n",
    "#         # TODO: this does seem to remove the handler from handlers but their\n",
    "#         # must be some other trace of it because we still log to stdout.\n",
    "#         self.gpt.handlers = [handler for handler in self.gpt.logger.handlers \n",
    "#                              if 'stdout' not in str(handler)]\n",
    "#         self.query_kwargs = load_prompt(\n",
    "#             'debug_full' if full_context else 'debug', \n",
    "#             verbose=False\n",
    "#         )\n",
    "#         self.prompt_template = self.query_kwargs.pop('prompt')\n",
    "#         if model is not None:\n",
    "#             self.query_kwargs['model'] = model\n",
    "#         self.backend = backend\n",
    "#         self.full_context = full_context\n",
    "#         self.log = log\n",
    "#         self._last_completion = ''\n",
    "#         self.repr_func = partial(truncated_repr, max_len=max_len_per_var)\n",
    "    \n",
    "#     def _get_prompt_kwargs(self):\n",
    "#         res = {}\n",
    "        \n",
    "#         # Get current code snippet.\n",
    "#         try:\n",
    "#             res['code'] = inspect.getsource(self.curframe)\n",
    "#         except OSError as err:\n",
    "#             self.error(err)\n",
    "#         res['local_vars'] = type_annotated_dict_str(\n",
    "#             {k: v for k, v in self.curframe_locals.items() \n",
    "#              if not is_ipy_name(k)},\n",
    "#             self.repr_func\n",
    "#         )\n",
    "            \n",
    "#         # Get full source code if necessary.\n",
    "#         if self.full_context:            \n",
    "#             # File is a string, either a file name or something like\n",
    "#             # <ipython-input-50-e97ed612f523>.\n",
    "#             file = inspect.getsourcefile(self.curframe.f_code)\n",
    "#             if file.startswith('<ipython'):\n",
    "#                 res['full_code'] = load_ipynb(ipynbname.path())\n",
    "#                 res['file_type'] = 'jupyter notebook'\n",
    "#             else:\n",
    "#                 res['full_code'] = load(file, verbose=False)\n",
    "#                 res['file_type'] = 'python script'\n",
    "#             used_tokens = set(res['full_code'].split())\n",
    "#         else:   \n",
    "#             # This is intentionally different from the used_tokens line in the\n",
    "#             # if clause - we only want to consider local code here.\n",
    "#             used_tokens = set(res['code'].split())\n",
    "            \n",
    "#         # TODO: code.split() might not work so well in some cases.\n",
    "#         # Namespace is often polluted with lots of unused globals (htools is\n",
    "#         # very much guilty of this ðŸ˜¬) and we don't want to clutter up the \n",
    "#         # prompt with these.\n",
    "#         res['global_vars'] = type_annotated_dict_str(\n",
    "#             {k: v for k, v in self.curframe.f_globals.items() \n",
    "#              if k in used_tokens and not is_ipy_name(k)},\n",
    "#             self.repr_func\n",
    "#         )\n",
    "#         return res\n",
    "\n",
    "#     def onecmd(self, line):\n",
    "#         \"\"\"Interpret the argument as though it had been typed in response\n",
    "#         to the prompt.\n",
    "#         Checks whether this line is typed at the normal prompt or in\n",
    "#         a breakpoint command list definition.\n",
    "#         \"\"\"\n",
    "#         if not self.commands_defining:\n",
    "#             if '?' in line:\n",
    "#                 return self.ask_language_model(line)\n",
    "#             return cmd.Cmd.onecmd(self, line)\n",
    "#         else:\n",
    "#             return self.handle_command_def(line)\n",
    "        \n",
    "#     def ask_language_model(self, question):\n",
    "#         # TODO: maybe should reconstruct each time q is asked? State changes,\n",
    "#         # that's the whole point of this debugger.\n",
    "#         prompt_kwargs = self._get_prompt_kwargs()\n",
    "#         prompt = self.prompt_template.format(question=question, \n",
    "#                                              **prompt_kwargs)\n",
    "#         if len(prompt.split()) > 1_000:\n",
    "#             warnings.warn(\n",
    "#                 'Prompt is very long (>1k words). You\\'re approaching a risky'\n",
    "#                 ' zone where your prompt + completion might exceed the max '\n",
    "#                 'sequence length.'\n",
    "#             )\n",
    "#         # TODO rm\n",
    "#         print(colored(prompt, 'red'))\n",
    "        \n",
    "#         # TODO: could we somehow use convmanager here? Given that I envisioned\n",
    "#         # this as a conversation with the kernel/interpreter/script/something.\n",
    "#         # TODO: maybe add option in gpt.query to avoid printing to stdout. For\n",
    "#         # now, just use redirect_stdout here to see what result will look \n",
    "#         # like.\n",
    "#         # TODO: temporarily disabled logging.\n",
    "#         print(colored(self.duck_prompt, 'green'), end='')\n",
    "#         res = ''\n",
    "#         # Suppress jabberwocky auto-warning about codex model name.\n",
    "#         with warnings.catch_warnings():\n",
    "#             warnings.filterwarnings('ignore')\n",
    "#             with self.gpt(self.backend, verbose=False):\n",
    "#                 for i, (cur, full) in enumerate(self.gpt.query(\n",
    "#                     prompt, \n",
    "#                     **self.query_kwargs, \n",
    "#                     log=self.log,\n",
    "#                     stream=True\n",
    "#                 )):\n",
    "#                     if not i and cur.startswith('\\n'):\n",
    "#                         continue\n",
    "#                     res += cur\n",
    "#                     for char in cur:\n",
    "#                         print(colored(char, 'green'), end='')\n",
    "#                         time.sleep(.02)\n",
    "#         # Strip trailing quotes because the entire prompt is inside a \n",
    "#         # docstring and codex may try to close it. We can't use it as a stop\n",
    "#         # phrase in case codex generates a fixed code snippet that includes\n",
    "#         # a docstring.\n",
    "#         answer = res.strip()\n",
    "#         if not answer:\n",
    "#             answer = 'Sorry, I don\\'t know. Can you try '\\\n",
    "#                 'rephrasing your question?'\n",
    "#             print(colored(answer, 'green'))\n",
    "# #         print(colored(f'{self.duck_prompt} {answer}', 'green'))\n",
    "        \n",
    "#         # TODO: when called from magic, ipython seems to delete reference to \n",
    "#         # this obj so for now store it as a global var so we can try inserting\n",
    "#         # a new cell.\n",
    "#         self._last_completion = answer\n",
    "#         global _roboduck_last_completion\n",
    "#         _roboduck_last_completion = answer\n",
    "\n",
    "class RoboDuckDB(Pdb):\n",
    "    \n",
    "    def __init__(self, *args, backend='openai', model=None, \n",
    "                 full_context=False, log=False, max_len_per_var=79,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Once you're in a debugging session, any conversational turn containing\n",
    "        a question mark will be interepreted as a question for gpt. Prefixing\n",
    "        your question with \"[dev]\" will print out the full prompt before\n",
    "        making the query.\n",
    "        \n",
    "        max_len_per_var: int\n",
    "            Limits number of characters per variable when communicating \n",
    "            current state (local or global depending on `full_context`) to \n",
    "            gpt. If unbounded, that section of the prompt alone could grow\n",
    "            very big . I somewhat arbitrarily set 79 as the default, i.e. \n",
    "            1 line of python per variable. I figure that's usually enough to\n",
    "            communicate the gist of what's happening.\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.prompt = '>>> '\n",
    "        self.duck_prompt = '[RoboDuck] '\n",
    "        # Check if None explicitly because model=0 is different.\n",
    "        self.query_kwargs = {'model': model} if model is not None else {}\n",
    "        self.backend = backend\n",
    "        self.full_context = full_context\n",
    "        self.task = 'debug' + '_full'*full_context\n",
    "        self.log = log\n",
    "        self.repr_func = partial(truncated_repr, max_len=max_len_per_var)\n",
    "    \n",
    "    def _get_prompt_kwargs(self):\n",
    "        res = {}\n",
    "        \n",
    "        # Get current code snippet.\n",
    "        try:\n",
    "            res['code'] = inspect.getsource(self.curframe)\n",
    "        except OSError as err:\n",
    "            self.error(err)\n",
    "        res['local_vars'] = type_annotated_dict_str(\n",
    "            {k: v for k, v in self.curframe_locals.items() \n",
    "             if not is_ipy_name(k)},\n",
    "            self.repr_func\n",
    "        )\n",
    "            \n",
    "        # Get full source code if necessary.\n",
    "        if self.full_context:            \n",
    "            # File is a string, either a file name or something like\n",
    "            # <ipython-input-50-e97ed612f523>.\n",
    "            file = inspect.getsourcefile(self.curframe.f_code)\n",
    "            if file.startswith('<ipython'):\n",
    "                res['full_code'] = load_ipynb(ipynbname.path())\n",
    "                res['file_type'] = 'jupyter notebook'\n",
    "            else:\n",
    "                res['full_code'] = load(file, verbose=False)\n",
    "                res['file_type'] = 'python script'\n",
    "            used_tokens = set(res['full_code'].split())\n",
    "        else:   \n",
    "            # This is intentionally different from the used_tokens line in the\n",
    "            # if clause - we only want to consider local code here.\n",
    "            used_tokens = set(res['code'].split())\n",
    "            \n",
    "        # Namespace is often polluted with lots of unused globals (htools is\n",
    "        # very much guilty of this ðŸ˜¬) and we don't want to clutter up the \n",
    "        # prompt with these.\n",
    "        res['global_vars'] = type_annotated_dict_str(\n",
    "            {k: v for k, v in self.curframe.f_globals.items() \n",
    "             if k in used_tokens and not is_ipy_name(k)},\n",
    "            self.repr_func\n",
    "        )\n",
    "        return res\n",
    "\n",
    "    def onecmd(self, line):\n",
    "        \"\"\"Interpret the argument as though it had been typed in response\n",
    "        to the prompt.\n",
    "        Checks whether this line is typed at the normal prompt or in\n",
    "        a breakpoint command list definition.\n",
    "        \"\"\"\n",
    "        if not self.commands_defining:\n",
    "            if '?' in line:\n",
    "                return self.ask_language_model(\n",
    "                    line, verbose=line.startswith('[dev]')\n",
    "                )\n",
    "            return cmd.Cmd.onecmd(self, line)\n",
    "        else:\n",
    "            return self.handle_command_def(line)\n",
    "        \n",
    "    def ask_language_model(self, question, verbose=False):\n",
    "        prompt_kwargs = self._get_prompt_kwargs()\n",
    "        prompt_kwargs['question'] = question\n",
    "        prompt = PROMPT_MANAGER.prompt(self.task, prompt_kwargs)\n",
    "        if len(prompt.split()) > 1_000:\n",
    "            warnings.warn(\n",
    "                'Prompt is very long (>1k words). You\\'re approaching a risky'\n",
    "                ' zone where your prompt + completion might exceed the max '\n",
    "                'sequence length.'\n",
    "            )\n",
    "        if verbose:\n",
    "            print(colored(prompt, 'red'))\n",
    "        \n",
    "        print(colored(self.duck_prompt, 'green'), end='')\n",
    "        res = ''\n",
    "        # Suppress jabberwocky auto-warning about codex model name.\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore')\n",
    "            with ROBODUCK_GPT(self.backend, verbose=False):\n",
    "                prev_is_title = False\n",
    "                for i, (cur, full) in enumerate(PROMPT_MANAGER.query(\n",
    "                    self.task,\n",
    "                    prompt_kwargs,\n",
    "                    **self.query_kwargs, \n",
    "                    log=self.log,\n",
    "                    stream=True\n",
    "                )):\n",
    "                    # We do this BEFORE the checks around SOLUTION PART 2\n",
    "                    # because we don't want to print that line, but we do want\n",
    "                    # to retain it in our CodeCompletionCache so that our\n",
    "                    # jupyter magic can easily extract the code portion later.\n",
    "                    res += cur\n",
    "                    \n",
    "                    # Slightly fragile logic - openai currently returns this\n",
    "                    # in a single streaming step even though the current codex\n",
    "                    # tokenizer splits it into 5 tokens. If they return this\n",
    "                    # as multiple tokens, we'd need to change this logic.\n",
    "                    if cur == 'SOLUTION PART 2':\n",
    "                        prev_is_title = True\n",
    "                        continue\n",
    "                    # Avoid printing the ':' after 'SOLUTION PART 2'. Openai\n",
    "                    # returns this at a different streaming step.\n",
    "                    if prev_is_title and cur.startswith(':'):\n",
    "                        continue\n",
    "                    prev_is_title = False\n",
    "                    if not i:\n",
    "                        cur = cur.lstrip('\\n')\n",
    "                    for char in cur:\n",
    "                        print(colored(char, 'green'), end='')\n",
    "                        time.sleep(.02)\n",
    "        \n",
    "        # Strip trailing quotes because the entire prompt is inside a \n",
    "        # docstring and codex may try to close it. We can't use it as a stop\n",
    "        # phrase in case codex generates a fixed code snippet that includes\n",
    "        # a docstring.\n",
    "        answer = res.strip()\n",
    "        if not answer:\n",
    "            answer = 'Sorry, I don\\'t know. Can you try '\\\n",
    "                'rephrasing your question?'\n",
    "            print(colored(answer, 'green'))\n",
    "        \n",
    "        # When using the `duck` jupyter magic in \"insert\" mode, we reference\n",
    "        # the CodeCompletionCache to populate the new code cell.\n",
    "        CodeCompletionCache.last_completion = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T03:02:22.149118Z",
     "start_time": "2023-02-18T03:02:22.051747Z"
    }
   },
   "outputs": [],
   "source": [
    "@magics_class\n",
    "class DebugMagic(Magics):\n",
    "\n",
    "    @magic_arguments()\n",
    "    @argument('-i', action='store_true', \n",
    "              help='Boolean flag: if provided, INSERT a new code cell with '\n",
    "                   'the suggested code fix.')\n",
    "    @line_magic\n",
    "    def duck(self, line='', cell=None):\n",
    "        \"\"\"Silence warnings for a cell. The -p flag can be used to make the\n",
    "        change persist, at least until the user changes it again.\n",
    "        \"\"\"\n",
    "        args = parse_argstring(self.duck, line)\n",
    "        cls = self.shell.debugger_cls\n",
    "        self.shell.debugger_cls = RoboDuckDB\n",
    "        self.shell.InteractiveTB.debugger_cls = RoboDuckDB\n",
    "        self.shell.debugger(force=True)\n",
    "        # Insert suggested code into next cell.\n",
    "        if args.i and CodeCompletionCache.last_completion:\n",
    "            *_, code_snippet = CodeCompletionCache.last_completion.split(\n",
    "                'SOLUTION PART 2:'\n",
    "            )\n",
    "            self.shell.set_next_input(code_snippet.lstrip('\\n'),\n",
    "                                      replace=False)\n",
    "        CodeCompletionCache.last_completion = ''\n",
    "        self.shell.debugger_cls = self.shell.InteractiveTB.debugger_cls = cls\n",
    "\n",
    "\n",
    "shell = get_ipython()\n",
    "shell.magics_manager.magics.get('line', {}).pop('duck', None)\n",
    "shell.register_magics(DebugMagic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T02:56:14.333985Z",
     "start_time": "2023-02-18T02:56:14.268424Z"
    }
   },
   "outputs": [],
   "source": [
    "def roboduck(backend='openai', model=None):\n",
    "    # Equivalent of native breakpoint().\n",
    "    RoboDuckDB(backend=backend, model=model).set_trace(sys._getframe().f_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T02:56:14.545921Z",
     "start_time": "2023-02-18T02:56:14.473975Z"
    }
   },
   "outputs": [],
   "source": [
    "def foo(x):\n",
    "    for i in range(x):\n",
    "        roboduck()\n",
    "        print(2 / (i - 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T02:56:27.286023Z",
     "start_time": "2023-02-18T02:56:27.210063Z"
    }
   },
   "outputs": [],
   "source": [
    "def bubble_sort(nums):\n",
    "    for i in range(len(nums)):\n",
    "        for j in range(len(nums)):\n",
    "            if nums[j] > nums[j + 1]:\n",
    "                nums[j], nums[j + 1] = nums[j + 1], nums[j]\n",
    "            roboduck()\n",
    "    return nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T02:56:15.090675Z",
     "start_time": "2023-02-18T02:56:15.012309Z"
    }
   },
   "outputs": [],
   "source": [
    "# def bubble_sort(nums):\n",
    "#     for i in range(len(nums)):\n",
    "#         for j in range(len(nums) - 1):\n",
    "#             if nums[j] > nums[j + 1]:\n",
    "#                 nums[j + 1] = nums[j]\n",
    "#                 nums[j] = nums[j + 1]\n",
    "# #             roboduck()\n",
    "#     return nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T02:56:15.311113Z",
     "start_time": "2023-02-18T02:56:15.221409Z"
    }
   },
   "outputs": [],
   "source": [
    "nums_ = [9, 9, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T02:56:15.706607Z",
     "start_time": "2023-02-18T02:56:15.640705Z"
    }
   },
   "outputs": [],
   "source": [
    "# def bubble_sort(nums):\n",
    "#     for i in range(len(nums)):\n",
    "#         for j in range(len(nums) - 1):\n",
    "#             if nums[j] > nums[j + 1]:\n",
    "#                 nums[j], nums[j + 1] = nums[j + 1], nums[j]\n",
    "# #             roboduck()\n",
    "#     return nums_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T02:56:16.136853Z",
     "start_time": "2023-02-18T02:56:16.024574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set some globals.\n",
    "z = 100\n",
    "a = ['a', 'b', 'c']\n",
    "nums = DotDict({i: i*2 for i in range(100)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T02:56:16.602788Z",
     "start_time": "2023-02-18T02:56:16.516337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is some output.\n"
     ]
    }
   ],
   "source": [
    "print('This is some output.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-18T02:57:30.330188Z",
     "start_time": "2023-02-18T02:56:29.960491Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m3\u001b[00m)bubble_sort()\n",
      "-> for j in range(len(nums)):\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> i,j\n",
      "(0, 0)\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m4\u001b[00m)bubble_sort()\n",
      "-> if nums[j] > nums[j + 1]:\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m5\u001b[00m)bubble_sort()\n",
      "-> nums[j], nums[j + 1] = nums[j + 1], nums[j]\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m6\u001b[00m)bubble_sort()\n",
      "-> roboduck()\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m3\u001b[00m)bubble_sort()\n",
      "-> for j in range(len(nums)):\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m4\u001b[00m)bubble_sort()\n",
      "-> if nums[j] > nums[j + 1]:\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m5\u001b[00m)bubble_sort()\n",
      "-> nums[j], nums[j + 1] = nums[j + 1], nums[j]\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m6\u001b[00m)bubble_sort()\n",
      "-> roboduck()\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m3\u001b[00m)bubble_sort()\n",
      "-> for j in range(len(nums)):\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m4\u001b[00m)bubble_sort()\n",
      "-> if nums[j] > nums[j + 1]:\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m5\u001b[00m)bubble_sort()\n",
      "-> nums[j], nums[j + 1] = nums[j + 1], nums[j]\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m6\u001b[00m)bubble_sort()\n",
      "-> roboduck()\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m3\u001b[00m)bubble_sort()\n",
      "-> for j in range(len(nums)):\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m4\u001b[00m)bubble_sort()\n",
      "-> if nums[j] > nums[j + 1]:\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m5\u001b[00m)bubble_sort()\n",
      "-> nums[j], nums[j + 1] = nums[j + 1], nums[j]\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m6\u001b[00m)bubble_sort()\n",
      "-> roboduck()\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m3\u001b[00m)bubble_sort()\n",
      "-> for j in range(len(nums)):\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m4\u001b[00m)bubble_sort()\n",
      "-> if nums[j] > nums[j + 1]:\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> nums\n",
      "[2, 4, 4, 3, 1, 5, 9, 17, 7]\n",
      ">>> i,j\n",
      "(0, 5)\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m6\u001b[00m)bubble_sort()\n",
      "-> roboduck()\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m3\u001b[00m)bubble_sort()\n",
      "-> for j in range(len(nums)):\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m4\u001b[00m)bubble_sort()\n",
      "-> if nums[j] > nums[j + 1]:\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> n\n",
      "[27] > \u001b[33;01m<ipython-input-46-95174b1d61b8>\u001b[00m(\u001b[36;01m6\u001b[00m)bubble_sort()\n",
      "-> roboduck()\n",
      "   1 frame hidden (try 'help hidden_frames')\n",
      ">>> i,j\n",
      "(0, 6)\n",
      ">>> nums\n",
      "[2, 4, 4, 3, 1, 5, 9, 17, 7]\n",
      ">>> What prevents us from reaching i=1?\n",
      "\u001b[31m\"\"\"ANSWER KEY\n",
      "\n",
      "This code snippet is not working as expected. Help me debug it. First read my question, then examine the snippet of code that is causing the issue and look at the values of the local and global variables. If you see a function called roboduck, ignore it. In the section titled SOLUTION PART 1, use plain English to explain what the problem is and how to fix it. In the section titled SOLUTION PART 2, write a corrected version of the input code snippet. If you don't know what the problem is, SOLUTION PART 1 should list a few possible causes or things I could try in order to identify the issue and SOLUTION PART 2 should say N/A. Be concise and use simple language because I am a beginning programmer.\n",
      "\n",
      "QUESTION:\n",
      "What prevents us from reaching i=1?\n",
      "\n",
      "CURRENT CODE SNIPPET:\n",
      "def bubble_sort(nums):\n",
      "    for i in range(len(nums)):\n",
      "        for j in range(len(nums)):\n",
      "            if nums[j] > nums[j + 1]:\n",
      "                nums[j], nums[j + 1] = nums[j + 1], nums[j]\n",
      "            roboduck()\n",
      "    return nums\n",
      "\n",
      "\n",
      "LOCAL VARIABLES:\n",
      "{\n",
      "    'nums': [2, 4, 4, 3, 1, 5, 9, 17, 7],   # type: list\n",
      "    'i': 0,   # type: int\n",
      "    'j': 6,   # type: int\n",
      "}\n",
      "\n",
      "GLOBAL VARIABLES:\n",
      "{\n",
      "    'nums': {0: 0, 1: 2, 2: 4, 3: 6, 4: 8, 5: 10, 6: 12, 7: 14, 8: 16, 9: 18, 10: 20,...},   # type: DotDict\n",
      "}\n",
      "\n",
      "SOLUTION PART 1:\u001b[0m\n",
      "\u001b[32m[RoboDuck] \u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mT\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32mp\u001b[0m\u001b[32mr\u001b[0m\u001b[32mo\u001b[0m\u001b[32mb\u001b[0m\u001b[32ml\u001b[0m\u001b[32me\u001b[0m\u001b[32mm\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32ms\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32ma\u001b[0m\u001b[32mt\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32ms\u001b[0m\u001b[32me\u001b[0m\u001b[32mc\u001b[0m\u001b[32mo\u001b[0m\u001b[32mn\u001b[0m\u001b[32md\u001b[0m\u001b[32m \u001b[0m\u001b[32mf\u001b[0m\u001b[32mo\u001b[0m\u001b[32mr\u001b[0m\u001b[32m \u001b[0m\u001b[32ml\u001b[0m\u001b[32mo\u001b[0m\u001b[32mo\u001b[0m\u001b[32mp\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32ms\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32mt\u001b[0m\u001b[32me\u001b[0m\u001b[32mr\u001b[0m\u001b[32ma\u001b[0m\u001b[32mt\u001b[0m\u001b[32mi\u001b[0m\u001b[32mn\u001b[0m\u001b[32mg\u001b[0m\u001b[32m \u001b[0m\u001b[32mo\u001b[0m\u001b[32mv\u001b[0m\u001b[32me\u001b[0m\u001b[32mr\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32ml\u001b[0m\u001b[32me\u001b[0m\u001b[32mn\u001b[0m\u001b[32mg\u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32m \u001b[0m\u001b[32mo\u001b[0m\u001b[32mf\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32ml\u001b[0m\u001b[32mi\u001b[0m\u001b[32ms\u001b[0m\u001b[32mt\u001b[0m\u001b[32m,\u001b[0m\u001b[32m \u001b[0m\u001b[32mw\u001b[0m\u001b[32mh\u001b[0m\u001b[32mi\u001b[0m\u001b[32mc\u001b[0m\u001b[32mh\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32ms\u001b[0m\u001b[32m \u001b[0m\u001b[32m9\u001b[0m\u001b[32m.\u001b[0m\u001b[32m \u001b[0m\u001b[32mH\u001b[0m\u001b[32mo\u001b[0m\u001b[32mw\u001b[0m\u001b[32me\u001b[0m\u001b[32mv\u001b[0m\u001b[32me\u001b[0m\u001b[32mr\u001b[0m\u001b[32m,\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32mf\u001b[0m\u001b[32m \u001b[0m\u001b[32ms\u001b[0m\u001b[32mt\u001b[0m\u001b[32ma\u001b[0m\u001b[32mt\u001b[0m\u001b[32me\u001b[0m\u001b[32mm\u001b[0m\u001b[32me\u001b[0m\u001b[32mn\u001b[0m\u001b[32mt\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32ms\u001b[0m\u001b[32m \u001b[0m\u001b[32mc\u001b[0m\u001b[32mo\u001b[0m\u001b[32mm\u001b[0m\u001b[32mp\u001b[0m\u001b[32ma\u001b[0m\u001b[32mr\u001b[0m\u001b[32mi\u001b[0m\u001b[32mn\u001b[0m\u001b[32mg\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32mv\u001b[0m\u001b[32ma\u001b[0m\u001b[32ml\u001b[0m\u001b[32mu\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32ma\u001b[0m\u001b[32mt\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32mn\u001b[0m\u001b[32md\u001b[0m\u001b[32me\u001b[0m\u001b[32mx\u001b[0m\u001b[32m \u001b[0m\u001b[32mj\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mo\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32mv\u001b[0m\u001b[32ma\u001b[0m\u001b[32ml\u001b[0m\u001b[32mu\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32ma\u001b[0m\u001b[32mt\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32mn\u001b[0m\u001b[32md\u001b[0m\u001b[32me\u001b[0m\u001b[32mx\u001b[0m\u001b[32m \u001b[0m\u001b[32mj\u001b[0m\u001b[32m+\u001b[0m\u001b[32m1\u001b[0m\u001b[32m.\u001b[0m\u001b[32m \u001b[0m\u001b[32mW\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32mn\u001b[0m\u001b[32m \u001b[0m\u001b[32mj\u001b[0m\u001b[32m=\u001b[0m\u001b[32m8\u001b[0m\u001b[32m,\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32mr\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32ms\u001b[0m\u001b[32m \u001b[0m\u001b[32mn\u001b[0m\u001b[32mo\u001b[0m\u001b[32m \u001b[0m\u001b[32mv\u001b[0m\u001b[32ma\u001b[0m\u001b[32ml\u001b[0m\u001b[32mu\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32ma\u001b[0m\u001b[32mt\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32mn\u001b[0m\u001b[32md\u001b[0m\u001b[32me\u001b[0m\u001b[32mx\u001b[0m\u001b[32m \u001b[0m\u001b[32m9\u001b[0m\u001b[32m.\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32md\u001b[0m\u001b[32me\u001b[0m\u001b[32mf\u001b[0m\u001b[32m \u001b[0m\u001b[32mb\u001b[0m\u001b[32mu\u001b[0m\u001b[32mb\u001b[0m\u001b[32mb\u001b[0m\u001b[32ml\u001b[0m\u001b[32me\u001b[0m\u001b[32m_\u001b[0m\u001b[32ms\u001b[0m\u001b[32mo\u001b[0m\u001b[32mr\u001b[0m\u001b[32mt\u001b[0m\u001b[32m(\u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32mf\u001b[0m\u001b[32mo\u001b[0m\u001b[32mr\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32mn\u001b[0m\u001b[32m \u001b[0m\u001b[32mr\u001b[0m\u001b[32ma\u001b[0m\u001b[32mn\u001b[0m\u001b[32mg\u001b[0m\u001b[32me\u001b[0m\u001b[32m(\u001b[0m\u001b[32ml\u001b[0m\u001b[32me\u001b[0m\u001b[32mn\u001b[0m\u001b[32m(\u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32mf\u001b[0m\u001b[32mo\u001b[0m\u001b[32mr\u001b[0m\u001b[32m \u001b[0m\u001b[32mj\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32mn\u001b[0m\u001b[32m \u001b[0m\u001b[32mr\u001b[0m\u001b[32ma\u001b[0m\u001b[32mn\u001b[0m\u001b[32mg\u001b[0m\u001b[32me\u001b[0m\u001b[32m(\u001b[0m\u001b[32ml\u001b[0m\u001b[32me\u001b[0m\u001b[32mn\u001b[0m\u001b[32m(\u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m)\u001b[0m\u001b[32m-\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\u001b[0m\u001b[32m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32mf\u001b[0m\u001b[32m \u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m[\u001b[0m\u001b[32mj\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\u001b[32m>\u001b[0m\u001b[32m \u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m[\u001b[0m\u001b[32mj\u001b[0m\u001b[32m \u001b[0m\u001b[32m+\u001b[0m\u001b[32m \u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m:\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m[\u001b[0m\u001b[32mj\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\u001b[0m\u001b[32m \u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m[\u001b[0m\u001b[32mj\u001b[0m\u001b[32m \u001b[0m\u001b[32m+\u001b[0m\u001b[32m \u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\u001b[32m=\u001b[0m\u001b[32m \u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m[\u001b[0m\u001b[32mj\u001b[0m\u001b[32m \u001b[0m\u001b[32m+\u001b[0m\u001b[32m \u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\u001b[0m\u001b[32m \u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m[\u001b[0m\u001b[32mj\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32mr\u001b[0m\u001b[32mo\u001b[0m\u001b[32mb\u001b[0m\u001b[32mo\u001b[0m\u001b[32md\u001b[0m\u001b[32mu\u001b[0m\u001b[32mc\u001b[0m\u001b[32mk\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32mr\u001b[0m\u001b[32me\u001b[0m\u001b[32mt\u001b[0m\u001b[32mu\u001b[0m\u001b[32mr\u001b[0m\u001b[32mn\u001b[0m\u001b[32m \u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m\n",
      "\u001b[0m>>> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-cd058749a54e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Un-comment the roboduck() line.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbubble_sort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-95174b1d61b8>\u001b[0m in \u001b[0;36mbubble_sort\u001b[0;34m(nums)\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mroboduck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-95174b1d61b8>\u001b[0m in \u001b[0;36mbubble_sort\u001b[0;34m(nums)\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mroboduck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Un-comment the roboduck() line.\n",
    "bubble_sort([5, 2, 4, 4, 3, 1, 9, 17, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T02:53:55.902883Z",
     "start_time": "2023-02-17T02:53:55.105580Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-63082f0afe88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Re-comment the roboduck() line.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbubble_sort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-cab5a6393537>\u001b[0m in \u001b[0;36mbubble_sort\u001b[0;34m(nums)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                 \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#             roboduck()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Re-comment the roboduck() line.\n",
    "bubble_sort([5, 2, 4, 4, 3, 1, 9, 17, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T02:54:15.259798Z",
     "start_time": "2023-02-17T02:53:58.353332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] > \u001b[33;01m<ipython-input-12-cab5a6393537>\u001b[00m(\u001b[36;01m4\u001b[00m)bubble_sort()\n",
      "-> if nums[j] > nums[j + 1]:\n",
      ">>> Why will this throw an index error?\n",
      "\u001b[31m\"\"\"ANSWER KEY\n",
      "\n",
      "This code snippet is not working as expected. Help me debug it. First read my question, then examine the snippet of code that is causing the issue and look at the values of the local and global variables. If you see a function called roboduck, ignore it. In the section titled SOLUTION PART 1, use plain English to explain what the problem is and how to fix it. In the section titled SOLUTION PART 2, write a corrected version of the input code snippet. If you don't know what the problem is, SOLUTION PART 1 should list a few possible causes or things I could try in order to identify the issue and SOLUTION PART 2 should say N/A. Be concise and use simple language because I am a beginning programmer.\n",
      "\n",
      "QUESTION:\n",
      "Why will this throw an index error?\n",
      "\n",
      "CURRENT CODE SNIPPET:\n",
      "def bubble_sort(nums):\n",
      "    for i in range(len(nums)):\n",
      "        for j in range(len(nums)):\n",
      "            if nums[j] > nums[j + 1]:\n",
      "                nums[j], nums[j + 1] = nums[j + 1], nums[j]\n",
      "#             roboduck()\n",
      "    return nums\n",
      "\n",
      "\n",
      "LOCAL VARIABLES:\n",
      "{\n",
      "    'nums': [2, 4, 4, 3, 1, 5, 9, 7, 17],   # type: list\n",
      "    'i': 0,   # type: int\n",
      "    'j': 8,   # type: int\n",
      "}\n",
      "\n",
      "GLOBAL VARIABLES:\n",
      "{\n",
      "    'nums': {0: 0, 1: 2, 2: 4, 3: 6, 4: 8, 5: 10, 6: 12, 7: 14, 8: 16, 9: 18, 10: 20,...},   # type: DotDict\n",
      "}\n",
      "\n",
      "SOLUTION PART 1:\u001b[0m\n",
      "\u001b[32m[RoboDuck] \u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mT\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32mp\u001b[0m\u001b[32mr\u001b[0m\u001b[32mo\u001b[0m\u001b[32mb\u001b[0m\u001b[32ml\u001b[0m\u001b[32me\u001b[0m\u001b[32mm\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32ms\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32ma\u001b[0m\u001b[32mt\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32ms\u001b[0m\u001b[32me\u001b[0m\u001b[32mc\u001b[0m\u001b[32mo\u001b[0m\u001b[32mn\u001b[0m\u001b[32md\u001b[0m\u001b[32m \u001b[0m\u001b[32mf\u001b[0m\u001b[32mo\u001b[0m\u001b[32mr\u001b[0m\u001b[32m \u001b[0m\u001b[32ml\u001b[0m\u001b[32mo\u001b[0m\u001b[32mo\u001b[0m\u001b[32mp\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32ms\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32mt\u001b[0m\u001b[32me\u001b[0m\u001b[32mr\u001b[0m\u001b[32ma\u001b[0m\u001b[32mt\u001b[0m\u001b[32mi\u001b[0m\u001b[32mn\u001b[0m\u001b[32mg\u001b[0m\u001b[32m \u001b[0m\u001b[32mo\u001b[0m\u001b[32mv\u001b[0m\u001b[32me\u001b[0m\u001b[32mr\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32ml\u001b[0m\u001b[32me\u001b[0m\u001b[32mn\u001b[0m\u001b[32mg\u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32m \u001b[0m\u001b[32mo\u001b[0m\u001b[32mf\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32ml\u001b[0m\u001b[32mi\u001b[0m\u001b[32ms\u001b[0m\u001b[32mt\u001b[0m\u001b[32m,\u001b[0m\u001b[32m \u001b[0m\u001b[32mw\u001b[0m\u001b[32mh\u001b[0m\u001b[32mi\u001b[0m\u001b[32mc\u001b[0m\u001b[32mh\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32ms\u001b[0m\u001b[32m \u001b[0m\u001b[32m9\u001b[0m\u001b[32m.\u001b[0m\u001b[32m \u001b[0m\u001b[32mH\u001b[0m\u001b[32mo\u001b[0m\u001b[32mw\u001b[0m\u001b[32me\u001b[0m\u001b[32mv\u001b[0m\u001b[32me\u001b[0m\u001b[32mr\u001b[0m\u001b[32m,\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32mf\u001b[0m\u001b[32m \u001b[0m\u001b[32ms\u001b[0m\u001b[32mt\u001b[0m\u001b[32ma\u001b[0m\u001b[32mt\u001b[0m\u001b[32me\u001b[0m\u001b[32mm\u001b[0m\u001b[32me\u001b[0m\u001b[32mn\u001b[0m\u001b[32mt\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32ms\u001b[0m\u001b[32m \u001b[0m\u001b[32mc\u001b[0m\u001b[32mo\u001b[0m\u001b[32mm\u001b[0m\u001b[32mp\u001b[0m\u001b[32ma\u001b[0m\u001b[32mr\u001b[0m\u001b[32mi\u001b[0m\u001b[32mn\u001b[0m\u001b[32mg\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32mv\u001b[0m\u001b[32ma\u001b[0m\u001b[32ml\u001b[0m\u001b[32mu\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32ma\u001b[0m\u001b[32mt\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32mn\u001b[0m\u001b[32md\u001b[0m\u001b[32me\u001b[0m\u001b[32mx\u001b[0m\u001b[32m \u001b[0m\u001b[32mj\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mo\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32mv\u001b[0m\u001b[32ma\u001b[0m\u001b[32ml\u001b[0m\u001b[32mu\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32ma\u001b[0m\u001b[32mt\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32mn\u001b[0m\u001b[32md\u001b[0m\u001b[32me\u001b[0m\u001b[32mx\u001b[0m\u001b[32m \u001b[0m\u001b[32mj\u001b[0m\u001b[32m \u001b[0m\u001b[32m+\u001b[0m\u001b[32m \u001b[0m\u001b[32m1\u001b[0m\u001b[32m,\u001b[0m\u001b[32m \u001b[0m\u001b[32mw\u001b[0m\u001b[32mh\u001b[0m\u001b[32mi\u001b[0m\u001b[32mc\u001b[0m\u001b[32mh\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32ms\u001b[0m\u001b[32m \u001b[0m\u001b[32m1\u001b[0m\u001b[32m0\u001b[0m\u001b[32m.\u001b[0m\u001b[32m \u001b[0m\u001b[32mS\u001b[0m\u001b[32mi\u001b[0m\u001b[32mn\u001b[0m\u001b[32mc\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32mr\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32ma\u001b[0m\u001b[32mr\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32mo\u001b[0m\u001b[32mn\u001b[0m\u001b[32ml\u001b[0m\u001b[32my\u001b[0m\u001b[32m \u001b[0m\u001b[32m9\u001b[0m\u001b[32m \u001b[0m\u001b[32me\u001b[0m\u001b[32ml\u001b[0m\u001b[32me\u001b[0m\u001b[32mm\u001b[0m\u001b[32me\u001b[0m\u001b[32mn\u001b[0m\u001b[32mt\u001b[0m\u001b[32ms\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32mn\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32ml\u001b[0m\u001b[32mi\u001b[0m\u001b[32ms\u001b[0m\u001b[32mt\u001b[0m\u001b[32m,\u001b[0m\u001b[32m \u001b[0m\u001b[32mt\u001b[0m\u001b[32mh\u001b[0m\u001b[32me\u001b[0m\u001b[32mr\u001b[0m\u001b[32me\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32ms\u001b[0m\u001b[32m \u001b[0m\u001b[32mn\u001b[0m\u001b[32mo\u001b[0m\u001b[32m \u001b[0m\u001b[32me\u001b[0m\u001b[32ml\u001b[0m\u001b[32me\u001b[0m\u001b[32mm\u001b[0m\u001b[32me\u001b[0m\u001b[32mn\u001b[0m\u001b[32mt\u001b[0m\u001b[32m \u001b[0m\u001b[32ma\u001b[0m\u001b[32mt\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32mn\u001b[0m\u001b[32md\u001b[0m\u001b[32me\u001b[0m\u001b[32mx\u001b[0m\u001b[32m \u001b[0m\u001b[32m1\u001b[0m\u001b[32m0\u001b[0m\u001b[32m.\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32md\u001b[0m\u001b[32me\u001b[0m\u001b[32mf\u001b[0m\u001b[32m \u001b[0m\u001b[32mb\u001b[0m\u001b[32mu\u001b[0m\u001b[32mb\u001b[0m\u001b[32mb\u001b[0m\u001b[32ml\u001b[0m\u001b[32me\u001b[0m\u001b[32m_\u001b[0m\u001b[32ms\u001b[0m\u001b[32mo\u001b[0m\u001b[32mr\u001b[0m\u001b[32mt\u001b[0m\u001b[32m(\u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32mf\u001b[0m\u001b[32mo\u001b[0m\u001b[32mr\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32mn\u001b[0m\u001b[32m \u001b[0m\u001b[32mr\u001b[0m\u001b[32ma\u001b[0m\u001b[32mn\u001b[0m\u001b[32mg\u001b[0m\u001b[32me\u001b[0m\u001b[32m(\u001b[0m\u001b[32ml\u001b[0m\u001b[32me\u001b[0m\u001b[32mn\u001b[0m\u001b[32m(\u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m)\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32mf\u001b[0m\u001b[32mo\u001b[0m\u001b[32mr\u001b[0m\u001b[32m \u001b[0m\u001b[32mj\u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32mn\u001b[0m\u001b[32m \u001b[0m\u001b[32mr\u001b[0m\u001b[32ma\u001b[0m\u001b[32mn\u001b[0m\u001b[32mg\u001b[0m\u001b[32me\u001b[0m\u001b[32m(\u001b[0m\u001b[32ml\u001b[0m\u001b[32me\u001b[0m\u001b[32mn\u001b[0m\u001b[32m(\u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m-\u001b[0m\u001b[32m \u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32mi\u001b[0m\u001b[32mf\u001b[0m\u001b[32m \u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m[\u001b[0m\u001b[32mj\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\u001b[32m>\u001b[0m\u001b[32m \u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m[\u001b[0m\u001b[32mj\u001b[0m\u001b[32m \u001b[0m\u001b[32m+\u001b[0m\u001b[32m \u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m:\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m[\u001b[0m\u001b[32mj\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\u001b[0m\u001b[32m \u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m[\u001b[0m\u001b[32mj\u001b[0m\u001b[32m \u001b[0m\u001b[32m+\u001b[0m\u001b[32m \u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\u001b[32m=\u001b[0m\u001b[32m \u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m[\u001b[0m\u001b[32mj\u001b[0m\u001b[32m \u001b[0m\u001b[32m+\u001b[0m\u001b[32m \u001b[0m\u001b[32m1\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\u001b[0m\u001b[32m \u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m[\u001b[0m\u001b[32mj\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m#\u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32mr\u001b[0m\u001b[32mo\u001b[0m\u001b[32mb\u001b[0m\u001b[32mo\u001b[0m\u001b[32md\u001b[0m\u001b[32mu\u001b[0m\u001b[32mc\u001b[0m\u001b[32mk\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32m \u001b[0m\u001b[32mr\u001b[0m\u001b[32me\u001b[0m\u001b[32mt\u001b[0m\u001b[32mu\u001b[0m\u001b[32mr\u001b[0m\u001b[32mn\u001b[0m\u001b[32m \u001b[0m\u001b[32mn\u001b[0m\u001b[32mu\u001b[0m\u001b[32mm\u001b[0m\u001b[32ms\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m\n",
      "\u001b[0m>>> q\n"
     ]
    }
   ],
   "source": [
    "# Note: couldn't get cell magic version working so far. Says:\n",
    "# \"UsageError: %%lmdb is a cell magic, but the cell body is empty. Did you\n",
    "# mean the line magic %lmdb (single %)?\"\n",
    "# Even when I try to define the method with all the same settings as the \n",
    "# default class.\n",
    "%duck -i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubble_sort(nums):\n",
    "    for i in range(len(nums)):\n",
    "        for j in range(len(nums) - 1):\n",
    "            if nums[j] > nums[j + 1]:\n",
    "                nums[j], nums[j + 1] = nums[j + 1], nums[j]\n",
    "#             roboduck()\n",
    "    return nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch\n",
    "\n",
    "Mostly informal tests of functionality I developed above. Moving down because jupyter magic seems to require restarting the kernel a lot and I don't want to re-run unnecessary things (especially slow things like loading the tokenizer) or cells that need custom editing (like the one that requires you to change the cell without saving before calling load_ipynb). This means we can now restart, select this cell and click Run All Above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:21.974960Z",
     "start_time": "2023-02-16T04:05:21.912369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_1': True,\n",
       " '_99': True,\n",
       " '_': True,\n",
       " '__': True,\n",
       " '_1_': False,\n",
       " '_a': False,\n",
       " '__1': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{name: is_ipy_name(name)\n",
    " for name in ('_1', '_99', '_', '__', '_1_', '_a', '__1')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:23.071787Z",
     "start_time": "2023-02-16T04:05:21.977273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set new var on line below and do NOT save notebook.\n",
    "qqq = 'xcz,vl lzvjxc'\n",
    "tmp = load_ipynb(ipynbname.path())\n",
    "assert qqq in tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:26.811922Z",
     "start_time": "2023-02-16T04:05:26.734168Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set new var on line below and do NOT save. If you don't change the var, the\n",
    "# test will generally fail bc a previous version of the nb will have had the\n",
    "# var value.\n",
    "qqq = 'a1zce1zazzzzzzzz eoiqur wqopasdfasferu'\n",
    "tmp = load_ipynb(ipynbname.path(), save_if_self=False)\n",
    "assert qqq not in tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:27.337340Z",
     "start_time": "2023-02-16T04:05:27.269087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> True False\n",
      "<class 'tuple'> True False\n",
      "<class 'list'> True False\n",
      "<class 'dict'> True True\n",
      "<class 'set'> True False\n",
      "<class 'bool'> False False\n",
      "<class 'htools.meta.MultiLogger'> False False\n"
     ]
    }
   ],
   "source": [
    "for obj in (\n",
    "    'string',\n",
    "    ('tuple', 1),\n",
    "    ['list', 2],\n",
    "    {'dict': 3},\n",
    "    {'set'},\n",
    "    True,\n",
    "    MultiLogger(None)\n",
    "):\n",
    "    print(type(obj), isinstance(obj, Iterable), isinstance(obj, Mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:28.055854Z",
     "start_time": "2023-02-16T04:05:27.988466Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tmp = pd.DataFrame(np.arange(390).reshape(30, 13), \n",
    "                      columns=list('abcdefghijklm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:28.401568Z",
     "start_time": "2023-02-16T04:05:28.314038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd.DataFrame(columns=\"['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j',...]\")\n"
     ]
    }
   ],
   "source": [
    "print(truncated_repr(df_tmp, 79))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:28.540212Z",
     "start_time": "2023-02-16T04:05:28.478496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd.Series([0, 13, 26, 39, 52, 65, 78, 91, 104, 117, 130, 143, 156, 169,...])\n"
     ]
    }
   ],
   "source": [
    "print(truncated_repr(df_tmp.a, 79))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:28.690745Z",
     "start_time": "2023-02-16T04:05:28.612205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd.Series([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...])\n"
     ]
    }
   ],
   "source": [
    "print(truncated_repr(pd.Series(np.arange(1000)), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:28.816197Z",
     "start_time": "2023-02-16T04:05:28.750111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['a', 'b', 'c', 'd',...]\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(df_tmp.columns.tolist() * 5, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:28.960225Z",
     "start_time": "2023-02-16T04:05:28.880845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'abcdefghijklmno...'\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr('abcdefghijklmnopqrstuvwxyz', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:29.650407Z",
     "start_time": "2023-02-16T04:05:29.586522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,...]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(list(range(100)), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:29.650407Z",
     "start_time": "2023-02-16T04:05:29.586522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f',...}\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(dict(enumerate('abcdefghijklmnop')), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:29.379178Z",
     "start_time": "2023-02-16T04:05:29.289106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g',...}\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(dict(enumerate('abcdefghijklmnop')), 58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:29.650407Z",
     "start_time": "2023-02-16T04:05:29.586522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(True, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:29.650407Z",
     "start_time": "2023-02-16T04:05:29.586522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<htools.meta.MultiLogger object at 0x7fcb8442d828>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(MultiLogger(None), 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:29.775515Z",
     "start_time": "2023-02-16T04:05:29.713500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<class 'htools.meta.MultiLogger'>\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(MultiLogger, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:29.972426Z",
     "start_time": "2023-02-16T04:05:29.911230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<htools.meta.MultiLogger>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(MultiLogger(None), 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:30.163079Z",
     "start_time": "2023-02-16T04:05:30.104444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<class MultiLogger>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(MultiLogger, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:30.447992Z",
     "start_time": "2023-02-16T04:05:30.379525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<function>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(colored, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:30.627971Z",
     "start_time": "2023-02-16T04:05:30.564455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'array([0, 1, 2, 3, 4,...])'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(np.arange(100), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:30.855523Z",
     "start_time": "2023-02-16T04:05:30.797474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0, 1, 2, 3, 4, 5,...]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(list(range(100)), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:31.152289Z",
     "start_time": "2023-02-16T04:05:31.081629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensor([0, 1, 2, 3, 4,...])'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(torch.arange(100), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:31.350223Z",
     "start_time": "2023-02-16T04:05:31.280171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{0: 0, 1: 2, 2: 4,...}'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(DotDict({i: i*2 for i in range(100)}), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:31.566026Z",
     "start_time": "2023-02-16T04:05:31.493876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'2.502e+121'\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(1379823479234**10, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:32.114721Z",
     "start_time": "2023-02-16T04:05:32.048989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    'a': [1, 2, 3],   # type: list\n",
      "    True: 223456,   # type: int\n",
      "    (3, 4): {'a', 'z'},   # type: set\n",
      "    0: {1: 3, 5: 'x'},   # type: dict\n",
      "    'dd': {3: '4', 'a': True},   # type: DotDict\n",
      "    'ddcls': <class 'htools.structures.DotDict'>,   # type: type\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "d = {\n",
    "    'a': [1, 2, 3],\n",
    "    True: 223_456,\n",
    "    (3, 4): {'a', 'z', 'a'},\n",
    "    0: {1: 3, 5: 'x'},\n",
    "    'dd': DotDict({3: '4', 'a': True}),\n",
    "    'ddcls': DotDict,\n",
    "}\n",
    "print(type_annotated_dict_str(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:32.305208Z",
     "start_time": "2023-02-16T04:05:32.230090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    'a': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,...],   # type: list\n",
      "    True: '9.283e+213',   # type: int\n",
      "    (3, 4): set(...),   # type: set\n",
      "    0: {1: 3, 5: 'x'},   # type: dict\n",
      "    'dd': {0: 1.0, 1: 0.5, 2: 0.3333333333333333, 3: 0.25,...},   # type: DotDict\n",
      "    'ddcls': <class 'htools.structures.DotDict'>,   # type: type\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "d = {\n",
    "    'a': list(range(100)),\n",
    "    True: 223_456**40,\n",
    "    (3, 4): {'a'*i for i in range(100)},\n",
    "    0: {1: 3, 5: 'x'},\n",
    "    'dd': DotDict({i: 1/(i+1) for i in range(200)}),\n",
    "    'ddcls': DotDict,\n",
    "}\n",
    "print(type_annotated_dict_str(d, partial(truncated_repr, max_len=50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:32.449282Z",
     "start_time": "2023-02-16T04:05:32.375737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    'a': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...],   # type: list\n",
      "    True: '9.283e+213',   # type: int\n",
      "    (3, 4): {'',...},   # type: set\n",
      "    0: {1: 3, 5: 'x'},   # type: dict\n",
      "    'dd': {0: 1.0, 1: 0.5, 2: 0.3333333333333333, 3: 0.25, 4: 0.2, 5: 0.16666666666666666,...},   # type: DotDict\n",
      "    'ddcls': <class 'htools.structures.DotDict'>,   # type: type\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "d = {\n",
    "    'a': list(range(100)),\n",
    "    True: 223_456**40,\n",
    "    (3, 4): {'a'*i for i in range(100)},\n",
    "    0: {1: 3, 5: 'x'},\n",
    "    'dd': DotDict({i: 1/(i+1) for i in range(200)}),\n",
    "    'ddcls': DotDict,\n",
    "}\n",
    "print(type_annotated_dict_str(d, partial(truncated_repr, max_len=79)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:37.497323Z",
     "start_time": "2023-02-16T04:05:32.543826Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:37.621347Z",
     "start_time": "2023-02-16T04:05:37.499828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize(\n",
    "    type_annotated_dict_str(d, partial(truncated_repr, max_len=79))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:37.746903Z",
     "start_time": "2023-02-16T04:05:37.631129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'set(...)'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(\n",
    "    {'a'*i for i in range(100)},\n",
    "    53\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:37.813557Z",
     "start_time": "2023-02-16T04:05:37.751843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'',...}\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(\n",
    "    {'a'*i for i in range(100)},\n",
    "    54\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:37.886050Z",
     "start_time": "2023-02-16T04:05:37.822758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[...]'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(\n",
    "    ['a'*i for i in range(100)],\n",
    "    53\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T04:05:37.943522Z",
     "start_time": "2023-02-16T04:05:37.888759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['',...]\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_repr(\n",
    "    ['a'*i for i in range(100)],\n",
    "    54\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
