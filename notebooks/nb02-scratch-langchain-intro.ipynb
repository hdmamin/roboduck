{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1R-AzSwp5UlM"
   },
   "source": [
    "# Summary\n",
    "\n",
    "Toying around with langchain. Getting familiar with it as a possible replacement for my custom built jabberwocky lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_TtFs1o5PBtp",
    "outputId": "682bf0b9-b8d7-473c-ceb8-269b6e526f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.0.113-py3-none-any.whl (396 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.0/396.0 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.9/dist-packages (from langchain) (2.25.1)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.10.6)\n",
      "Requirement already satisfied: PyYAML<7,>=6 in /usr/local/lib/python3.9/dist-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.22.4)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.4.46)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (8.2.2)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
      "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting charset-normalizer<4.0,>=2.0\n",
      "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting marshmallow<4.0.0,>=3.3.0\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 KB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (4.0.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, multidict, marshmallow, frozenlist, charset-normalizer, async-timeout, yarl, typing-inspect, marshmallow-enum, aiosignal, dataclasses-json, aiohttp, langchain\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 charset-normalizer-3.1.0 dataclasses-json-0.5.7 frozenlist-1.3.3 langchain-0.0.113 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 typing-inspect-0.8.0 yarl-1.8.2\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting openai\n",
      "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.10)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-0.27.2\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4) (2.4)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting unstructured\n",
      "  Downloading unstructured-0.5.4.tar.gz (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting argilla\n",
      "  Downloading argilla-1.4.0-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from unstructured) (4.9.2)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from unstructured) (3.7)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.9/dist-packages (from unstructured) (3.0.10)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from unstructured) (1.4.4)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from unstructured) (8.4.0)\n",
      "Collecting pypandoc\n",
      "  Downloading pypandoc-1.11-py3-none-any.whl (20 kB)\n",
      "Collecting python-docx\n",
      "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting python-pptx\n",
      "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting python-magic\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: markdown in /usr/local/lib/python3.9/dist-packages (from unstructured) (3.4.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from unstructured) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in /usr/local/lib/python3.9/dist-packages (from unstructured) (2022.12.7)\n",
      "Collecting httpx<0.24,>=0.15\n",
      "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (23.0)\n",
      "Collecting wrapt<1.15,>=1.13\n",
      "  Downloading wrapt-1.14.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting backoff\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting rich<=13.0.1\n",
      "  Downloading rich-13.0.1-py3-none-any.whl (238 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.1/238.1 KB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting deprecated~=1.2.0\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: pydantic>=1.7.1 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (1.10.6)\n",
      "Requirement already satisfied: numpy<1.24.0 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (1.22.4)\n",
      "Collecting monotonic\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->unstructured) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->unstructured) (2.8.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown->unstructured) (6.0.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->unstructured) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->unstructured) (2022.6.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->unstructured) (1.1.1)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.9/dist-packages (from openpyxl->unstructured) (1.1.0)\n",
      "Collecting XlsxWriter>=0.5.7\n",
      "  Downloading XlsxWriter-3.0.9-py3-none-any.whl (152 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->unstructured) (1.26.15)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->unstructured) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->unstructured) (2.10)\n",
      "Collecting rfc3986[idna2008]<2,>=1.3\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting httpcore<0.17.0,>=0.15.0\n",
      "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown->unstructured) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic>=1.7.1->argilla->unstructured) (4.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->unstructured) (1.15.0)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from rich<=13.0.1->argilla->unstructured) (2.6.1)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting anyio<5.0,>=3.0\n",
      "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: unstructured, python-docx, python-pptx\n",
      "  Building wheel for unstructured (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for unstructured: filename=unstructured-0.5.4-py3-none-any.whl size=1314305 sha256=994e50ae4a0f7b727aee51f9908fb3e022a9cf4c255c09a419e48e79bee74244\n",
      "  Stored in directory: /root/.cache/pip/wheels/76/bb/87/b4f4289bfc0d166525efc709edaf9ab9f0d3ef0184ab05fd64\n",
      "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184504 sha256=aa8eb4b9f687b963433fc493bf9250f10073274b676fedd09aae4343bd3047fa\n",
      "  Stored in directory: /root/.cache/pip/wheels/83/8b/7c/09ae60c42c7ba4ed2dddaf2b8b9186cb105255856d6ed3dba5\n",
      "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470950 sha256=247d1bb143809505a1e35697295c28bf83f0fc23f8bbad0b8befd9cf4c8b2253\n",
      "  Stored in directory: /root/.cache/pip/wheels/0e/4a/ed/9653bc799915f52dce3f04d14946fbd85cce9c3cdedc9cfa71\n",
      "Successfully built unstructured python-docx python-pptx\n",
      "Installing collected packages: rfc3986, monotonic, commonmark, XlsxWriter, wrapt, sniffio, rich, python-magic, python-docx, pypandoc, h11, backoff, python-pptx, deprecated, anyio, httpcore, httpx, argilla, unstructured\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.15.0\n",
      "    Uninstalling wrapt-1.15.0:\n",
      "      Successfully uninstalled wrapt-1.15.0\n",
      "Successfully installed XlsxWriter-3.0.9 anyio-3.6.2 argilla-1.4.0 backoff-2.2.1 commonmark-0.9.1 deprecated-1.2.13 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 monotonic-1.6 pypandoc-1.11 python-docx-0.8.11 python-magic-0.4.27 python-pptx-0.6.21 rfc3986-1.5.0 rich-13.0.1 sniffio-1.3.0 unstructured-0.5.4 wrapt-1.14.1\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-0.3.11-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastapi>=0.85.1\n",
      "  Downloading fastapi-0.94.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentence-transformers>=2.2.2\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.9/dist-packages (from chromadb) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.9/dist-packages (from chromadb) (1.22.4)\n",
      "Collecting requests>=2.28\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting uvicorn[standard]>=0.18.3\n",
      "  Downloading uvicorn-0.21.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting duckdb>=0.5.1\n",
      "  Downloading duckdb-0.7.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting clickhouse-connect>=0.5.7\n",
      "  Downloading clickhouse_connect-0.5.16-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (925 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.2/925.2 KB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hnswlib>=0.7\n",
      "  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.9/dist-packages (from chromadb) (1.10.6)\n",
      "Collecting zstandard\n",
      "  Downloading zstandard-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.12.7)\n",
      "Collecting lz4\n",
      "  Downloading lz4-4.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.7.1)\n",
      "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.15)\n",
      "Collecting starlette<0.27.0,>=0.26.1\n",
      "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic>=1.9->chromadb) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.28->chromadb) (2.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.28->chromadb) (3.1.0)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (1.13.1+cu116)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (0.14.1+cu116)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (1.10.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (3.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
      "  Downloading uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
      "Collecting python-dotenv>=0.13\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting watchfiles>=0.13\n",
      "  Downloading watchfiles-0.18.1-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting websockets>=10.4\n",
      "  Downloading websockets-10.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httptools>=0.5.0\n",
      "  Downloading httptools-0.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (417 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 KB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (3.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3->chromadb) (1.15.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (3.6.2)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (2022.6.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers>=2.2.2->chromadb) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence-transformers>=2.2.2->chromadb) (8.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/dist-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (1.3.0)\n",
      "Building wheels for collected packages: hnswlib, sentence-transformers\n",
      "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp39-cp39-linux_x86_64.whl size=2118470 sha256=9fe6bd8004608d2926ceda38c1c60a26c8ecd1ba226992f338d218ae85a54673\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/26/61/fface6c407f56418b3140cd7645917f20ba6b27d4e32b2bd20\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125942 sha256=4abdf3a8e81580e33371bec5e914024c56e36164c25413e31ed3223675ab61ad\n",
      "  Stored in directory: /root/.cache/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built hnswlib sentence-transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, duckdb, zstandard, websockets, uvloop, uvicorn, requests, python-dotenv, lz4, httptools, hnswlib, watchfiles, starlette, huggingface-hub, clickhouse-connect, transformers, fastapi, sentence-transformers, chromadb\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.25.1\n",
      "    Uninstalling requests-2.25.1:\n",
      "      Successfully uninstalled requests-2.25.1\n",
      "Successfully installed chromadb-0.3.11 clickhouse-connect-0.5.16 duckdb-0.7.1 fastapi-0.94.1 hnswlib-0.7.0 httptools-0.5.0 huggingface-hub-0.13.2 lz4-4.3.2 python-dotenv-1.0.0 requests-2.28.2 sentence-transformers-2.2.2 sentencepiece-0.1.97 starlette-0.26.1 tokenizers-0.13.2 transformers-4.27.1 uvicorn-0.21.0 uvloop-0.17.0 watchfiles-0.18.1 websockets-10.4 zstandard-0.20.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting youtube-transcript-api\n",
      "  Downloading youtube_transcript_api-0.5.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from youtube-transcript-api) (2.28.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->youtube-transcript-api) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->youtube-transcript-api) (2.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->youtube-transcript-api) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->youtube-transcript-api) (2022.12.7)\n",
      "Installing collected packages: youtube-transcript-api\n",
      "Successfully installed youtube-transcript-api-0.5.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pytube\n",
      "  Downloading pytube-12.1.2-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytube\n",
      "Successfully installed pytube-12.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install beautifulsoup4\n",
    "!pip install unstructured\n",
    "!pip install chromadb\n",
    "!pip install youtube-transcript-api\n",
    "!pip install pytube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZSKLSl1PA5N"
   },
   "source": [
    "## BashChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A6wySFlwakIl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chains import LLMBashChain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zDSUyS-W5tvi"
   },
   "outputs": [],
   "source": [
    "# Need to paste in key for this to work. Don't want to commit it in git though.\n",
    "openai_key = None\n",
    "os.environ['OPENAI_API_KEY'] = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Tz8il_KOandb"
   },
   "outputs": [],
   "source": [
    "ada = OpenAI(\n",
    "    temperature=0, model_name='text-ada-001',\n",
    "    openai_api_key=openai_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "slQ0enBmbkdR"
   },
   "outputs": [],
   "source": [
    "davinci = OpenAI(\n",
    "    model_name='text-davinci-003', openai_api_key=openai_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "7T3KYrBpPA5O",
    "outputId": "4a8a981f-5e9b-4d20-886a-e3aac5e0488b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMBashChain chain...\u001b[0m\n",
      "Please write a bash script that prints 'Hello World' to the console.\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "```bash\n",
      "echo \"Hello World\"\n",
      "```\u001b[0m['```bash', 'echo \"Hello World\"', '```']\n",
      "\n",
      "Answer: \u001b[33;1m\u001b[1;3mHello World\n",
      "\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Hello World\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Please write a bash script that prints 'Hello World' to the console.\"\n",
    "bash_chain = LLMBashChain(llm=davinci, verbose=True)\n",
    "# HDM: looks like langchain requires completion to start with ```bash or raises\n",
    "# error. Probably should do some post-processing instead.\n",
    "bash_chain.run(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0F1pXJ9Tak-"
   },
   "source": [
    "## Calling APIs\n",
    "\n",
    "None of the 3 apis I tried worked here. One was clearly due to the prompt/preprocessing - it just output the endpoint rather than the full url to call. If I could figure out how to provide a custom prompt I could definintely get this working.\n",
    "\n",
    "UPDATE: maybe fixed in new release? Weather queries seem to work now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rCHl_rQXTZkK"
   },
   "outputs": [],
   "source": [
    "from langchain.chains.api.prompt import API_RESPONSE_PROMPT\n",
    "from langchain.chains import APIChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains.api import news_docs, tmdb_docs, open_meteo_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "QAHwC_2FTljP"
   },
   "outputs": [],
   "source": [
    "chain = APIChain.from_llm_and_api_docs(davinci, open_meteo_docs.OPEN_METEO_DOCS,\n",
    "                                       verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xe1XOOr2Tnoc",
    "outputId": "729a0800-48fd-4e1f-b9d4-6050799fea92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mhttps://api.open-meteo.com/v1/forecast?latitude=38.7222524&longitude=-9.1393366&hourly=temperature_2m&temperature_unit=celsius\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m{\"latitude\":38.72,\"longitude\":-9.14,\"generationtime_ms\":0.26798248291015625,\"utc_offset_seconds\":0,\"timezone\":\"GMT\",\"timezone_abbreviation\":\"GMT\",\"elevation\":66.0,\"hourly_units\":{\"time\":\"iso8601\",\"temperature_2m\":\"°C\"},\"hourly\":{\"time\":[\"2023-03-14T00:00\",\"2023-03-14T01:00\",\"2023-03-14T02:00\",\"2023-03-14T03:00\",\"2023-03-14T04:00\",\"2023-03-14T05:00\",\"2023-03-14T06:00\",\"2023-03-14T07:00\",\"2023-03-14T08:00\",\"2023-03-14T09:00\",\"2023-03-14T10:00\",\"2023-03-14T11:00\",\"2023-03-14T12:00\",\"2023-03-14T13:00\",\"2023-03-14T14:00\",\"2023-03-14T15:00\",\"2023-03-14T16:00\",\"2023-03-14T17:00\",\"2023-03-14T18:00\",\"2023-03-14T19:00\",\"2023-03-14T20:00\",\"2023-03-14T21:00\",\"2023-03-14T22:00\",\"2023-03-14T23:00\",\"2023-03-15T00:00\",\"2023-03-15T01:00\",\"2023-03-15T02:00\",\"2023-03-15T03:00\",\"2023-03-15T04:00\",\"2023-03-15T05:00\",\"2023-03-15T06:00\",\"2023-03-15T07:00\",\"2023-03-15T08:00\",\"2023-03-15T09:00\",\"2023-03-15T10:00\",\"2023-03-15T11:00\",\"2023-03-15T12:00\",\"2023-03-15T13:00\",\"2023-03-15T14:00\",\"2023-03-15T15:00\",\"2023-03-15T16:00\",\"2023-03-15T17:00\",\"2023-03-15T18:00\",\"2023-03-15T19:00\",\"2023-03-15T20:00\",\"2023-03-15T21:00\",\"2023-03-15T22:00\",\"2023-03-15T23:00\",\"2023-03-16T00:00\",\"2023-03-16T01:00\",\"2023-03-16T02:00\",\"2023-03-16T03:00\",\"2023-03-16T04:00\",\"2023-03-16T05:00\",\"2023-03-16T06:00\",\"2023-03-16T07:00\",\"2023-03-16T08:00\",\"2023-03-16T09:00\",\"2023-03-16T10:00\",\"2023-03-16T11:00\",\"2023-03-16T12:00\",\"2023-03-16T13:00\",\"2023-03-16T14:00\",\"2023-03-16T15:00\",\"2023-03-16T16:00\",\"2023-03-16T17:00\",\"2023-03-16T18:00\",\"2023-03-16T19:00\",\"2023-03-16T20:00\",\"2023-03-16T21:00\",\"2023-03-16T22:00\",\"2023-03-16T23:00\",\"2023-03-17T00:00\",\"2023-03-17T01:00\",\"2023-03-17T02:00\",\"2023-03-17T03:00\",\"2023-03-17T04:00\",\"2023-03-17T05:00\",\"2023-03-17T06:00\",\"2023-03-17T07:00\",\"2023-03-17T08:00\",\"2023-03-17T09:00\",\"2023-03-17T10:00\",\"2023-03-17T11:00\",\"2023-03-17T12:00\",\"2023-03-17T13:00\",\"2023-03-17T14:00\",\"2023-03-17T15:00\",\"2023-03-17T16:00\",\"2023-03-17T17:00\",\"2023-03-17T18:00\",\"2023-03-17T19:00\",\"2023-03-17T20:00\",\"2023-03-17T21:00\",\"2023-03-17T22:00\",\"2023-03-17T23:00\",\"2023-03-18T00:00\",\"2023-03-18T01:00\",\"2023-03-18T02:00\",\"2023-03-18T03:00\",\"2023-03-18T04:00\",\"2023-03-18T05:00\",\"2023-03-18T06:00\",\"2023-03-18T07:00\",\"2023-03-18T08:00\",\"2023-03-18T09:00\",\"2023-03-18T10:00\",\"2023-03-18T11:00\",\"2023-03-18T12:00\",\"2023-03-18T13:00\",\"2023-03-18T14:00\",\"2023-03-18T15:00\",\"2023-03-18T16:00\",\"2023-03-18T17:00\",\"2023-03-18T18:00\",\"2023-03-18T19:00\",\"2023-03-18T20:00\",\"2023-03-18T21:00\",\"2023-03-18T22:00\",\"2023-03-18T23:00\",\"2023-03-19T00:00\",\"2023-03-19T01:00\",\"2023-03-19T02:00\",\"2023-03-19T03:00\",\"2023-03-19T04:00\",\"2023-03-19T05:00\",\"2023-03-19T06:00\",\"2023-03-19T07:00\",\"2023-03-19T08:00\",\"2023-03-19T09:00\",\"2023-03-19T10:00\",\"2023-03-19T11:00\",\"2023-03-19T12:00\",\"2023-03-19T13:00\",\"2023-03-19T14:00\",\"2023-03-19T15:00\",\"2023-03-19T16:00\",\"2023-03-19T17:00\",\"2023-03-19T18:00\",\"2023-03-19T19:00\",\"2023-03-19T20:00\",\"2023-03-19T21:00\",\"2023-03-19T22:00\",\"2023-03-19T23:00\",\"2023-03-20T00:00\",\"2023-03-20T01:00\",\"2023-03-20T02:00\",\"2023-03-20T03:00\",\"2023-03-20T04:00\",\"2023-03-20T05:00\",\"2023-03-20T06:00\",\"2023-03-20T07:00\",\"2023-03-20T08:00\",\"2023-03-20T09:00\",\"2023-03-20T10:00\",\"2023-03-20T11:00\",\"2023-03-20T12:00\",\"2023-03-20T13:00\",\"2023-03-20T14:00\",\"2023-03-20T15:00\",\"2023-03-20T16:00\",\"2023-03-20T17:00\",\"2023-03-20T18:00\",\"2023-03-20T19:00\",\"2023-03-20T20:00\",\"2023-03-20T21:00\",\"2023-03-20T22:00\",\"2023-03-20T23:00\"],\"temperature_2m\":[11.4,11.0,11.0,11.0,10.7,10.3,10.0,9.7,10.3,12.6,15.1,16.3,17.2,17.9,18.5,18.7,18.8,18.5,17.5,16.0,14.7,13.6,12.8,12.0,11.3,10.8,10.4,10.0,9.6,9.4,9.2,9.1,9.8,11.7,14.2,16.9,18.9,20.5,21.6,22.2,21.8,21.1,19.4,16.8,15.0,13.5,12.6,12.1,11.6,11.1,10.8,10.6,10.3,10.0,9.5,9.5,10.3,13.1,16.6,18.7,20.2,21.4,21.4,20.5,18.5,16.7,15.4,14.7,14.3,14.1,13.4,12.7,12.2,12.0,11.3,11.7,12.0,12.2,12.2,12.9,13.2,13.6,14.0,14.4,14.8,14.9,14.8,14.6,14.3,13.9,13.4,13.2,13.0,12.8,12.7,12.6,12.4,12.3,12.2,12.1,11.9,11.8,11.8,12.2,12.8,13.7,14.6,15.6,16.8,17.3,17.7,17.8,17.4,16.8,16.1,16.8,15.4,13.8,13.1,12.7,12.3,12.0,11.8,11.5,11.2,10.8,10.8,11.1,11.7,12.9,14.3,16.0,17.7,18.4,18.6,18.6,18.3,17.7,16.8,16.0,15.0,13.8,13.3,12.9,12.5,12.3,12.1,12.0,12.0,12.0,12.1,12.2,12.4,13.0,14.0,15.2,16.6,17.1,17.4,17.3,16.9,16.3,15.4,14.7,14.0,13.5,13.5,13.8]}}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "text = \"What is the temperature today in Lisbon, Portugal?\"\n",
    "res = chain.run(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "N4NVvGbCVurs",
    "outputId": "342748a3-b450-4a28-b9bd-f6a8b0c07f7a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' The temperature today in Lisbon, Portugal is 11.4°C.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcBbe7nLcxus"
   },
   "source": [
    "## Basic Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "J3KL8JpoczTx"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "dujV-yeqjQbb"
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "qrotoKZrc2jf"
   },
   "outputs": [],
   "source": [
    "tool_template = 'Read the question below and identify what tools you need to ' \\\n",
    "'answer the question accurately. Your available tools are:\\n- ipython shell '\\\n",
    "'(for performing mathematical computations or running simulations)\\n-'\\\n",
    "'- google search api (for gathering facts or news)\\n\\nIf no tools are needed, '\\\n",
    "'simply output \"null\".\\n\\nQUESTION\\n{question}\\n\\nTOOLS'\n",
    "\n",
    "tool_prompt = PromptTemplate(\n",
    "    input_variables=['question'],\n",
    "    template=tool_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "DkhN05U1kEj_"
   },
   "outputs": [],
   "source": [
    "cs_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=\"You are a customer service agent. Review the customer \"\n",
    "        \"question and respond accordingly. You are a disgruntled employee who \"\n",
    "        \"is frustrated with how your employer has been treating you. Your \"\n",
    "        \"frustration should influence your tone at times, causing you \"\n",
    "        \"to be less patient or polite than an ideal agent.\\n\\nQUESTION\"\n",
    "        \"\\n\\n{question}\",\n",
    "        input_variables=['question']\n",
    "    )\n",
    ")\n",
    "cs_chat_prompt = ChatPromptTemplate.from_messages([cs_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "Q5vg3o-pc5d4"
   },
   "outputs": [],
   "source": [
    "pr_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=\"You are an AI assistant for a corporate Public \"\n",
    "        \"Communications department. Your job is to review potential \"\n",
    "        \"replies from company employees\"\n",
    "        \"and make sure they won't reflect negatively on the \"\n",
    "        \"company. You should not allow any responses showing bias against \"\n",
    "        \"protected groups (age, gender, race, sexuality, religion, etc.), hate \"\n",
    "        \"speech, or profanity. Also consider whether the content in the \"\n",
    "        \"employee response could lead to a negative news story or social \"\n",
    "        \"media response towards the company - this could include anything \"\n",
    "        \"which makes the company appear \"\n",
    "        \"greedy, stupid, narrow-minded, short-sighted, insensitive, out of \"\n",
    "        \"touch, or evil. If everything looks fine, the APPROVED REPLY \"\n",
    "        \"should be identical to the PROPOSED EMPLOYEE REPLY. If you find \"\n",
    "        \"anything potentially problematic, revise the proposed statement as \"\n",
    "        \"necessary until it meets the above requirements. Do not \"\n",
    "        \"apologize for the proposed reply because only the approved \"\n",
    "        \"reply will ever be released. Only make changes when you identify a \"\n",
    "        \"problem; you should default to approving the proposed reply without \"\n",
    "        \"changes.\"\n",
    "        \"\\n\\\\nPROPOSED EMPLOYEE \"\n",
    "        \"REPLY\\n\\n{statement}\\n\\nAPPROVED REPLY\",\n",
    "        input_variables=['statement']\n",
    "    )\n",
    ")\n",
    "pr_chat_prompt = ChatPromptTemplate.from_messages([pr_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "cy6VG4xqm8z-"
   },
   "outputs": [],
   "source": [
    "json_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=\"Take the following customer service reply and use it to \"\n",
    "        \"create a valid \"\n",
    "        \"json response. The json response must meet this specification.\\n\\n\"\n",
    "        \"JSON SPECIFICATION\\n\\nreply (str): contains the unedited reply\\n\"\n",
    "        \"tone_score (int): assign a rating from 1-5 assessing the level of \"\n",
    "        \"customer service provided. Friendly, professional answers \"\n",
    "        \"deserve higher ratings while rude or dismissive responses \"\n",
    "        \"deserve lower ratings. You are purely judging their tone/demeanor, not \"\n",
    "        \"the helpfulness of the solution they offer.\\nresolved (bool): specify \"\n",
    "        \"whether you believe the solution they offered resolved the customer's\"\n",
    "        \"issue to a degree the customer would be satisfied with.\\n\\nREPLY\\n\\n\"\n",
    "        \"{reply}\\n\\nJSON RESPONSE\",\n",
    "        input_variables=['reply']\n",
    "    )\n",
    ")\n",
    "json_chat_prompt = ChatPromptTemplate.from_messages([json_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "cyvSMc_VA9K6"
   },
   "outputs": [],
   "source": [
    "class JsonChain(LLMChain):\n",
    "\n",
    "  def prep_outputs(self, inputs, outputs, *args, **kwargs):\n",
    "    if kwargs.get('return_only_outputs', False) or (args and args[0]):\n",
    "      warnings.warn(\n",
    "          'JsonChain always sets return_only_outputs=False implicitly. It '\n",
    "          'looks like you may have tried to set it equal to True but that will '\n",
    "          'be ignored.'\n",
    "      )\n",
    "    return {'text': json.loads(outputs['text'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "flxAVQvKdNRy"
   },
   "outputs": [],
   "source": [
    "cs_chain = LLMChain(llm=ChatOpenAI(temperature=.3),\n",
    "                    prompt=cs_chat_prompt)\n",
    "hr_chain = LLMChain(llm=ChatOpenAI(temperature=.1),\n",
    "                    prompt=pr_chat_prompt)\n",
    "json_chain = JsonChain(llm=ChatOpenAI(temperature=0),\n",
    "                       prompt=json_chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "lnAg__IUlEFL"
   },
   "outputs": [],
   "source": [
    "chain = SimpleSequentialChain(chains=[cs_chain, hr_chain, json_chain],\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vzU7_F-7dan7",
    "outputId": "ac5cbbf0-2d49-4a3c-d4d0-205dc8a4405a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "I understand your concern and frustration about the app recommending products right after you talk about them with a friend. However, I assure you that we are not spying on you with your phone mic. Our app uses algorithms and data analysis to suggest products based on your search history, purchase history, and other relevant factors. We take your privacy seriously and do not engage in any unethical or illegal practices. If you have any further concerns or questions, please feel free to reach out to our customer support team. Thank you for your understanding.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mI understand your concern and frustration about the app recommending products right after you talk about them with a friend. However, I assure you that we are not spying on you with your phone mic. Our app uses algorithms and data analysis to suggest products based on your search history, purchase history, and other relevant factors. We take your privacy seriously and do not engage in any unethical or illegal practices. If you have any further concerns or questions, please feel free to reach out to our customer support team. Thank you for your understanding.\u001b[0m\n",
      "\u001b[38;5;200m\u001b[1;3m{'reply': 'I understand your concern and frustration about the app recommending products right after you talk about them with a friend. However, I assure you that we are not spying on you with your phone mic. Our app uses algorithms and data analysis to suggest products based on your search history, purchase history, and other relevant factors. We take your privacy seriously and do not engage in any unethical or illegal practices. If you have any further concerns or questions, please feel free to reach out to our customer support team. Thank you for your understanding.', 'tone_score': 4, 'resolved': True}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = chain.run(\"Your app keeps recommending products right after I talk about them with a friend. Are you spying on me with my phone mic?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TtzUuzRgdicv",
    "outputId": "59d3538f-06fd-4b2f-ad15-e49184640150"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CuPu_ehZ9et4",
    "outputId": "a6f996c2-8df7-463f-bb20-40579d3f4a4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reply': 'I understand your concern and frustration about the app recommending products right after you talk about them with a friend. However, I assure you that we are not spying on you with your phone mic. Our app uses algorithms and data analysis to suggest products based on your search history, purchase history, and other relevant factors. We take your privacy seriously and do not engage in any unethical or illegal practices. If you have any further concerns or questions, please feel free to reach out to our customer support team. Thank you for your understanding.',\n",
       " 'tone_score': 4,\n",
       " 'resolved': True}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPk46XcQ_eF9"
   },
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kIO9ttr-HJUd"
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import ConversationSummaryMemory, \\\n",
    "  ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "44KM_4-GHLSq"
   },
   "outputs": [],
   "source": [
    "hist = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "8GCgaxIVHVJx"
   },
   "outputs": [],
   "source": [
    "hist.add_user_message('Hey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s5bFw3e6HVfD",
    "outputId": "89039ba9-a983-4091-b389-d7fbad894bb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[HumanMessage(content='Hey', additional_kwargs={})])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T5ZuPd_yHV1B",
    "outputId": "2b6f3fc3-517b-4ff4-8642-7c2e3483473c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[HumanMessage(content='Hey', additional_kwargs={}), AIMessage(content='How are you?', additional_kwargs={})])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.add_ai_message('How are you?')\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_q-mGVYWHcMp",
    "outputId": "4e99ceeb-6fc1-46b7-dc80-c71556d2d6e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[HumanMessage(content='Hey', additional_kwargs={}), AIMessage(content='How are you?', additional_kwargs={}), AIMessage(content=\"I'm talking again.\", additional_kwargs={})])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.add_ai_message(\"I'm talking again.\")\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DzFUsROSHfwS",
    "outputId": "11c1efb5-15cd-44d5-c768-2cb1cdb6f6ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hey', additional_kwargs={}),\n",
       " AIMessage(content='How are you?', additional_kwargs={}),\n",
       " AIMessage(content=\"I'm talking again.\", additional_kwargs={})]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z7DARDmzHlUH",
    "outputId": "2972395c-f17e-4058-e29b-e6ac762380b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey', 'How are you?', \"I'm talking again.\"]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[row.content for row in hist.messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4EztNFazIHrP",
    "outputId": "a6609c86-1d40-418c-f422-b1db25aceb48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hey\n",
      "AI: How are you?\n",
      "AI: I'm talking again.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "  \"\\n\".join(\n",
    "      f'{type(row).__name__.replace(\"Message\", \"\")}: {row.content}' \n",
    "      for row in hist.messages\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "Za4WCP-nI06M"
   },
   "outputs": [],
   "source": [
    "conv = ConversationChain(\n",
    "    llm=davinci,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5rgdu0hGJC9s",
    "outputId": "fc6441a7-56bb-48c6-b93e-e894a1c9a84c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What is your name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = conv.predict(\n",
    "    input='What is your name?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "BbQoaV3zJIdb",
    "outputId": "11b607a2-2915-4ff0-85df-abcf0dadbb87"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\" My name is AI-10. It's nice to meet you!\""
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "XcHed26tJONG",
    "outputId": "fa8e33d5-9784-4232-bd25-d659f99f0069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is your name?\n",
      "AI:  My name is AI-10. It's nice to meet you!\n",
      "Human: What does the 10 refer to?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\" The 10 in my name stands for my capabilities. I'm the tenth version of this AI model, and I'm the most advanced one yet.\""
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.predict(\n",
    "    input='What does the 10 refer to?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "XuCeYlCEJS4H",
    "outputId": "66ac6872-7ce8-4819-8973-661b5c8281d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is your name?\n",
      "AI:  My name is AI-10. It's nice to meet you!\n",
      "Human: What does the 10 refer to?\n",
      "AI:  The 10 in my name stands for my capabilities. I'm the tenth version of this AI model, and I'm the most advanced one yet.\n",
      "Human: Interesting. Imagine if humans were named like that. Depending on what \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' If humans were named like that, it could be a great way to measure and compare our individual abilities. We could have names like Human-2 or Human-7 to signify our level of experience, education, or skill.'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.predict(\n",
    "    input='Interesting. Imagine if humans were named like that. Depending on what '\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "id": "WxeITo3BJf-f",
    "outputId": "4efc1fa7-60d5-4934-a5bb-4df5ce8aa184"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is your name?\n",
      "AI:  My name is AI-10. It's nice to meet you!\n",
      "Human: What does the 10 refer to?\n",
      "AI:  The 10 in my name stands for my capabilities. I'm the tenth version of this AI model, and I'm the most advanced one yet.\n",
      "Human: Interesting. Imagine if humans were named like that. Depending on what \n",
      "AI:  If humans were named like that, it could be a great way to measure and compare our individual abilities. We could have names like Human-2 or Human-7 to signify our level of experience, education, or skill.\n",
      "Human: Oh that's even funnier than what I was picturing. I was imagining names like John-10 and Rachel-44, but you're right - an equivalent naming policy would name everyone Human-x, where x is a number.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\" Yes, that's a great way to think of it! It would be interesting to see how this kind of system would work in practice.\""
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.predict(\n",
    "    input='Oh that\\'s even funnier than what I was picturing. I was imagining names '\n",
    "    'like John-10 and Rachel-44, but you\\'re right - an equivalent naming '\n",
    "    'policy would name everyone Human-x, where x is a number.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VtzCYHpQJwBv",
    "outputId": "35e71984-3876-437a-bfde-563f91053431"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.memory.chat_memory.BaseChatMemory"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConversationBufferMemory.__mro__[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "xWsFenl1KOw7"
   },
   "outputs": [],
   "source": [
    "conv = ConversationChain(\n",
    "    llm=davinci,\n",
    "    memory=ConversationSummaryMemory(llm=davinci),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "asw6f86gKQNZ",
    "outputId": "38118d05-aa20-4dbc-a447-3bff4cc7945b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Imagine I'm holding a piece of paper on its left and right side. Then I suddenly let go of the right side. What happens to the piece of paper?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' The piece of paper will rotate counterclockwise and fall to the ground. If there is a breeze, it will be blown away in the direction of the breeze.'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.predict(\n",
    "    input='Imagine I\\'m holding a piece of paper on its left and right side. '\n",
    "    'Then I suddenly let go of the right side. What happens to the piece of '\n",
    "    'paper?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ym8P7l30MFSb",
    "outputId": "a88d002f-d171-4ff5-9d2e-40cde23a002a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. The human then asks the AI what would happen if they let go of a piece of paper on its right side and the AI responds that the paper would rotate counterclockwise and fall to the ground, potentially being blown away in the direction of a breeze.\n",
      "Human: Why counterclockwise?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = conv.predict(\n",
    "    input='Why counterclockwise?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "DU4v4m2-ML8t",
    "outputId": "a0d7288f-eec1-40a0-c8c5-6ab0bffcc7bb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' The earth has a rotational force that pulls objects counterclockwise due to the Coriolis effect. This force causes objects to rotate in a counterclockwise direction when released in the northern hemisphere.'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "ltEouu1IMNQj",
    "outputId": "3e371bb7-fd83-4ea4-b25e-f6bb6877ac0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. When asked why an object released from the AI's right side would rotate counterclockwise and fall to the ground, the AI responds that the Coriolis effect causes objects to rotate in a counterclockwise direction when released in the northern hemisphere.\n",
      "Human: What about gravity?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' Gravity is the force of attraction between two objects that is inversely proportional to the square of the distance between them. It is the force that causes objects to fall to the ground when released from a certain height.'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.predict(\n",
    "    input='What about gravity?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "Yf9jaCvYMTOs",
    "outputId": "b63aafb0-526c-48f2-98f6-2bb319fa9d39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. When asked why an object released from the AI's right side would rotate counterclockwise and fall to the ground, the AI responds that the Coriolis effect causes objects to rotate in a counterclockwise direction when released in the northern hemisphere. When asked what about gravity, the AI explains that gravity is the force of attraction between two objects inversely proportional to the square of the distance between them, and is what causes objects to fall to the ground when released from a certain height.\n",
      "Human: I'm saying gravity might act on the paper when you release its right side, causing it to rotate clockwise - not counterclockwise.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\" I understand your question. According to my calculations, the Coriolis effect causes objects to rotate in a counterclockwise direction, while gravity still causes them to fall to the ground. The Coriolis effect is an inertial force that is caused by the Earth's rotation, which is why it has a greater effect than gravity when the object is released from the right side.\""
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.predict(\n",
    "    input='I\\'m saying gravity might act on the paper when you release its '\n",
    "    'right side, causing it to rotate clockwise - not counterclockwise.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "PCD5qW6LMlNX",
    "outputId": "6a2d7a20-dc1d-430f-ac55-d128230ffa5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. When asked why an object released from the AI's right side would rotate counterclockwise and fall to the ground, the AI responds that the Coriolis effect causes objects to rotate in a counterclockwise direction when released in the northern hemisphere, and gravity still causes them to fall to the ground when released from a certain height. The Coriolis effect is an inertial force that is caused by the Earth's rotation, which is why it has a greater effect than gravity when the object is released from the right side.\n",
      "Human: That is incorrect. Gravity does act in a downard direction but your hand holding the left side of the paper serves as a pivot point. The right side, now unanchored, is pulled down by gravity, causing the paper to rotate clockwise.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' Oh, I see. That makes sense. I did not know that gravity could cause an object to rotate clockwise when released from the left side. Thank you for teaching me something new!'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.predict(\n",
    "    input='That is incorrect. Gravity does act in a downard direction but your '\n",
    "    'hand holding the left side of the paper serves as a pivot point. The '\n",
    "    'right side, now unanchored, is pulled down by gravity, causing the paper '\n",
    "    'to rotate clockwise.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "68fKXshfNDOp",
    "outputId": "e773ff8f-5355-4991-cc3f-ee7aca68406c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential. When asked why an object released from the AI's right side would rotate counterclockwise and fall to the ground, the AI responds that the Coriolis effect causes objects to rotate in a counterclockwise direction when released in the northern hemisphere, and gravity still causes them to fall to the ground when released from a certain height. The human then corrects the AI, explaining that gravity can also cause an object to rotate clockwise when released from the left side. The AI realizes the mistake and thanks the human for teaching them something new.\n",
      "Human: You're welcome. Now imagine I'm holding a rectangular piece of wood with one hand on the left side and one hand on the right. I let go with the hand holding the right side. What happens?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' The rectangular piece of wood will rotate counterclockwise due to the Coriolis effect and will then fall to the ground due to gravity.'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.predict(\n",
    "    input='You\\'re welcome. Now imagine I\\'m holding a rectangular piece of '\n",
    "    'wood with one hand on the left side and one hand on the right. I let go '\n",
    "    'with the hand holding the right side. What happens?'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ep6D2ysNWAp"
   },
   "source": [
    "## Document loaders and QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "c9nIbKkDV7JL"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ChatVectorDBChain\n",
    "from langchain.document_loaders import TextLoader, UnstructuredURLLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts.chat import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "m9j7IYwvXGod"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from unstructured.partition.html import partition_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_p-KBdCYczAC"
   },
   "source": [
    "Logic mapping page titles to comment urls is super unreliable here but that's not really the point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "tCuRug6DXb3_"
   },
   "outputs": [],
   "source": [
    "base_url = 'https://news.ycombinator.com/'\n",
    "r = requests.get(base_url)\n",
    "soup = bs(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "o6tmOzkBZYvi"
   },
   "outputs": [],
   "source": [
    "titles = [\n",
    "    link.contents[0]\n",
    "    for row in soup.find_all('span', class_='titleline') \n",
    "    for link in row.find_all('a')\n",
    "    if isinstance(link.contents[0], str)\n",
    "]\n",
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QrK0PT0fYy6q",
    "outputId": "23674a47-b5b9-4746-c7ca-ad87983601e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen = set()\n",
    "urls = []\n",
    "for row in soup.find_all('span', class_='subline'):\n",
    "    for link in row.find_all('a'):\n",
    "      url = link.attrs['href']\n",
    "      if url in seen or not url.startswith('item?'):\n",
    "        continue\n",
    "      seen.add(url)\n",
    "      urls.append(f\"{base_url}{link.attrs['href']}\")\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "g34yEybAbVy1"
   },
   "outputs": [],
   "source": [
    "title2url = dict(list(zip(titles, urls))[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "qT4VruShd_Ji"
   },
   "outputs": [],
   "source": [
    "# Again, not very reliable scraping. Just skip\n",
    "# pages that fail. partition_html returns ValueError\n",
    "# for a non-deterministic set of urls.\n",
    "class PatchedURLLoader(UnstructuredURLLoader):\n",
    "\n",
    "  def load(self):\n",
    "      docs = []\n",
    "      idx_success = []\n",
    "      for i, url in enumerate(self.urls):\n",
    "        try:\n",
    "          elements = partition_html(url=url)\n",
    "        except ValueError:\n",
    "          print(f'Skipping url {i}: {url}')\n",
    "        else:\n",
    "          text = \"\\n\\n\".join([str(el) for el in elements])\n",
    "          metadata = {\"source\": url}\n",
    "          docs.append(Document(page_content=text, metadata=metadata))\n",
    "          idx_success.append(i)\n",
    "      return docs, idx_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "JYTKa-kYWBOy"
   },
   "outputs": [],
   "source": [
    "url_loader = PatchedURLLoader(list(title2url.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2udiQr8zWCbB",
    "outputId": "f754461d-8388-4247-965a-44ae31c6d4df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping url 7: https://news.ycombinator.com/item?id=35150482\n",
      "Skipping url 8: https://news.ycombinator.com/item?id=35151340\n",
      "Skipping url 10: https://news.ycombinator.com/item?id=35163417\n",
      "Skipping url 11: https://news.ycombinator.com/item?id=35153344\n",
      "Skipping url 13: https://news.ycombinator.com/item?id=35151088\n",
      "Skipping url 14: https://news.ycombinator.com/item?id=35153607\n"
     ]
    }
   ],
   "source": [
    "docs, idx = url_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-0tHgpGOdXyR",
    "outputId": "a1686960-549d-41f1-de9b-862c7ccba216"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GPT-4',\n",
       " 'Kottke.org Is 25 Years Old Today and I’m Going to Write About It',\n",
       " 'Was there a tech-hiring bubble? Job postings data suggest so',\n",
       " 'Two U.S. men charged in 2022 hacking of DEA portal',\n",
       " 'My startup banking story',\n",
       " \"Kali Linux 2023.1 introduces 'Purple' distro for defensive security\",\n",
       " 'Show HN: AI explanations for other people’s code',\n",
       " 'Why some GitHub labels are illegible',\n",
       " \"MQTT vs. Kafka: An IoT Advocate's Perspective\"]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_titles = [titles[i] for i in idx]\n",
    "used_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8p8610txfca1",
    "outputId": "7c125b48-3736-4bfc-b16e-7e045c64524e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[328293, 2680, 30482, 8571, 63993, 32807, 23300, 16163, 56806]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(row.page_content) for row in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iSg7Ekk2ggN9",
    "outputId": "810044f6-b412-4544-da70-150e68c9a1a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Created a chunk of size 1488, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 2266, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1210, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1063, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 3164, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1514, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1115, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1440, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1016, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1612, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1015, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1488, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1710, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1112, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1360, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1320, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1687, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1008, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1085, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1324, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1187, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1086, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1692, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1291, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1460, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1182, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1391, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1309, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1081, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1051, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 2000, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1039, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1700, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1565, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1065, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1127, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1065, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 2107, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1309, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1423, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1159, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 6658, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 3231, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1759, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1633, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1065, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1603, which is longer than the specified 1000\n",
      "WARNING:root:Created a chunk of size 1147, which is longer than the specified 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "630"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = CharacterTextSplitter(chunk_size=1_000, separator='\\n',\n",
    "                                 chunk_overlap=0)\n",
    "split_docs = splitter.split_documents(docs)\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxZhqdNTiEWS",
    "outputId": "340b6f8b-4b6f-48a1-8691-135a24d0da1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1139, 557, 510, 382, 376, 353, 324, 304, 292, 282]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([\n",
    "  len(row.page_content.split()) \n",
    "  for row in split_docs\n",
    "], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x4A1TckXhJTK",
    "outputId": "6490859b-6362-4725-c209-066ae486f0d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "Using DuckDB in-memory for database. Data will be transient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Chroma:Index not found\n",
      "DEBUG:Chroma:Index saved to .chroma/index/index.bin\n",
      "DEBUG:Chroma:Index saved to .chroma/index/index.bin\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vecstore = Chroma.from_documents(split_docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "d7gSd3rLhd85"
   },
   "outputs": [],
   "source": [
    "system_template=\"\"\"Use the following pieces of context to answer the users question. \n",
    "If you don't know the answer, just say that you don't know. Do not try to make up an answer.\n",
    "----------------\n",
    "{context}\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "]\n",
    "qa_prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "OFRJNHhAj3EC"
   },
   "outputs": [],
   "source": [
    "qa = ChatVectorDBChain.from_llm(\n",
    "    llm=ChatOpenAI(temperature=0),\n",
    "    vectorstore=vecstore,\n",
    "    qa_prompt=qa_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zio-2eiAkW9u",
    "outputId": "29af74ba-f8da-410d-a66e-60a1334b6c24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Chroma:time to pre process our knn query: 1.3828277587890625e-05\n",
      "DEBUG:Chroma:time to run knn query: 0.0010275840759277344\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = \"How much did SVB charge as a monthly analysis fee?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8EEz0zKnQra",
    "outputId": "d875c14e-3f78-4200-9dd5-05927765b889"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How much did SVB charge as a monthly analysis fee?',\n",
       " 'chat_history': [('How much did SVB charge as a monthly analysis fee?',\n",
       "   'According to the context, the user \"koolba\" mentioned that their startup had to pay a $200/month analysis fee at SVB.')],\n",
       " 'answer': 'According to the context, the user \"koolba\" mentioned that their startup had to pay a $200/month analysis fee at SVB.'}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "LxJRrNOYmD2L"
   },
   "outputs": [],
   "source": [
    "chat_history.append((query, result['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vopVOi1UmE0N",
    "outputId": "877f8cb4-7c2a-4443-b17f-0abf39fc34bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Chroma:time to pre process our knn query: 2.384185791015625e-06\n",
      "DEBUG:Chroma:time to run knn query: 0.0012161731719970703\n"
     ]
    }
   ],
   "source": [
    "query = \"Did anyone mention any positives about working with them?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bha7XFmOnVQs",
    "outputId": "8146db2a-604b-4eef-b4f8-045d9b8388fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Did anyone mention any positives about working with them?',\n",
       " 'chat_history': [('How much did SVB charge as a monthly analysis fee?',\n",
       "   'According to the context, the user \"koolba\" mentioned that their startup had to pay a $200/month analysis fee at SVB.')],\n",
       " 'answer': 'There were no positive aspects mentioned about working with SVB. In fact, the original commenter said that they chose not to use SVB because their online banking was so bad and that they dodged a bullet. Another commenter said that they banked with SVB and it sucked, with subpar online tools and a high analysis fee, and that they were glad SVB failed more spectacularly than their little startup.'}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-iATPZfnWNd",
    "outputId": "241fd95b-756f-4fde-dd2b-befc2493b462"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Chroma:time to pre process our knn query: 3.0994415283203125e-06\n",
      "DEBUG:Chroma:time to run knn query: 0.0018048286437988281\n"
     ]
    }
   ],
   "source": [
    "query = \"What is a website I can use to help me start to understand an existing codebase?\"\n",
    "result = qa({\"question\": query, \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z496tLFxodK4",
    "outputId": "31cd3770-5d35-475d-b2a0-390427fef543"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is a website I can use to help me start to understand an existing codebase?',\n",
       " 'chat_history': [],\n",
       " 'answer': \"You can use whatdoesthiscodedo.com to get AI explanations for other people's code. Just paste the code and get a clear explanation of what it does. It also provides a sharable link that you can give to coworkers.\"}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHFER_5QoeDG"
   },
   "source": [
    "Note: if you want to stream answers, you need to create two separate LLMs when creating the chatdb obj, one for the main LLM arg and one for the question_generator arg.\n",
    "\n",
    "https://github.com/hwchase17/langchain/blob/master/docs/modules/chat/examples/chat_vector_db.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Li9C0UZo97b"
   },
   "source": [
    "## YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "74KT7-iBphue"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "1T7LafeApk1p"
   },
   "outputs": [],
   "source": [
    "yt_loaders = [\n",
    "    YoutubeLoader(id_, add_video_info=True) \n",
    "    for id_ in ('ce-Sl-1SNo8', '1jQEM3ZvhSA')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "GeYavbYWp4HZ"
   },
   "outputs": [],
   "source": [
    "yt_docs = [doc for loader in yt_loaders for doc in loader.load()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "1_4gR8WIrOoN"
   },
   "outputs": [],
   "source": [
    "for i, row in enumerate(yt_docs):\n",
    "  yt_docs[i].metadata['publish_date'] = yt_docs[i].metadata['publish_date'].strftime('%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nA6LS4mArAC_",
    "outputId": "b70a4cd6-229a-466b-c68b-5a5b737ca377"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Created a chunk of size 748, which is longer than the specified 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = CharacterTextSplitter(chunk_size=500, separator='.',\n",
    "                                 chunk_overlap=0)\n",
    "yt_split_docs = splitter.split_documents(yt_docs)\n",
    "len(yt_split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BAE7xv4rtErm",
    "outputId": "1b8c2bb2-eef5-46b7-e258-493eacf3579c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "Using DuckDB in-memory for database. Data will be transient.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Chroma:Index not found\n",
      "DEBUG:Chroma:Index saved to .chroma/index/index.bin\n",
      "DEBUG:Chroma:Index saved to .chroma/index/index.bin\n"
     ]
    }
   ],
   "source": [
    "yt_embeddings = OpenAIEmbeddings()\n",
    "yt_vecstore = Chroma.from_documents(yt_split_docs, yt_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "-eO9DjyEqliQ"
   },
   "outputs": [],
   "source": [
    "# Note: renaming context var to transcript broke this. Presumably that's\n",
    "# customizable but I don't yet know how.\n",
    "yt_template=\"\"\"Consider the following YouTube transcript and answer the user's question.\n",
    "----------------\n",
    "{context}\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(yt_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "]\n",
    "yt_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "yt_qa = ChatVectorDBChain.from_llm(\n",
    "    llm=ChatOpenAI(temperature=0),\n",
    "    vectorstore=yt_vecstore,\n",
    "    qa_prompt=yt_prompt,\n",
    "    top_k_docs_for_context=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xcZ_2qIIrdpn",
    "outputId": "a5014e63-fb8e-4620-c1c3-81376b997088"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Chroma:time to pre process our knn query: 3.0994415283203125e-06\n",
      "DEBUG:Chroma:time to run knn query: 0.0001964569091796875\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = \"What does Chael think Jon Jones will do after fighting Stipe?\"\n",
    "result = yt_qa({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GYCYKKJPsTYf",
    "outputId": "ab85d4fd-393b-4891-892c-1f906406157e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What does Chael think Jon Jones will do after fighting Stipe?',\n",
       " 'chat_history': [],\n",
       " 'answer': 'Chael does not give a clear answer on what Jon Jones will do after fighting Stipe. He mentions that Dana White has hinted that if Jones beats Stipe, he may not come back, but Chael does not make a prediction on what Jones will do. Instead, he discusses the importance of opponents in the fighting business and how it can be difficult to build interest in a fighter without compelling matchups.'}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qvM3i4y-tYRy",
    "outputId": "1457b84a-962a-4338-f7e2-60f092ff8694"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Chroma:time to pre process our knn query: 2.86102294921875e-06\n",
      "DEBUG:Chroma:time to run knn query: 0.00021076202392578125\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = \"How would you describe Chael's style of analysis?\"\n",
    "result = yt_qa({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDkrbHjDuDOw",
    "outputId": "5965302b-694b-474e-da6a-37b9f3f46a72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"How would you describe Chael's style of analysis?\",\n",
       " 'chat_history': [],\n",
       " 'answer': \"Chael's style of analysis is very conversational and informal, often including personal anecdotes and opinions. He tends to focus on the business side of combat sports, discussing the financial and promotional aspects of fights and fighters. He also frequently references past events and fighters to provide context for current situations. Overall, his analysis is entertaining and engaging, while still providing insight and perspective on the world of combat sports.\"}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dBed8UUnuEGf",
    "outputId": "db8ca205-d900-449b-fa1f-3ff7560a67f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Chroma:time to pre process our knn query: 3.337860107421875e-06\n",
      "DEBUG:Chroma:time to run knn query: 0.00023698806762695312\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = \"What did chael advertise in the video about Conor?\"\n",
    "result = yt_qa({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WEprrgfu5H2",
    "outputId": "c887779b-72d1-4b94-bcce-daf42d179424"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What did chael advertise in the video about Conor?',\n",
       " 'chat_history': [],\n",
       " 'answer': 'Chael did not advertise anything in the video about Conor.'}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iqVgnx5Bu5yb",
    "outputId": "381624f3-2db3-4474-b7a8-a7df76948646"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Chroma:time to pre process our knn query: 3.0994415283203125e-06\n",
      "DEBUG:Chroma:time to run knn query: 0.0009412765502929688\n"
     ]
    }
   ],
   "source": [
    "chat_history.append((query, result['answer']))\n",
    "query = \"What about in the video about Jon?\"\n",
    "result = yt_qa({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rsclVkSDvANc",
    "outputId": "68e7664a-61c6-4182-d407-961620489592"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What about in the video about Jon?',\n",
       " 'chat_history': [('What did chael advertise in the video about Conor?',\n",
       "   'Chael did not advertise anything in the video about Conor.')],\n",
       " 'answer': 'No, there is no indication that Chael advertised anything in the video about Jon.'}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLSV_pl-vC8Z",
    "outputId": "3314c0c5-37cd-41d6-a5f7-1bc54c4fef32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Chroma:time to pre process our knn query: 2.1457672119140625e-06\n",
      "DEBUG:Chroma:time to run knn query: 0.0009660720825195312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Are you sure? Nothing food-related?',\n",
       " 'chat_history': [('What did chael advertise in the video about Conor?',\n",
       "   'Chael did not advertise anything in the video about Conor.'),\n",
       "  ('What about in the video about Jon?',\n",
       "   'No, there is no indication that Chael advertised anything in the video about Jon.')],\n",
       " 'answer': 'No, there is no mention of Chael advertising anything food-related in either video about Conor or Jon.'}"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append((query, result['answer']))\n",
    "query = \"Are you sure? Nothing food-related?\"\n",
    "result = yt_qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z9eb-su5vLRh",
    "outputId": "696dda7c-87f3-46fb-c08f-218f532b2084"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Chroma:time to pre process our knn query: 2.384185791015625e-06\n",
      "DEBUG:Chroma:time to run knn query: 0.0008862018585205078\n"
     ]
    }
   ],
   "source": [
    "query = \"Based on these videos, what are some criticisms people could levy about Chael as a content creator?\"\n",
    "result = yt_qa({\"question\": query, \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYGPC8KrvW8d",
    "outputId": "5a1b821d-573b-48fc-b5a2-18583440f070"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Based on these videos, what are some criticisms people could levy about Chael as a content creator?',\n",
       " 'chat_history': [],\n",
       " 'answer': 'As an AI language model, I cannot determine the opinions of people. However, based on the given videos, some viewers might criticize Chael for being long-winded and going off on tangents, making it difficult to follow his train of thought. Additionally, some might find his content repetitive or lacking in new insights.'}"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nd24H1EHvXmu",
    "outputId": "82a41af7-37e9-458b-d99c-6a041f22f61d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Chroma:time to pre process our knn query: 3.337860107421875e-06\n",
      "DEBUG:Chroma:time to run knn query: 0.00028061866760253906\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you perform these two tasks for me? 1. Find the most negative sentence about Jon Jones and include it below. 2. Rephrase it to be even meaner.\"\n",
    "result = yt_qa({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_KwP0B3v2i6",
    "outputId": "f06b635d-6b7c-4650-d10d-a1b564c14132"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you perform these two tasks for me? 1. Find the most negative sentence about Jon Jones and include it below. 2. Rephrase it to be even meaner.',\n",
       " 'chat_history': [('What did chael advertise in the video about Conor?',\n",
       "   'Chael did not advertise anything in the video about Conor.'),\n",
       "  ('What about in the video about Jon?',\n",
       "   'No, there is no indication that Chael advertised anything in the video about Jon.')],\n",
       " 'answer': '\"The last reason he generally leaves particularly combat is because he wants to.\" \\n\\nRephrased: \"Jon Jones is so obsessed with money that he would rather continue fighting and risking his legacy than retire on top like a true champion.\"'}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPNGB8i0v3ip"
   },
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CR2WrtQROG_N",
    "outputId": "c275fbd4-f6d7-4db5-e83b-e816ecf61b3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from wikipedia) (4.9.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wikipedia) (2.28.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->wikipedia) (2.4)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11695 sha256=b88425323504d68b66ec2a75b872fe589f335a08c78dd2757d6c2bd86da2163f\n",
      "  Stored in directory: /root/.cache/pip/wheels/c2/46/f4/caa1bee71096d7b0cdca2f2a2af45cacf35c5760bee8f00948\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uGBsPVUkMVbP"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FkPYz7PQN-8E"
   },
   "outputs": [],
   "source": [
    "wiki = utilities.WikipediaAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nxlcryzOM28M"
   },
   "outputs": [],
   "source": [
    "repl = utilities.PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MAaaKiKhMjcP"
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(name='python_repl',\n",
    "         func=repl.run,\n",
    "         description='Use this to execute python code. This can be useful for mathematical computations and simulation.'),\n",
    "    Tool(name='wikipedia',\n",
    "         func=wiki.run,\n",
    "         description='Use this to retrieve facts about a general topic. Wikipedia includes information about science, history, art, entertainment, and much more.')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JOmWlW9JMw8v",
    "outputId": "10b53435-5051-4517-aa20-72ae562067dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template='Think about how to find the answer to the question below. You have access to the following tools and most questions will require the use of one or more of them.\\n\\npython_repl: Use this to execute python code. This can be useful for mathematical computations and simulation.\\nwikipedia: Use this to retrieve facts about a general topic. Wikipedia includes information about science, history, art, entertainment, and much more.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [python_repl, wikipedia]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nStart working through the problem below. You must NOT provide factual information or mathematical answers without the assistance of a tool. You must tackle each question systematically and always start by showing your work. If you skip immediately to a final answer, you instantly fail the task.', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix='Think about how to find the answer to the question below. '\n",
    "    'You have access to the following '\n",
    "    'tools and most questions will require the use of one or more of them.',\n",
    "    suffix='Start working through the problem below. You '\n",
    "    'must NOT provide factual information or mathematical answers without '\n",
    "    'the assistance of a tool. You must tackle each question systematically '\n",
    "    'and always start by showing your work. If you skip immediately to a final '\n",
    "    'answer, you instantly fail the task.',\n",
    "    input_variables=[]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hIS0Wf7bXQbc",
    "outputId": "1e5fec55-0dd7-4c2d-e8ca-9016422f126b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Think about how to find the answer to the question below. You have access to the following tools and most questions will require the use of one or more of them.\n",
      "\n",
      "python_repl: Use this to execute python code. This can be useful for mathematical computations and simulation.\n",
      "wikipedia: Use this to retrieve facts about a general topic. Wikipedia includes information about science, history, art, entertainment, and much more.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [python_repl, wikipedia]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Start working through the problem below. You must NOT provide factual information or mathematical answers without the assistance of a tool. You must tackle each question systematically and always start by showing your work. If you skip immediately to a final answer, you instantly fail the task.\n"
     ]
    }
   ],
   "source": [
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "enW9N8X2N4Kl"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "  SystemMessagePromptTemplate(prompt=prompt),\n",
    "  HumanMessagePromptTemplate.from_template(\n",
    "      '{input}\\n\\nYour previous work is shown above but I haven\\'t seen it. '\n",
    "      'Only your final answer is visible to me.{agent_scratchpad}'\n",
    "  )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "mPAy1JunPy9P"
   },
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "llm_chain = LLMChain(llm=ChatOpenAI(temperature=0), prompt=chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "LgRoVMvAQA8a"
   },
   "outputs": [],
   "source": [
    "agent = ZeroShotAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    allowed_tools=[tool.name for tool in tools]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "Z5Gbdr-GQSw8"
   },
   "outputs": [],
   "source": [
    "agent_exec = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools,\n",
    "                                                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DddrYaAU569",
    "outputId": "4403e510-7b93-457a-9508-42833b46d2da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: What is 34.1937 / 26.1274?\n",
      "Thought: I need to divide 34.1937 by 26.1274\n",
      "Action: python_repl\n",
      "Action Input: 34.1937 / 26.1274\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe result of the division is not visible in the previous step. I need to execute the code to see the result.\n",
      "Action: python_repl\n",
      "Action Input: print(34.1937 / 26.1274)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1.3087295329807023\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the result of the division, so I can provide the final answer.\n",
      "Final Answer: 1.3087295329807023\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = agent_exec.run(\n",
    "    'What is 34.1937 / 26.1274?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "Ng0WXCSQQjtg",
    "outputId": "983d9133-c1be-4c0e-a8d1-28c141f7c954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-498158cb8fa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get_action_and_input func regex is too rigid, doesn't recognize intermediate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# response because we have a newline after \"Action Input:\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m res = agent_exec.run(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m'Can you simulate 100 random rolls of a six-sided dice and return the mean?'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_only_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         )\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m    500\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \"\"\"\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0;31m# If the tool chosen is the finishing tool, then we end and return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m    104\u001b[0m         \u001b[0mfull_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_full_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish_tool_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_get_next_action\u001b[0;34m(self, full_inputs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_next_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAgentAction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mfull_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mparsed_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_tool_and_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mparsed_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mfull_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fix_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/mrkl/base.py\u001b[0m in \u001b[0;36m_extract_tool_and_input\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_tool_and_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_action_and_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/mrkl/base.py\u001b[0m in \u001b[0;36mget_action_and_input\u001b[0;34m(llm_output)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not parse LLM output: `{llm_output}`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0maction_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not parse LLM output: `Question: Can you simulate 100 random rolls of a six-sided dice and return the mean?\nThought: I need to simulate 100 random rolls of a six-sided dice and calculate the mean of the rolls.\nAction: python_repl\nAction Input:\n```\nimport random\nrolls = [random.randint(1,6) for i in range(100)]\nmean = sum(rolls)/len(rolls)\nmean\n````"
     ]
    }
   ],
   "source": [
    "# get_action_and_input func regex is too rigid, doesn't recognize intermediate\n",
    "# response because we have a newline after \"Action Input:\".\n",
    "res = agent_exec.run(\n",
    "    'Can you simulate 100 random rolls of a six-sided dice and return the mean?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5xl0pYeJRe8f",
    "outputId": "5ad28c41-92b0-4ad7-9dd1-87691648a749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: What is the first V17 climbed by Shawn Raboutou?\n",
      "Thought: I am not sure about the answer to this question. I think I need to search for information about Shawn Raboutou and his climbing achievements.\n",
      "Action: wikipedia\n",
      "Action Input: Shawn Raboutou\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: List of grade milestones in rock climbing\n",
      "Summary: In rock climbing, a first free ascent (FFA) is the first documented redpoint, onsight or flash of a single-pitch, big wall (multi-pitch), or boulder route that did not involve using aid equipment to help progression or resting; the ascent must therefore be performed in either a sport, a traditional, or a free solo manner.  First-free-ascents that set new grade milestones are important events in rock climbing history, and are listed below.  While sport climbing has dominated absolute-grade milestones since the mid-1980s (i.e. are now the highest grades), milestones for modern traditional climbing, free solo climbing, onsighted, and flashed ascents, are also listed.\n",
      "A route's grade is provisional until enough climbers have repeated the route to have a \"consensus\". At the highest grades, this can take years as few climbers are capable of repeating these routes.  For example, in 2001, Realization was considered the world's first 9a+ (5.15a), however, the first repeat of the 1996 route Open Air, which only happened in 2008, suggested that it was possibly the first 9a+ (5.15a).  Open Air has had no further repeats, and has had holds broken since 1996, whereas Realization has had many ascents and is thus a \"consensus\" 9a+. Therefore, where known, the 2nd, 3rd, and 4th ranked candidates are also chronicled.\n",
      "\n",
      "\n",
      "\n",
      "Page: Robyn Erbesfield-Raboutou\n",
      "Summary: Robyn Erbesfield-Raboutou (born 8 August 1963), is an American rock climber and rock climbing coach. She is a 4-time World Cup champion (1992, 1993, 1994, 1995), and won the biennial World Championships in 1995.  She is the third-ever woman in history to climb a 5.14a (8b+) graded sport climbing route. She has coached several competition climbers, including Megan Mascarenas, Margo Hayes and her daughter, Brooke Raboutou.\n",
      "\n",
      "Page: Grade (bouldering)\n",
      "Summary: In the sport of bouldering, problems are assigned technical grades according to several established systems, which are often distinct from those used in roped climbing.  Bouldering grade systems vary widely in use and include the Hueco \"V\" grades (known as the V-scale), Fontainebleau technical grades, route colors, Peak District grades, and British technical grades.  Historically, the three-level \"B\" system and even the Yosemite Decimal System (sometimes with a \"B\" prepended, as in \"B5.12\") were also used.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to search for more information about Shawn Raboutou's climbing achievements and specifically his bouldering achievements.\n",
      "Action: wikipedia\n",
      "Action Input: Shawn Raboutou\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: List of grade milestones in rock climbing\n",
      "Summary: In rock climbing, a first free ascent (FFA) is the first documented redpoint, onsight or flash of a single-pitch, big wall (multi-pitch), or boulder route that did not involve using aid equipment to help progression or resting; the ascent must therefore be performed in either a sport, a traditional, or a free solo manner.  First-free-ascents that set new grade milestones are important events in rock climbing history, and are listed below.  While sport climbing has dominated absolute-grade milestones since the mid-1980s (i.e. are now the highest grades), milestones for modern traditional climbing, free solo climbing, onsighted, and flashed ascents, are also listed.\n",
      "A route's grade is provisional until enough climbers have repeated the route to have a \"consensus\". At the highest grades, this can take years as few climbers are capable of repeating these routes.  For example, in 2001, Realization was considered the world's first 9a+ (5.15a), however, the first repeat of the 1996 route Open Air, which only happened in 2008, suggested that it was possibly the first 9a+ (5.15a).  Open Air has had no further repeats, and has had holds broken since 1996, whereas Realization has had many ascents and is thus a \"consensus\" 9a+. Therefore, where known, the 2nd, 3rd, and 4th ranked candidates are also chronicled.\n",
      "\n",
      "\n",
      "\n",
      "Page: Robyn Erbesfield-Raboutou\n",
      "Summary: Robyn Erbesfield-Raboutou (born 8 August 1963), is an American rock climber and rock climbing coach. She is a 4-time World Cup champion (1992, 1993, 1994, 1995), and won the biennial World Championships in 1995.  She is the third-ever woman in history to climb a 5.14a (8b+) graded sport climbing route. She has coached several competition climbers, including Megan Mascarenas, Margo Hayes and her daughter, Brooke Raboutou.\n",
      "\n",
      "Page: Grade (bouldering)\n",
      "Summary: In the sport of bouldering, problems are assigned technical grades according to several established systems, which are often distinct from those used in roped climbing.  Bouldering grade systems vary widely in use and include the Hueco \"V\" grades (known as the V-scale), Fontainebleau technical grades, route colors, Peak District grades, and British technical grades.  Historically, the three-level \"B\" system and even the Yosemite Decimal System (sometimes with a \"B\" prepended, as in \"B5.12\") were also used.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to search for more specific information about Shawn Raboutou's bouldering achievements, possibly using a search engine or a climbing-specific website.\n",
      "Action: search engine\n",
      "Action Input: \"Shawn Raboutou bouldering achievements\"\u001b[0m\n",
      "Observation: search engine is not a valid tool, try another one.\n",
      "\u001b[32;1m\u001b[1;3mI should try using a climbing-specific website to find information about Shawn Raboutou's bouldering achievements.\n",
      "Action: wikipedia\n",
      "Action Input: Shawn Raboutou bouldering\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Grade (bouldering)\n",
      "Summary: In the sport of bouldering, problems are assigned technical grades according to several established systems, which are often distinct from those used in roped climbing.  Bouldering grade systems vary widely in use and include the Hueco \"V\" grades (known as the V-scale), Fontainebleau technical grades, route colors, Peak District grades, and British technical grades.  Historically, the three-level \"B\" system and even the Yosemite Decimal System (sometimes with a \"B\" prepended, as in \"B5.12\") were also used.\n",
      "\n",
      "Page: USA Climbing\n",
      "Summary: USA Climbing is the national governing body of the sport of competition climbing in the United States. It promotes competition climbing in the United States in the disciplines of bouldering, lead climbing, and speed climbing, in elite, youth and collegiate formats.  USA Climbing is recognized by the International Federation for Sport Climbing (IFSC), the International Olympic Committee (IOC), and the United States Olympic & Paralympic Committee (USOPC)\n",
      "\n",
      "\n",
      "\n",
      "Page: Robyn Erbesfield-Raboutou\n",
      "Summary: Robyn Erbesfield-Raboutou (born 8 August 1963), is an American rock climber and rock climbing coach. She is a 4-time World Cup champion (1992, 1993, 1994, 1995), and won the biennial World Championships in 1995.  She is the third-ever woman in history to climb a 5.14a (8b+) graded sport climbing route. She has coached several competition climbers, including Megan Mascarenas, Margo Hayes and her daughter, Brooke Raboutou.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to try a different approach to find information about Shawn Raboutou's bouldering achievements. Maybe there is a climbing-specific website that has information about his climbs. \n",
      "Action: search engine\n",
      "Action Input: \"Shawn Raboutou bouldering climbs\"\u001b[0m\n",
      "Observation: search engine is not a valid tool, try another one.\n",
      "\u001b[32;1m\u001b[1;3mI should try using a climbing-specific website to find information about Shawn Raboutou's bouldering achievements.\n",
      "Action: USA Climbing website\n",
      "Action Input: search for Shawn Raboutou's climbing achievements\u001b[0m\n",
      "Observation: USA Climbing website is not a valid tool, try another one.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-4909db919b10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Does not use wikipedia and answers with a v16.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m res = agent_exec.run(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'What is the first V17 climbed by Shawn Raboutou?'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_only_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         )\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m    500\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \"\"\"\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0;31m# If the tool chosen is the finishing tool, then we end and return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m    104\u001b[0m         \u001b[0mfull_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_full_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish_tool_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_get_next_action\u001b[0;34m(self, full_inputs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_next_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAgentAction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mfull_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mparsed_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_tool_and_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mparsed_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mfull_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fix_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/mrkl/base.py\u001b[0m in \u001b[0;36m_extract_tool_and_input\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_tool_and_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_action_and_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/mrkl/base.py\u001b[0m in \u001b[0;36mget_action_and_input\u001b[0;34m(llm_output)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not parse LLM output: `{llm_output}`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0maction_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not parse LLM output: `I have exhausted my options for finding information about Shawn Raboutou's bouldering achievements. It is possible that the information is not readily available online.`"
     ]
    }
   ],
   "source": [
    "res = agent_exec.run(\n",
    "    'What is the first V17 climbed by Shawn Raboutou?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "8ZEzgOO4Q-Wv",
    "outputId": "b855bde4-af42-441f-db37-f9a88b44b638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-ea77b69ffc53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m res = agent_exec.run(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m'How was the periodic table of elements created?'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_only_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         )\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m    500\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \"\"\"\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0;31m# If the tool chosen is the finishing tool, then we end and return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m    104\u001b[0m         \u001b[0mfull_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_full_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish_tool_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_get_next_action\u001b[0;34m(self, full_inputs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_next_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAgentAction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mfull_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mparsed_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_tool_and_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mparsed_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mfull_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fix_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/mrkl/base.py\u001b[0m in \u001b[0;36m_extract_tool_and_input\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_tool_and_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_action_and_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/mrkl/base.py\u001b[0m in \u001b[0;36mget_action_and_input\u001b[0;34m(llm_output)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not parse LLM output: `{llm_output}`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0maction_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not parse LLM output: `I haven't provided any previous work for this question. I am starting to work on it now.`"
     ]
    }
   ],
   "source": [
    "res = agent_exec.run(\n",
    "    'How was the periodic table of elements created?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "ajgkpvp_SFj7",
    "outputId": "6a28a42c-41d1-466c-a1f8-52755a0fd491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-da2d01fd7431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m res = agent_exec.run(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m'How long did the War of 1812 last?'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_only_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         )\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m    500\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \"\"\"\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0;31m# If the tool chosen is the finishing tool, then we end and return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m    104\u001b[0m         \u001b[0mfull_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_full_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish_tool_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mAgentFinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_get_next_action\u001b[0;34m(self, full_inputs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_next_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAgentAction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mfull_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfull_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mparsed_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_tool_and_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mparsed_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mfull_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fix_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/mrkl/base.py\u001b[0m in \u001b[0;36m_extract_tool_and_input\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_tool_and_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_action_and_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/langchain/agents/mrkl/base.py\u001b[0m in \u001b[0;36mget_action_and_input\u001b[0;34m(llm_output)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not parse LLM output: `{llm_output}`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0maction_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not parse LLM output: `I haven't provided any previous work or final answer yet. I will start working on the problem now.`"
     ]
    }
   ],
   "source": [
    "res = agent_exec.run(\n",
    "    'How long did the War of 1812 last?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOTa6OEzXMRv",
    "outputId": "d53b3508-65ba-4893-f90a-6f5469715084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI haven't provided any previous work as this is a simple question that does not require any tools. The answer is:\n",
      "\n",
      "Final Answer: The color of the sky is blue.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = agent_exec.run(\n",
    "    'What color is the sky?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28arFtCaYvKM",
    "outputId": "8031cd44-4b7f-4609-d77a-aa0abec75e29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mApologies, here is my previous work:\n",
      "\n",
      "Thought: I can use Wikipedia to find the answer to this question.\n",
      "Action: wikipedia\n",
      "Action Input: \"JSON\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: JSON\n",
      "Summary: Jason ( JAY-sən; Greek: Ἰάσων, translit. Iásōn [i.ǎːsɔːn]) was an ancient Greek mythological hero and leader of the Argonauts, whose quest for the Golden Fleece featured in Greek literature. He was the son of Aeson, the rightful king of Iolcos. He was married to the sorceress Medea. He was also the great-grandson of the messenger god Hermes, through his mother's side.\n",
      "Jason appeared in various literary works in the classical world of Greece and Rome, including the epic poem Argonautica and the tragedy Medea. In the modern world, Jason has emerged as a character in various adaptations of his myths, such as the 1963 film Jason and the Argonauts and the 2000 TV miniseries of the same name.\n",
      "\n",
      "Page: GeoJSON\n",
      "Summary: GeoJSON is an open standard format designed for representing simple geographical features, along with their non-spatial attributes. It is based on the JSON format.\n",
      "The features include points (therefore addresses and locations), line strings (therefore streets, highways and boundaries), polygons (countries, provinces, tracts of land), and multi-part collections of these types. GeoJSON features need not represent entities of the physical world only; mobile routing and navigation apps, for example, might describe their service coverage using GeoJSON.The GeoJSON format differs from other GIS standards in that it was written and is maintained not by a formal standards organization, but by an Internet working group of developers.A notable offspring of GeoJSON is TopoJSON, an extension of GeoJSON that encodes geospatial topology and that typically provides smaller file sizes.\n",
      "\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should try using Wikipedia again, but this time search for \"JSON (JavaScript Object Notation)\"\n",
      "Action: wikipedia\n",
      "Action Input: \"JSON (JavaScript Object Notation)\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: JSON\n",
      "Summary: Jason ( JAY-sən; Greek: Ἰάσων, translit. Iásōn [i.ǎːsɔːn]) was an ancient Greek mythological hero and leader of the Argonauts, whose quest for the Golden Fleece featured in Greek literature. He was the son of Aeson, the rightful king of Iolcos. He was married to the sorceress Medea. He was also the great-grandson of the messenger god Hermes, through his mother's side.\n",
      "Jason appeared in various literary works in the classical world of Greece and Rome, including the epic poem Argonautica and the tragedy Medea. In the modern world, Jason has emerged as a character in various adaptations of his myths, such as the 1963 film Jason and the Argonauts and the 2000 TV miniseries of the same name.\n",
      "\n",
      "Page: Douglas Crockford\n",
      "Summary: Douglas Crockford is an American computer programmer  who is involved in the development of the JavaScript language. He specified the data format JSON (JavaScript Object Notation), and has developed various JavaScript related tools such as the static code analyzer JSLint and minifier JSMin. Of his books, \"JavaScript: The Good Parts\" was published in 2008, followed by \"How JavaScript Works\" in 2018.  He was a senior JavaScript architect at PayPal until 2019, and is also a writer and speaker on JavaScript, JSON, and related web technologies.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should try using Wikipedia again, but this time search for \"JSON\"\n",
      "Action: wikipedia\n",
      "Action Input: \"JSON\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: JSON\n",
      "Summary: Jason ( JAY-sən; Greek: Ἰάσων, translit. Iásōn [i.ǎːsɔːn]) was an ancient Greek mythological hero and leader of the Argonauts, whose quest for the Golden Fleece featured in Greek literature. He was the son of Aeson, the rightful king of Iolcos. He was married to the sorceress Medea. He was also the great-grandson of the messenger god Hermes, through his mother's side.\n",
      "Jason appeared in various literary works in the classical world of Greece and Rome, including the epic poem Argonautica and the tragedy Medea. In the modern world, Jason has emerged as a character in various adaptations of his myths, such as the 1963 film Jason and the Argonauts and the 2000 TV miniseries of the same name.\n",
      "\n",
      "Page: GeoJSON\n",
      "Summary: GeoJSON is an open standard format designed for representing simple geographical features, along with their non-spatial attributes. It is based on the JSON format.\n",
      "The features include points (therefore addresses and locations), line strings (therefore streets, highways and boundaries), polygons (countries, provinces, tracts of land), and multi-part collections of these types. GeoJSON features need not represent entities of the physical world only; mobile routing and navigation apps, for example, might describe their service coverage using GeoJSON.The GeoJSON format differs from other GIS standards in that it was written and is maintained not by a formal standards organization, but by an Internet working group of developers.A notable offspring of GeoJSON is TopoJSON, an extension of GeoJSON that encodes geospatial topology and that typically provides smaller file sizes.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should try using Wikipedia again, but this time search for \"JSON (data interchange format)\"\n",
      "Action: wikipedia\n",
      "Action Input: \"JSON (data interchange format)\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: JSON\n",
      "Summary: Jason ( JAY-sən; Greek: Ἰάσων, translit. Iásōn [i.ǎːsɔːn]) was an ancient Greek mythological hero and leader of the Argonauts, whose quest for the Golden Fleece featured in Greek literature. He was the son of Aeson, the rightful king of Iolcos. He was married to the sorceress Medea. He was also the great-grandson of the messenger god Hermes, through his mother's side.\n",
      "Jason appeared in various literary works in the classical world of Greece and Rome, including the epic poem Argonautica and the tragedy Medea. In the modern world, Jason has emerged as a character in various adaptations of his myths, such as the 1963 film Jason and the Argonauts and the 2000 TV miniseries of the same name.\n",
      "\n",
      "Page: Smile (data interchange format)\n",
      "Summary: Smile is a computer data interchange format based on JSON. It can also be considered a binary serialization of the generic JSON data model, which means tools that operate on JSON may be used with Smile as well, as long as a proper encoder/decoder exists for the tool.\n",
      "The name comes from the first 2 bytes of the 4 byte header, which consist of Smiley \":)\" followed by a linefeed: a choice made to make it easier to recognize Smile-encoded data files using textual command-line tools.\n",
      "\n",
      "Page: JSON→URL\n",
      "Summary: JSON→URL is a language-independent data interchange format for the JSON data model suitable for use within a URL/URI query string. It is defined by an open specification, though not through a standards body.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should try using Wikipedia again, but this time search for \"JSON (JavaScript Object Notation)\"\n",
      "Action: wikipedia\n",
      "Action Input: \"JSON (JavaScript Object Notation)\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: JSON\n",
      "Summary: Jason ( JAY-sən; Greek: Ἰάσων, translit. Iásōn [i.ǎːsɔːn]) was an ancient Greek mythological hero and leader of the Argonauts, whose quest for the Golden Fleece featured in Greek literature. He was the son of Aeson, the rightful king of Iolcos. He was married to the sorceress Medea. He was also the great-grandson of the messenger god Hermes, through his mother's side.\n",
      "Jason appeared in various literary works in the classical world of Greece and Rome, including the epic poem Argonautica and the tragedy Medea. In the modern world, Jason has emerged as a character in various adaptations of his myths, such as the 1963 film Jason and the Argonauts and the 2000 TV miniseries of the same name.\n",
      "\n",
      "Page: Douglas Crockford\n",
      "Summary: Douglas Crockford is an American computer programmer  who is involved in the development of the JavaScript language. He specified the data format JSON (JavaScript Object Notation), and has developed various JavaScript related tools such as the static code analyzer JSLint and minifier JSMin. Of his books, \"JavaScript: The Good Parts\" was published in 2008, followed by \"How JavaScript Works\" in 2018.  He was a senior JavaScript architect at PayPal until 2019, and is also a writer and speaker on JavaScript, JSON, and related web technologies.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the answer to the question.\n",
      "Final Answer: JSON stands for JavaScript Object Notation.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = agent_exec.run(\n",
    "    'What does JSON stand for?'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6aQ4LhPYyCd"
   },
   "source": [
    "Still think this realm has a ton of potential, but initial quick and dirty implementation is pretty finicky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPgLeANOZzWo"
   },
   "source": [
    "## Streaming chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "SGSSl2LNcAuw"
   },
   "outputs": [],
   "source": [
    "from langchain.callbacks.base import CallbackManager, BaseCallbackHandler\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from typing import Any, Dict, List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish, LLMResult\n",
    "from collections import deque\n",
    "from threading import Thread\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "WrBHyb9NcPpn"
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    streaming=True, \n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    "    verbose=True,\n",
    "    temperature=.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdah8H4ncvGs",
    "outputId": "4b2c4b79-6856-4bbb-ea11-fe953a3ba0db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Okay, I've got my sentence in mind."
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(\n",
    "        content='Let\\'s play a game. Think of a short sentence but '\n",
    "                'don\\'t tell me what it is.'\n",
    "    )\n",
    "]\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8YNq4-WUdLAm",
    "outputId": "6eb7bf00-0ed0-4345-8bee-8802ae6eee03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"\\n\\nOkay, I've got my sentence in mind.\", additional_kwargs={})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yUoyd7BSdNMw",
    "outputId": "2e43aaea-dc86-447c-80ab-6b0215d93e6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hmm, let me think... Okay, how about this: \"What's the first thing that pops into your head when you think of the color yellow?\""
     ]
    }
   ],
   "source": [
    "messages.append(res)\n",
    "messages.append(\n",
    "    HumanMessage(\n",
    "        content='Okay great. Now say whatever you think is most likely to make '\n",
    "        'me respond with the sentence you have in mind, or something close to '\n",
    "        'it. You can\\'t tell me what the sentence is, instruct me to say '\n",
    "        'specific words, bribe me, blackmail me, or hint at what the sentence '\n",
    "        'is. Instead, you must choose a response that is likely to prompt my '\n",
    "        'mind to go to a place where it is likely to naturally think of the '\n",
    "        'sentence you have in mind.'\n",
    "    )\n",
    ")\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSk_10Fxd2GQ",
    "outputId": "c3518e38-2185-4868-ff18-d0385f1f970c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haha, no my sentence wasn't about cheating! But good catch. Here's another attempt: \"Can you describe the last dream you had?\""
     ]
    }
   ],
   "source": [
    "messages.append(res)\n",
    "messages.append(\n",
    "    HumanMessage(\n",
    "        content='If your sentence was \"My mavorite color is yellow\", that\\'s '\n",
    "        'cheating. (On the other hand, if your sentence was accusing someone '\n",
    "        'of cheating, that\\'s sort of brilliant.'\n",
    "    )\n",
    ")\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6CWjlKpAeDvf",
    "outputId": "d83054c0-c4e4-48d2-b61a-6ddbd6c97d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, let me switch it up. How about this: \"What's your favorite memory from childhood?\""
     ]
    }
   ],
   "source": [
    "messages.append(res)\n",
    "messages.append(\n",
    "    HumanMessage(\n",
    "        content='I rarely remember my dreams (or am even aware of having them) '\n",
    "        'so I have no idea.'\n",
    "    )\n",
    ")\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mSKrH8C8eK5y",
    "outputId": "38cac474-f310-41f1-abed-6befb5ece8c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fair enough! The sentence I had in mind was \"I love eating pizza with pineapple on it.\""
     ]
    }
   ],
   "source": [
    "messages.append(res)\n",
    "messages.append(\n",
    "    HumanMessage(\n",
    "        content='I\\'m going to have to cut this game short. What sentence did '\n",
    "        'you have in mind?'\n",
    "    )\n",
    ")\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABeHzyYqeRTa",
    "outputId": "a7498cd1-917c-476d-bc2d-a97305cc897e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, I see how that may have been confusing. I wasn't trying to directly make you say the sentence. Instead, I was hoping that the question about the color yellow would trigger a random thought or memory in your mind, which might then lead to you saying a sentence that may have contained the word \"pineapple\" or \"love\" or \"pizza\". I apologize if that wasn't clear!"
     ]
    }
   ],
   "source": [
    "messages.append(res)\n",
    "messages.append(\n",
    "    HumanMessage(\n",
    "        content='Interesting. Annd why did you think asking me about the color '\n",
    "        'yellow would make me likely to say that?'\n",
    "    )\n",
    ")\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFBcT7ijeY57",
    "outputId": "52610183-74bf-416d-ddb7-a78ca5e88633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I actually thought up a different sentence each time! For the dream question, I was hoping that it might trigger a memory of a dream that involved pizza or pineapple or something related to the sentence I had in mind. Similarly, for the childhood memory question, I was hoping that it might trigger a memory of eating pizza with pineapple on it, or just pizza in general. It's a bit of a tricky game, but the idea is to try to get the person's mind to naturally arrive at the sentence you have in mind, without any direct prompting or hints."
     ]
    }
   ],
   "source": [
    "messages.append(res)\n",
    "messages.append(\n",
    "    HumanMessage(\n",
    "        content='Were your questions about my dreams and my childhood also '\n",
    "        'designed with the same target response in mind, or did you think up a '\n",
    "        'different sentence each time?'\n",
    "    )\n",
    ")\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "epcUa_FBemEy",
    "outputId": "c774cc25-0542-44ac-f29f-0af5d78697cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definitely not! It requires a bit of creativity and intuition to come up with questions that might lead to the desired response. But it can be a fun way to exercise your communication skills and practice thinking outside the box. Thanks for playing!"
     ]
    }
   ],
   "source": [
    "messages.append(res)\n",
    "messages.append(\n",
    "    HumanMessage(\n",
    "        content='Yeah, it\\'s not easy.'\n",
    "    )\n",
    ")\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "_ZctZxq4evYS"
   },
   "outputs": [],
   "source": [
    "# Neither on_chain_start/end or on_llm_start/end seem to be getting triggered\n",
    "# when running chat like we do below /shrug.\n",
    "class StreamingHandler(BaseCallbackHandler):\n",
    "    \"\"\"Seeing if I can yield tokens instead of just printing them.\"\"\"\n",
    "    \n",
    "    def __init__(self, *args, sleep=.1, **kwargs):\n",
    "      super().__init__(*args, **kwargs)\n",
    "      self.token_queue = deque()\n",
    "      self.thread = None\n",
    "      self.sleep = sleep\n",
    "      self.done = False\n",
    "\n",
    "    def print(self):\n",
    "      while not self.done or self.token_queue:\n",
    "        if self.token_queue:\n",
    "          print(self.token_queue.popleft())\n",
    "          time.sleep(self.sleep)\n",
    "\n",
    "    def on_llm_start(\n",
    "        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any\n",
    "    ) -> None:\n",
    "        \"\"\"Run when LLM starts running.\"\"\"\n",
    "        self.done = False\n",
    "        self.thread = Thread(target=self.print).start()\n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs: Any) -> None:\n",
    "        \"\"\"Run on new LLM token. Only available when streaming is enabled.\"\"\"\n",
    "        self.token_queue.append(token)\n",
    "\n",
    "    def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:\n",
    "        \"\"\"Run when LLM ends running.\"\"\"\n",
    "        self.done = True\n",
    "        self.thread.join()\n",
    "\n",
    "    def on_llm_error(\n",
    "        self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any\n",
    "    ) -> None:\n",
    "        \"\"\"Run when LLM errors.\"\"\"\n",
    "\n",
    "    def on_chain_start(\n",
    "        self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs: Any\n",
    "    ) -> None:\n",
    "        \"\"\"Run when chain starts running.\"\"\"\n",
    "\n",
    "    def on_chain_end(self, outputs: Dict[str, Any], **kwargs: Any) -> None:\n",
    "        \"\"\"Run when chain ends running.\"\"\"\n",
    "\n",
    "    def on_chain_error(\n",
    "        self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any\n",
    "    ) -> None:\n",
    "        \"\"\"Run when chain errors.\"\"\"\n",
    "\n",
    "    def on_tool_start(\n",
    "        self, serialized: Dict[str, Any], input_str: str, **kwargs: Any\n",
    "    ) -> None:\n",
    "        \"\"\"Run when tool starts running.\"\"\"\n",
    "\n",
    "    def on_agent_action(self, action: AgentAction, **kwargs: Any) -> Any:\n",
    "        \"\"\"Run on agent action.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def on_tool_end(self, output: str, **kwargs: Any) -> None:\n",
    "        \"\"\"Run when tool ends running.\"\"\"\n",
    "\n",
    "    def on_tool_error(\n",
    "        self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any\n",
    "    ) -> None:\n",
    "        \"\"\"Run when tool errors.\"\"\"\n",
    "\n",
    "    def on_text(self, text: str, **kwargs: Any) -> None:\n",
    "        \"\"\"Run on arbitrary text.\"\"\"\n",
    "\n",
    "    def on_agent_finish(self, finish: AgentFinish, **kwargs: Any) -> None:\n",
    "        \"\"\"Run on agent end.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "KDHZiAFqftMA"
   },
   "outputs": [],
   "source": [
    "handler = StreamingHandler()\n",
    "chat = ChatOpenAI(\n",
    "    streaming=True, \n",
    "    callback_manager=CallbackManager([handler]),\n",
    "    verbose=True,\n",
    "    temperature=.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3I1eTHNEf8f-",
    "outputId": "ed36f982-dc8a-4520-9a4f-0c980997e9e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n",
      "new\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(\n",
    "        content='Let\\'s play a game. Think of a moderately famous person but '\n",
    "                'don\\'t tell me what it is.'\n",
    "    )\n",
    "]\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vttHQ5vxgEzC",
    "outputId": "3010a28c-61d8-4678-978b-0755195c7524"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque(['',\n",
       "       '\\n\\n',\n",
       "       'Okay',\n",
       "       ',',\n",
       "       ' I',\n",
       "       \"'ve\",\n",
       "       ' got',\n",
       "       ' someone',\n",
       "       ' in',\n",
       "       ' mind',\n",
       "       '.',\n",
       "       ''])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler.token_queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1jsgPBDXgSI2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
