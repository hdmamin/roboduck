{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:04.480108Z",
     "start_time": "2023-03-27T05:47:04.463629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:08.644298Z",
     "start_time": "2023-03-27T05:47:04.484253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/gooseai_sample_responses.pkl.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, \\\n",
    "    HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from htools import *\n",
    "from jabberwocky.openai_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:08.803028Z",
     "start_time": "2023-03-27T05:47:08.696893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmamin/roboduck\n"
     ]
    }
   ],
   "source": [
    "cd_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:08.865773Z",
     "start_time": "2023-03-27T05:47:08.811102Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = api_key = load_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:26.226263Z",
     "start_time": "2023-03-25T06:53:26.174407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: Could try davinci text as well but codex is free for now. You may want to strip triple double-quotes from the end in case codex generates them (we don't include that as a stop phrase because codex might generate a docstring as part of a correct code snippet).\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\"\"\"ANSWER KEY\n",
      "\n",
      "This code snippet is not working as expected. Help me debug it. First read my question, then examine the snippet of code that is causing the issue and look at the values of the local and global variables. In the section titled SOLUTION PART 1, use plain English to explain what the problem is and how to fix it. In the section titled SOLUTION PART 2, write a corrected version of the input code snippet. If you don't know what the problem is, SOLUTION PART 1 should list a few possible causes or things I could try in order to identify the issue and SOLUTION PART 2 should say N/A. Be concise and use simple language because I am a beginning programmer.\n",
      "\n",
      "QUESTION:\n",
      "{question}\n",
      "\n",
      "CURRENT CODE SNIPPET:\n",
      "{code}\n",
      "\n",
      "LOCAL VARIABLES:\n",
      "{local_vars}\n",
      "\n",
      "GLOBAL VARIABLES:\n",
      "{global_vars}\n",
      "\n",
      "SOLUTION PART 1:\n"
     ]
    }
   ],
   "source": [
    "print(load_prompt('debug')['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:29.030576Z",
     "start_time": "2023-03-25T06:53:29.000618Z"
    }
   },
   "outputs": [],
   "source": [
    "system_prompt_text = \"\"\"You are an incredibly effective AI programming assistant. You have in-depth knowledge across a broad range of sub-fields within computer science, software development, and data science, and your goal is to help Python programmers resolve their most challenging bugs.\n",
    "\"\"\"\n",
    "system_prompt = SystemMessage(content=system_prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:29.208500Z",
     "start_time": "2023-03-25T06:53:29.172102Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "user_prompt_text = \"\"\"This code snippet is not working as expected. Help me debug it. First read my question, then examine the snippet of code that is causing the issue and look at the values of the local and global variables. Your response must have exactly two parts. In the section titled SOLUTION PART 1, use plain English to explain what the problem is and how to fix it (if you don't know what the problem is, SOLUTION PART 1 should instead list a few possible causes or things I could try in order to identify the issue). In the section titled SOLUTION PART 2, write a corrected version of the input code snippet (if you don't know, SOLUTION PART 2 should say None). SOLUTION PART 2 must contain only python code - there must not be any English explanation outside of code comments or docstrings. Be concise and use simple language because I am a beginning programmer.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "CURRENT CODE SNIPPET:\n",
    "{code}\n",
    "\n",
    "LOCAL VARIABLES:\n",
    "{local_vars}\n",
    "\n",
    "GLOBAL VARIABLES:\n",
    "{global_vars}\"\"\"\n",
    "user_prompt_template = HumanMessagePromptTemplate.from_template(\n",
    "    user_prompt_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:29.812462Z",
     "start_time": "2023-03-25T06:53:29.778952Z"
    }
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'question': 'Why will this throw an index error soon?',\n",
    "    'code': \"\"\"def bubble_sort(nums):\n",
    "    for i in range(len(nums)):\n",
    "        for j in range(len(nums)):\n",
    "            if nums[j] > nums[j + 1]:\n",
    "                nums[j + 1], nums[j] = nums[j], nums[j + 1]\n",
    "    return nums\"\"\",\n",
    "    'local_vars': \"\"\"{\n",
    "    'nums': [3, 4, 2, 1, 5, 9],   # type: list\n",
    "    'i': 0,   # type: int\n",
    "    'j': 4,   # type: int\n",
    "}\"\"\",\n",
    "    'global_vars': \"\"\"{\n",
    "}\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:30.186584Z",
     "start_time": "2023-03-25T06:53:30.155314Z"
    }
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    system_prompt,\n",
    "    user_prompt_template.format(**kwargs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:30.591338Z",
     "start_time": "2023-03-25T06:53:30.553451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an incredibly effective AI programming assistant. You have in-depth knowledge across a broad range of sub-fields within computer science, software development, and data science, and your goal is to help Python programmers resolve their most challenging bugs.\n",
      "\n",
      "This code snippet is not working as expected. Help me debug it. First read my question, then examine the snippet of code that is causing the issue and look at the values of the local and global variables. Your response must have exactly two parts. In the section titled SOLUTION PART 1, use plain English to explain what the problem is and how to fix it (if you don't know what the problem is, SOLUTION PART 1 should instead list a few possible causes or things I could try in order to identify the issue). In the section titled SOLUTION PART 2, write a corrected version of the input code snippet (if you don't know, SOLUTION PART 2 should say None). SOLUTION PART 2 must contain only python code - there must not be any English explanation outside of code comments or docstrings. Be concise and use simple language because I am a beginning programmer.\n",
      "\n",
      "QUESTION:\n",
      "Why will this throw an index error soon?\n",
      "\n",
      "CURRENT CODE SNIPPET:\n",
      "def bubble_sort(nums):\n",
      "    for i in range(len(nums)):\n",
      "        for j in range(len(nums)):\n",
      "            if nums[j] > nums[j + 1]:\n",
      "                nums[j + 1], nums[j] = nums[j], nums[j + 1]\n",
      "    return nums\n",
      "\n",
      "LOCAL VARIABLES:\n",
      "{\n",
      "    'nums': [3, 4, 2, 1, 5, 9],   # type: list\n",
      "    'i': 0,   # type: int\n",
      "    'j': 4,   # type: int\n",
      "}\n",
      "\n",
      "GLOBAL VARIABLES:\n",
      "{\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(m.content for m in messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T04:39:53.830156Z",
     "start_time": "2023-03-27T04:39:53.791727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x7fed643756d0>, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', model_kwargs={'temperature': 0.66, 'a': 'b'}, openai_api_key=None, request_timeout=60, max_retries=6, streaming=False, n=1, max_tokens=33)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatOpenAI(temperature=.66, a='b', max_tokens=33, \n",
    "                  model_name='gpt-3.5-turbo')\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T04:39:54.027579Z",
     "start_time": "2023-03-27T04:39:53.987254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temperature': 0.66, 'a': 'b'}"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.model_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T04:40:00.939864Z",
     "start_time": "2023-03-27T04:40:00.879291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T04:06:34.986994Z",
     "start_time": "2023-03-22T04:06:34.949026Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOLUTION PART 1:\n",
      "The code will throw an index error soon because the inner loop is iterating up to the length of the list, which means that on the last iteration, `nums[j + 1]` will be out of range. To fix this, we need to change the range of the inner loop to `range(len(nums) - i - 1)`.\n",
      "\n",
      "SOLUTION PART 2:\n",
      "\n",
      "```\n",
      "def bubble_sort(nums):\n",
      "    for i in range(len(nums)):\n",
      "        for j in range(len(nums) - i - 1):\n",
      "            if nums[j] > nums[j + 1]:\n",
      "                nums[j + 1], nums[j] = nums[j], nums[j + 1]\n",
      "    return nums\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "res = chat(messages)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T04:11:21.695628Z",
     "start_time": "2023-03-22T04:11:21.649258Z"
    }
   },
   "outputs": [],
   "source": [
    "messages.append(res)\n",
    "messages.append(\n",
    "    user_prompt_template.format(\n",
    "        **{**kwargs, \n",
    "           'question': 'Can you revise your solution so you only find the length of nums once?'}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T04:11:55.671084Z",
     "start_time": "2023-03-22T04:11:49.538517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOLUTION PART 1:\n",
      "The problem with the current code is that it is calling `len(nums)` twice in the inner loop, which is inefficient. To fix this, we can store the length of `nums` in a variable before the loop and use that variable instead.\n",
      "\n",
      "SOLUTION PART 2:\n",
      "\n",
      "```\n",
      "def bubble_sort(nums):\n",
      "    n = len(nums)\n",
      "    for i in range(n):\n",
      "        for j in range(n - i - 1):\n",
      "            if nums[j] > nums[j + 1]:\n",
      "                nums[j + 1], nums[j] = nums[j], nums[j + 1]\n",
      "    return nums\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "res = chat(messages)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took first stab at storing this info in a file (py for now). Try loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:11.571880Z",
     "start_time": "2023-03-27T05:47:11.529091Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "from langchain.schema import AIMessage\n",
    "from roboduck.prompts import load_template\n",
    "from inspect import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:12.491240Z",
     "start_time": "2023-03-27T05:47:12.457241Z"
    }
   },
   "outputs": [],
   "source": [
    "class DummyChatModel:\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def __call__(self, messages, stop=None):\n",
    "        return AIMessage(content=messages[-1].content.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:12.961981Z",
     "start_time": "2023-03-27T05:47:12.905014Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Old approach. Decorator is not as useful for our use case because we want to\n",
    "# define the base function once but create several variants of it using\n",
    "# different fields.\n",
    "# def add_kwargs(*fields):\n",
    "#     def decorator(func):\n",
    "#         # In practice langchain checks for this anyway if we ask for a\n",
    "#         # completion, but outside of that context we need typecheck\n",
    "#         # because otherwise we could provide no kwargs and _func wouldn't\n",
    "#         # complain. Just use generic type because we only care that a value is\n",
    "#         # provided.\n",
    "#         @typecheck(**{f: object for f in fields})\n",
    "#         @wraps(func)\n",
    "#         def wrapper(**kwargs):\n",
    "#             return func(**kwargs)\n",
    "\n",
    "#         sig = signature(wrapper)\n",
    "#         params_ = {field: Parameter(field, Parameter.KEYWORD_ONLY)\n",
    "#                    for field in fields}\n",
    "#         wrapper.__signature__ = sig.replace(parameters=params_.values())\n",
    "#         return wrapper\n",
    "#     return decorator\n",
    "\n",
    "\n",
    "# @add_kwargs('question', 'abc')\n",
    "# def _reply(**kwargs):\n",
    "#     return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:13.606537Z",
     "start_time": "2023-03-27T05:47:13.561508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As expected, got TypeError(Field \"key\" is not a valid hide_field because it has no default value in the original function.).\n"
     ]
    }
   ],
   "source": [
    "def add_kwargs(func, fields, hide_fields=(), strict=False):\n",
    "    # Hide_fields must have default values in existing function. They will not\n",
    "    # show up in the new docstring and the user will not be able to pass in a\n",
    "    # value when calling the new function - it will always use the default.\n",
    "    # To set different defaults, you can pass in a partial rather than a \n",
    "    # function as the first arg here.\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "    if hide_fields and not strict:\n",
    "        raise ValueError(\n",
    "            'You must set strict=True when providing one or more '\n",
    "            'hide_fields. Otherwise the user can still pass in those args.'\n",
    "        )\n",
    "    sig = signature(wrapper)\n",
    "    params_ = {k: v for k, v in sig.parameters.items()}\n",
    "    \n",
    "    # Remove any fields we want to hide.\n",
    "    for field in hide_fields:\n",
    "        if field not in params_:\n",
    "            warnings.warn(f'No need to hide field {field} because it\\'s not '\n",
    "                          'in the existing function signature.')\n",
    "        elif params_.pop(field).default == Parameter.empty:\n",
    "            raise TypeError(\n",
    "                f'Field \"{field}\" is not a valid hide_field because it has '\n",
    "                'no default value in the original function.'\n",
    "            )\n",
    "            \n",
    "    if getattr(params_.pop('kwargs', None), 'kind') != Parameter.VAR_KEYWORD:\n",
    "        raise TypeError(f'Function {func} must accept **kwargs.')\n",
    "    new_params = {\n",
    "        field: Parameter(field, Parameter.KEYWORD_ONLY)\n",
    "        for field in fields\n",
    "    }\n",
    "    overlap = set(new_params) & set(params_)\n",
    "    if overlap:\n",
    "        raise RuntimeError(\n",
    "            f'Some of the kwargs you tried to inject into {func} already '\n",
    "            'exist in its signature. This is not allowed because it\\'s '\n",
    "            'unclear how to resolve default values and parameter type.'\n",
    "        )\n",
    "\n",
    "    params_.update(new_params)\n",
    "    wrapper.__signature__ = sig.replace(parameters=params_.values())\n",
    "    if strict:\n",
    "        # In practice langchain checks for this anyway if we ask for a\n",
    "        # completion, but outside of that context we need typecheck\n",
    "        # because otherwise we could provide no kwargs and _func wouldn't\n",
    "        # complain. Just use generic type because we only care that a value is\n",
    "        # provided.\n",
    "        wrapper = typecheck(wrapper, **{f: object for f in fields})\n",
    "    return wrapper\n",
    "\n",
    "def _reply(key, bar=-1, **kwargs):\n",
    "    \"\"\"Test docstring.\"\"\"\n",
    "    return key, bar, kwargs\n",
    "\n",
    "reply = add_kwargs(_reply, ['statement', 'response'])\n",
    "strict_reply = add_kwargs(_reply, ['statement', 'response'], strict=True)\n",
    "with assert_raises(TypeError):\n",
    "    no_key_reply = add_kwargs(_reply, ['statement', 'response'],\n",
    "                              hide_fields=['key'], strict=True)\n",
    "    \n",
    "    \n",
    "def reply_(key='aaa', bar=-1, **kwargs):\n",
    "    \"\"\"Test docstring.\"\"\"\n",
    "    return key, bar, kwargs\n",
    "\n",
    "\n",
    "no_key_reply = add_kwargs(reply_, ['statement', 'response'],\n",
    "                          hide_fields=['key'], strict=True)\n",
    "diff_key_reply = add_kwargs(\n",
    "    partial(reply_, key='zzz'), ['statement', 'response'],\n",
    "    hide_fields=['key'], strict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:16.353196Z",
     "start_time": "2023-03-27T05:47:16.314181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 99, {'statement': 44, 'response': -1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply('a', bar=99, statement=44, response=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:16.504396Z",
     "start_time": "2023-03-27T05:47:16.470254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 99, {'statement': 44})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply('a', bar=99, statement=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:16.648014Z",
     "start_time": "2023-03-27T05:47:16.611858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 99, {'statement': 44, 'response': -1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strict_reply('a', bar=99, statement=44, response=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:17.003765Z",
     "start_time": "2023-03-27T05:47:16.956934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As expected, got TypeError(missing a required argument: 'response').\n"
     ]
    }
   ],
   "source": [
    "with assert_raises(TypeError):\n",
    "    strict_reply('a', bar=99, statement=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:17.329670Z",
     "start_time": "2023-03-27T05:47:17.286439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('aaa', 99, {'statement': 44, 'response': -1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_key_reply(bar=99, statement=44, response=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:17.812991Z",
     "start_time": "2023-03-27T05:47:17.775467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As expected, got TypeError(got an unexpected keyword argument 'key').\n"
     ]
    }
   ],
   "source": [
    "with assert_raises(TypeError):\n",
    "    no_key_reply(bar=99, statement=44, response=-1, key=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:18.023613Z",
     "start_time": "2023-03-27T05:47:17.987097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('zzz', 99, {'statement': 44, 'response': -1})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_key_reply(bar=99, statement=44, response=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:18.309140Z",
     "start_time": "2023-03-27T05:47:18.270188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As expected, got TypeError(got an unexpected keyword argument 'key').\n"
     ]
    }
   ],
   "source": [
    "with assert_raises(TypeError):\n",
    "    diff_key_reply(bar=99, statement=44, response=-1, key='eeee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:57:50.891214Z",
     "start_time": "2023-03-27T05:57:50.843608Z"
    }
   },
   "outputs": [],
   "source": [
    "class Chat:\n",
    "    \n",
    "    def __init__(self, system, user, model_kwargs=None, \n",
    "                 chat_class=ChatOpenAI, history=(), **chat_kwargs):\n",
    "        # model_kwargs affect completion directly \n",
    "        # (e.g. 'temperature' or 'top_p').\n",
    "        # chat_kwargs contains things like `callback_manager` or `verbose`.\n",
    "        self.model_kwargs = dict(model_kwargs or {})\n",
    "        self.chat_kwargs = dict(chat_kwargs)\n",
    "        self.chat = chat_class(**self.chat_kwargs, **self.model_kwargs)\n",
    "        self.system_message = SystemMessage(content=system)\n",
    "        if isinstance(user, str):\n",
    "            user = {'reply': user}\n",
    "        self.user_templates = {\n",
    "            k: HumanMessagePromptTemplate.from_template(v)\n",
    "            for k, v in user.items()\n",
    "        }\n",
    "        self.default_user_key = next(iter(self.user_templates))\n",
    "        self.default_user_fields = (self.user_templates[self.default_user_key]\n",
    "                                    .input_variables)\n",
    "        self._history = list(history) or [self.system_message]\n",
    "        self._create_reply_methods()\n",
    "        \n",
    "    def _create_reply_methods(self):\n",
    "        \"\"\"Creates two options for user to send replies:\n",
    "        1. call chat.reply(), using the key_ arg to determine which type of\n",
    "        user_message is sent. The docstring shows the default user \n",
    "        message type's fields but if you set the key accordingly you can pass\n",
    "        in fields for another message type. We choose not to infer key_\n",
    "        because some user_message types may accept the same fields.\n",
    "        2. call methods like chat.question() or chat.statement(), where 'chat'\n",
    "        and 'statement' are the names of all available user message types\n",
    "        (i.e. the keys of the `user` dict in the prompt config file). You can\n",
    "        not pass in key_.\n",
    "        \"\"\"\n",
    "        for k, v in self.user_templates.items():\n",
    "            if hasattr(self, k):\n",
    "                warnings.warn(\n",
    "                    f'Name collision: prompt defines user message type {k} '\n",
    "                    f'but Chat class already has a method with that name. '\n",
    "                    f'Method will be named {k}_ instead.'\n",
    "                )\n",
    "                k = k + '_'\n",
    "            meth = add_kwargs(partial(self._reply, key_=k), \n",
    "                              fields=v.input_variables,\n",
    "                              hide_fields=['key_'],\n",
    "                              strict=True)\n",
    "            setattr(self, k, meth)\n",
    "        setattr(\n",
    "            self, \n",
    "            'reply', \n",
    "            add_kwargs(self._reply, self.default_user_fields, strict=False)\n",
    "        )\n",
    "        \n",
    "    @classmethod\n",
    "    def from_config(cls, name, model_kwargs=None, **chat_kwargs):\n",
    "        template = load_template(name)\n",
    "        if model_kwargs:\n",
    "            template['model_kwargs'].update(model_kwargs)\n",
    "        return cls(**template, **chat_kwargs)\n",
    "        \n",
    "    def _user_message(self, *, key_='', **kwargs):\n",
    "        key = key_ or self.default_user_key\n",
    "        template = self.user_templates[key]\n",
    "        return template.format(**kwargs)\n",
    "    \n",
    "    def _reply(self, *, key_='', **kwargs):\n",
    "        print('_reply:', key_, kwargs)\n",
    "        user_message = self._user_message(key_=key_, **kwargs)\n",
    "        self._history.append(user_message)\n",
    "        try:\n",
    "            response = self.chat(self._history)\n",
    "        except Exception as e:\n",
    "            self._history.pop(-1)\n",
    "            raise e\n",
    "        self._history.append(response)\n",
    "        return response\n",
    "    \n",
    "    def history(self, sep='\\n\\n', speaker_prefix=True):\n",
    "        \"\"\"Return chat history as a single string.\"\"\"\n",
    "        res = []\n",
    "        for row in self._history:\n",
    "            reply = row.content\n",
    "            if speaker_prefix:\n",
    "                speaker = type(row).__name__.split('Message')[0]\n",
    "                reply = f'{speaker}: {reply}'\n",
    "            res.append(reply)\n",
    "        return sep.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:51.408130Z",
     "start_time": "2023-03-27T05:47:51.371197Z"
    }
   },
   "outputs": [],
   "source": [
    "chat = Chat.from_config('debug', chat_class=DummyChatModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:53.001444Z",
     "start_time": "2023-03-27T05:47:52.957258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code snippet is not working as expected. Help me debug it. First read my question, then examine the snippet of code that is causing the issue and look at the values of the local and global variables. Your response must have exactly two parts. In the section titled SOLUTION PART 1, use plain English to explain what the problem is and how to fix it (if you don't know what the problem is, SOLUTION PART 1 should instead list a few possible causes or things I could try in order to identify the issue). In the section titled SOLUTION PART 2, write a corrected version of the input code snippet (if you don't know, SOLUTION PART 2 should say None). SOLUTION PART 2 must contain only python code - there must not be any English explanation outside of code comments or docstrings. Be concise and use simple language because I am a beginning programmer.\n",
      "\n",
      "QUESTION:\n",
      "Why?\n",
      "\n",
      "CURRENT CODE SNIPPET:\n",
      "a = 3\n",
      "b = 4\n",
      "\n",
      "NEXT LINE:\n",
      "b = 4\n",
      "\n",
      "LOCAL VARIABLES:\n",
      "{3: 4}\n",
      "\n",
      "GLOBAL VARIABLES:\n",
      "{True: False}\n"
     ]
    }
   ],
   "source": [
    "tmp = chat._user_message(\n",
    "    code='a = 3\\nb = 4', question='Why?', local_vars='{3: 4}',\n",
    "    global_vars='{True: False}', next_line='b = 4'\n",
    ")\n",
    "\n",
    "print(tmp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:53.486670Z",
     "start_time": "2023-03-27T05:47:53.453521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      "Why?\n"
     ]
    }
   ],
   "source": [
    "tmp = chat._user_message(\n",
    "    key_='contextless',\n",
    "    question='Why?'\n",
    ")\n",
    "\n",
    "print(tmp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:47:54.733330Z",
     "start_time": "2023-03-27T05:47:54.696743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_reply: contextless {'question': 'x'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='QUESTION:\\nX', additional_kwargs={})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.contextless(question='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:48:00.409980Z",
     "start_time": "2023-03-27T05:48:00.378339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As expected, got TypeError(got an unexpected keyword argument 'key_').\n"
     ]
    }
   ],
   "source": [
    "with assert_raises(TypeError):\n",
    "    chat.contextless(question='x', key_='contextful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:48:03.857099Z",
     "start_time": "2023-03-27T05:48:03.772646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_reply: contextful {'code': 'a = 3\\nb = 4', 'question': 'Why?', 'local_vars': '{3: 4}', 'global_vars': '{True: False}', 'next_line': 'b = 4'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"THIS CODE SNIPPET IS NOT WORKING AS EXPECTED. HELP ME DEBUG IT. FIRST READ MY QUESTION, THEN EXAMINE THE SNIPPET OF CODE THAT IS CAUSING THE ISSUE AND LOOK AT THE VALUES OF THE LOCAL AND GLOBAL VARIABLES. YOUR RESPONSE MUST HAVE EXACTLY TWO PARTS. IN THE SECTION TITLED SOLUTION PART 1, USE PLAIN ENGLISH TO EXPLAIN WHAT THE PROBLEM IS AND HOW TO FIX IT (IF YOU DON'T KNOW WHAT THE PROBLEM IS, SOLUTION PART 1 SHOULD INSTEAD LIST A FEW POSSIBLE CAUSES OR THINGS I COULD TRY IN ORDER TO IDENTIFY THE ISSUE). IN THE SECTION TITLED SOLUTION PART 2, WRITE A CORRECTED VERSION OF THE INPUT CODE SNIPPET (IF YOU DON'T KNOW, SOLUTION PART 2 SHOULD SAY NONE). SOLUTION PART 2 MUST CONTAIN ONLY PYTHON CODE - THERE MUST NOT BE ANY ENGLISH EXPLANATION OUTSIDE OF CODE COMMENTS OR DOCSTRINGS. BE CONCISE AND USE SIMPLE LANGUAGE BECAUSE I AM A BEGINNING PROGRAMMER.\\n\\nQUESTION:\\nWHY?\\n\\nCURRENT CODE SNIPPET:\\nA = 3\\nB = 4\\n\\nNEXT LINE:\\nB = 4\\n\\nLOCAL VARIABLES:\\n{3: 4}\\n\\nGLOBAL VARIABLES:\\n{TRUE: FALSE}\", additional_kwargs={})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.contextful(\n",
    "    code='a = 3\\nb = 4', question='Why?', local_vars='{3: 4}',\n",
    "    global_vars='{True: False}', next_line='b = 4'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:48:10.735861Z",
     "start_time": "2023-03-27T05:48:10.639357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_reply:  {'code': 'a = 3\\nb = 4', 'question': 'Why?', 'local_vars': '{3: 4}', 'global_vars': '{True: False}', 'next_line': 'b = 4'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"THIS CODE SNIPPET IS NOT WORKING AS EXPECTED. HELP ME DEBUG IT. FIRST READ MY QUESTION, THEN EXAMINE THE SNIPPET OF CODE THAT IS CAUSING THE ISSUE AND LOOK AT THE VALUES OF THE LOCAL AND GLOBAL VARIABLES. YOUR RESPONSE MUST HAVE EXACTLY TWO PARTS. IN THE SECTION TITLED SOLUTION PART 1, USE PLAIN ENGLISH TO EXPLAIN WHAT THE PROBLEM IS AND HOW TO FIX IT (IF YOU DON'T KNOW WHAT THE PROBLEM IS, SOLUTION PART 1 SHOULD INSTEAD LIST A FEW POSSIBLE CAUSES OR THINGS I COULD TRY IN ORDER TO IDENTIFY THE ISSUE). IN THE SECTION TITLED SOLUTION PART 2, WRITE A CORRECTED VERSION OF THE INPUT CODE SNIPPET (IF YOU DON'T KNOW, SOLUTION PART 2 SHOULD SAY NONE). SOLUTION PART 2 MUST CONTAIN ONLY PYTHON CODE - THERE MUST NOT BE ANY ENGLISH EXPLANATION OUTSIDE OF CODE COMMENTS OR DOCSTRINGS. BE CONCISE AND USE SIMPLE LANGUAGE BECAUSE I AM A BEGINNING PROGRAMMER.\\n\\nQUESTION:\\nWHY?\\n\\nCURRENT CODE SNIPPET:\\nA = 3\\nB = 4\\n\\nNEXT LINE:\\nB = 4\\n\\nLOCAL VARIABLES:\\n{3: 4}\\n\\nGLOBAL VARIABLES:\\n{TRUE: FALSE}\", additional_kwargs={})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(\n",
    "    code='a = 3\\nb = 4', question='Why?', local_vars='{3: 4}',\n",
    "    global_vars='{True: False}', next_line='b = 4'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:48:19.184722Z",
     "start_time": "2023-03-27T05:48:19.109627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_reply: contextless {'question': 'How are you?'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='QUESTION:\\nHOW ARE YOU?', additional_kwargs={})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(question='How are you?', key_='contextless')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:48:21.084364Z",
     "start_time": "2023-03-27T05:48:21.043158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an incredibly effective AI programming assistant. You have in-depth knowledge across a broad range of sub-fields within computer science, software development, and data science, and your goal is to help Python programmers resolve their most challenging bugs.\n",
      "\n",
      "Human: QUESTION:\n",
      "x\n",
      "\n",
      "AI: QUESTION:\n",
      "X\n",
      "\n",
      "Human: This code snippet is not working as expected. Help me debug it. First read my question, then examine the snippet of code that is causing the issue and look at the values of the local and global variables. Your response must have exactly two parts. In the section titled SOLUTION PART 1, use plain English to explain what the problem is and how to fix it (if you don't know what the problem is, SOLUTION PART 1 should instead list a few possible causes or things I could try in order to identify the issue). In the section titled SOLUTION PART 2, write a corrected version of the input code snippet (if you don't know, SOLUTION PART 2 should say None). SOLUTION PART 2 must contain only python code - there must not be any English explanation outside of code comments or docstrings. Be concise and use simple language because I am a beginning programmer.\n",
      "\n",
      "QUESTION:\n",
      "Why?\n",
      "\n",
      "CURRENT CODE SNIPPET:\n",
      "a = 3\n",
      "b = 4\n",
      "\n",
      "NEXT LINE:\n",
      "b = 4\n",
      "\n",
      "LOCAL VARIABLES:\n",
      "{3: 4}\n",
      "\n",
      "GLOBAL VARIABLES:\n",
      "{True: False}\n",
      "\n",
      "AI: THIS CODE SNIPPET IS NOT WORKING AS EXPECTED. HELP ME DEBUG IT. FIRST READ MY QUESTION, THEN EXAMINE THE SNIPPET OF CODE THAT IS CAUSING THE ISSUE AND LOOK AT THE VALUES OF THE LOCAL AND GLOBAL VARIABLES. YOUR RESPONSE MUST HAVE EXACTLY TWO PARTS. IN THE SECTION TITLED SOLUTION PART 1, USE PLAIN ENGLISH TO EXPLAIN WHAT THE PROBLEM IS AND HOW TO FIX IT (IF YOU DON'T KNOW WHAT THE PROBLEM IS, SOLUTION PART 1 SHOULD INSTEAD LIST A FEW POSSIBLE CAUSES OR THINGS I COULD TRY IN ORDER TO IDENTIFY THE ISSUE). IN THE SECTION TITLED SOLUTION PART 2, WRITE A CORRECTED VERSION OF THE INPUT CODE SNIPPET (IF YOU DON'T KNOW, SOLUTION PART 2 SHOULD SAY NONE). SOLUTION PART 2 MUST CONTAIN ONLY PYTHON CODE - THERE MUST NOT BE ANY ENGLISH EXPLANATION OUTSIDE OF CODE COMMENTS OR DOCSTRINGS. BE CONCISE AND USE SIMPLE LANGUAGE BECAUSE I AM A BEGINNING PROGRAMMER.\n",
      "\n",
      "QUESTION:\n",
      "WHY?\n",
      "\n",
      "CURRENT CODE SNIPPET:\n",
      "A = 3\n",
      "B = 4\n",
      "\n",
      "NEXT LINE:\n",
      "B = 4\n",
      "\n",
      "LOCAL VARIABLES:\n",
      "{3: 4}\n",
      "\n",
      "GLOBAL VARIABLES:\n",
      "{TRUE: FALSE}\n",
      "\n",
      "Human: This code snippet is not working as expected. Help me debug it. First read my question, then examine the snippet of code that is causing the issue and look at the values of the local and global variables. Your response must have exactly two parts. In the section titled SOLUTION PART 1, use plain English to explain what the problem is and how to fix it (if you don't know what the problem is, SOLUTION PART 1 should instead list a few possible causes or things I could try in order to identify the issue). In the section titled SOLUTION PART 2, write a corrected version of the input code snippet (if you don't know, SOLUTION PART 2 should say None). SOLUTION PART 2 must contain only python code - there must not be any English explanation outside of code comments or docstrings. Be concise and use simple language because I am a beginning programmer.\n",
      "\n",
      "QUESTION:\n",
      "Why?\n",
      "\n",
      "CURRENT CODE SNIPPET:\n",
      "a = 3\n",
      "b = 4\n",
      "\n",
      "NEXT LINE:\n",
      "b = 4\n",
      "\n",
      "LOCAL VARIABLES:\n",
      "{3: 4}\n",
      "\n",
      "GLOBAL VARIABLES:\n",
      "{True: False}\n",
      "\n",
      "AI: THIS CODE SNIPPET IS NOT WORKING AS EXPECTED. HELP ME DEBUG IT. FIRST READ MY QUESTION, THEN EXAMINE THE SNIPPET OF CODE THAT IS CAUSING THE ISSUE AND LOOK AT THE VALUES OF THE LOCAL AND GLOBAL VARIABLES. YOUR RESPONSE MUST HAVE EXACTLY TWO PARTS. IN THE SECTION TITLED SOLUTION PART 1, USE PLAIN ENGLISH TO EXPLAIN WHAT THE PROBLEM IS AND HOW TO FIX IT (IF YOU DON'T KNOW WHAT THE PROBLEM IS, SOLUTION PART 1 SHOULD INSTEAD LIST A FEW POSSIBLE CAUSES OR THINGS I COULD TRY IN ORDER TO IDENTIFY THE ISSUE). IN THE SECTION TITLED SOLUTION PART 2, WRITE A CORRECTED VERSION OF THE INPUT CODE SNIPPET (IF YOU DON'T KNOW, SOLUTION PART 2 SHOULD SAY NONE). SOLUTION PART 2 MUST CONTAIN ONLY PYTHON CODE - THERE MUST NOT BE ANY ENGLISH EXPLANATION OUTSIDE OF CODE COMMENTS OR DOCSTRINGS. BE CONCISE AND USE SIMPLE LANGUAGE BECAUSE I AM A BEGINNING PROGRAMMER.\n",
      "\n",
      "QUESTION:\n",
      "WHY?\n",
      "\n",
      "CURRENT CODE SNIPPET:\n",
      "A = 3\n",
      "B = 4\n",
      "\n",
      "NEXT LINE:\n",
      "B = 4\n",
      "\n",
      "LOCAL VARIABLES:\n",
      "{3: 4}\n",
      "\n",
      "GLOBAL VARIABLES:\n",
      "{TRUE: FALSE}\n",
      "\n",
      "Human: QUESTION:\n",
      "How are you?\n",
      "\n",
      "AI: QUESTION:\n",
      "HOW ARE YOU?\n"
     ]
    }
   ],
   "source": [
    "print(chat.history())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-26T03:53:06.725411Z",
     "start_time": "2023-03-26T03:53:06.690408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an incredibly effective AI programming assistant. You have in-depth knowledge across a broad range of sub-fields within computer science, software development, and data science, and your goal is to help Python programmers resolve their most challenging bugs.\n",
      "\n",
      "QUESTION:\n",
      "How are you?\n",
      "\n",
      "QUESTION:\n",
      "HOW ARE YOU?\n"
     ]
    }
   ],
   "source": [
    "# This would make more sense if our messages included speakers, i.e. if a\n",
    "# user_message looked like 'Me: {reply}' and gpt was prompted to reply like\n",
    "# 'Robert Sapolsky: {reply}' (for example).\n",
    "print(chat.history(speaker_prefix=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error when using real ChatOpenAI obj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:49:12.041018Z",
     "start_time": "2023-03-27T05:49:11.967878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x7fdb1f1eb5e0>, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', model_kwargs={'temperature': 0.0, 'top_p': 0.99, 'frequency_penalty': 0.2, 'presence_penalty': 0.0, 'logit_bias': {37811: -100, 27901: -50}, 'stop': ['QUESTION', 'SOLUTION PART 1', 'SOLUTION PART 3']}, openai_api_key=None, request_timeout=60, max_retries=6, streaming=False, n=1, max_tokens=512)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat.from_config('debug')\n",
    "chat.chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:49:15.564948Z",
     "start_time": "2023-03-27T05:49:15.496175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'gpt-3.5-turbo',\n",
       " 'temperature': 0.0,\n",
       " 'top_p': 0.99,\n",
       " 'max_tokens': 512,\n",
       " 'frequency_penalty': 0.2,\n",
       " 'presence_penalty': 0.0,\n",
       " 'logit_bias': {37811: -100, 27901: -50},\n",
       " 'stop': ['QUESTION', 'SOLUTION PART 1', 'SOLUTION PART 3']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.model_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:54:11.564709Z",
     "start_time": "2023-03-25T06:54:08.716102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI language model, I don't have feelings, but I'm functioning properly and ready to assist you with any programming-related questions you may have. How can I help you today?\", additional_kwargs={})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(question='How are you?', key_='contextless')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:54:36.688799Z",
     "start_time": "2023-03-25T06:54:36.602569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an incredibly effective AI programming assistant. You have in-depth knowledge across a broad range of sub-fields within computer science, software development, and data science, and your goal is to help Python programmers resolve their most challenging bugs.\n",
      "\n",
      "Human: QUESTION:\n",
      "How are you?\n",
      "\n",
      "AI: As an AI language model, I don't have feelings, but I'm functioning properly and ready to assist you with any programming-related questions you may have. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "print(chat.history())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:50:08.000218Z",
     "start_time": "2023-03-27T05:50:07.908858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x7fdb1f1eb5e0>, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', model_kwargs={'temperature': 0.7, 'top_p': 0.99, 'frequency_penalty': 0.2, 'presence_penalty': 0.0, 'logit_bias': {37811: -100, 27901: -50}, 'stop': ['QUESTION', 'SOLUTION PART 1', 'SOLUTION PART 3']}, openai_api_key=None, request_timeout=60, max_retries=6, streaming=False, n=1, max_tokens=512)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat.from_config('debug', {'temperature': .7})\n",
    "chat.chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-27T05:50:09.331680Z",
     "start_time": "2023-03-27T05:50:09.281207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'gpt-3.5-turbo',\n",
       " 'temperature': 0.7,\n",
       " 'top_p': 0.99,\n",
       " 'max_tokens': 512,\n",
       " 'frequency_penalty': 0.2,\n",
       " 'presence_penalty': 0.0,\n",
       " 'logit_bias': {37811: -100, 27901: -50},\n",
       " 'stop': ['QUESTION', 'SOLUTION PART 1', 'SOLUTION PART 3']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.model_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signature surgery\n",
    "\n",
    "Inintial prototype for inserting fields into signature and docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-26T03:59:30.438632Z",
     "start_time": "2023-03-26T03:59:30.402871Z"
    }
   },
   "outputs": [],
   "source": [
    "class Foo:\n",
    "    def __init__(self, fields, name2fields):\n",
    "        self.reply = self._make_func(self._reply, fields)\n",
    "        for k, v in name2fields.items():\n",
    "            setattr(self, k, self._make_func(self._reply, v))\n",
    "\n",
    "    def _reply(self, **kwargs):\n",
    "        print('Calling _reply')\n",
    "        return {'kwargs': kwargs, 'completion': 'new text...'}\n",
    "    \n",
    "    def _make_func(self, func, fields):\n",
    "        # In practice I think langchain checks for this anyway if we ask for a\n",
    "        # completion, but outside of that context typecheck would be necessary\n",
    "        # because otherwise we can provide no kwargs and _func won't complain. \n",
    "        @typecheck(**{f: str for f in fields})\n",
    "        @wraps(func)\n",
    "        def wrapper(**kwargs):\n",
    "            return func(**kwargs)\n",
    "        \n",
    "        sig = signature(wrapper)\n",
    "        params_ = {field: Parameter(field, Parameter.KEYWORD_ONLY)\n",
    "                   for field in fields}\n",
    "        wrapper.__signature__ = sig.replace(parameters=params_.values())\n",
    "        return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-26T03:58:20.114292Z",
     "start_time": "2023-03-26T03:58:20.074335Z"
    }
   },
   "outputs": [],
   "source": [
    "f = Foo(\n",
    "    ['a', 'dog', 'x'],\n",
    "    {'question': ['fact', 'question', 'answer'],\n",
    "     'statement': ['salutation', 'name']}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-26T03:58:20.457369Z",
     "start_time": "2023-03-26T03:58:20.421405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.Foo._reply(*, a, dog, x)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-26T03:58:20.860442Z",
     "start_time": "2023-03-26T03:58:20.822714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.Foo._reply(*, fact, question, answer)>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-26T03:58:22.481964Z",
     "start_time": "2023-03-26T03:58:22.443057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.Foo._reply(*, salutation, name)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-26T03:58:22.724402Z",
     "start_time": "2023-03-26T03:58:22.687908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As expected, got TypeError(missing a required argument: 'salutation').\n"
     ]
    }
   ],
   "source": [
    "with assert_raises(TypeError):\n",
    "    f.statement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-26T03:58:23.861949Z",
     "start_time": "2023-03-26T03:58:23.823429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling _reply\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kwargs': {'salutation': 'hi', 'name': 'harry'}, 'completion': 'new text...'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.statement(salutation='hi', name='harry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-26T03:58:26.637222Z",
     "start_time": "2023-03-26T03:58:26.593851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling _reply\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kwargs': {'fact': 'birds are sad', 'question': 'why?', 'answer': 'yes'},\n",
       " 'completion': 'new text...'}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.question(fact='birds are sad', question='why?', answer='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Debug scratch\n",
    "\n",
    "See if we can use frames to identify whether we need to provide context for a user message (i.e. if frame has changed since we last did)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T02:35:33.486423Z",
     "start_time": "2023-03-23T02:35:33.415676Z"
    }
   },
   "outputs": [],
   "source": [
    "from roboduck.debugger import duck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T04:02:00.648795Z",
     "start_time": "2023-03-23T04:01:59.817553Z"
    }
   },
   "outputs": [],
   "source": [
    "def binary_search(x, nums):\n",
    "    if not nums:\n",
    "        return -1\n",
    "    duck(backend='repeat')\n",
    "    mid = len(nums) // 2\n",
    "    if x == nums[mid]:\n",
    "        return x\n",
    "    if x > nums[mid]:\n",
    "        return binary_search(x, nums[mid + 1:])\n",
    "    if x < nums[mid]:\n",
    "        return binary_search(x, nums[:mid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T04:02:00.686427Z",
     "start_time": "2023-03-23T04:02:00.651642Z"
    }
   },
   "outputs": [],
   "source": [
    "nums = [33, 44, 55, 66, 77, 88, 99, 111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T04:02:44.774242Z",
     "start_time": "2023-03-23T04:02:00.695613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-70-8a37149461d4>(5)binary_search()\n",
      "-> mid = len(nums) // 2\n",
      ">>> l .\n",
      "  1  \tdef binary_search(x, nums):\n",
      "  2  \t    if not nums:\n",
      "  3  \t        return -1\n",
      "  4  \t    duck(backend='repeat')\n",
      "  5  ->\t    mid = len(nums) // 2\n",
      "  6  \t    if x == nums[mid]:\n",
      "  7  \t        return x\n",
      "  8  \t    if x > nums[mid]:\n",
      "  9  \t        return binary_search(x, nums[mid + 1:])\n",
      " 10  \t    if x < nums[mid]:\n",
      " 11  \t        return binary_search(x, nums[:mid])\n",
      ">>> y?\n",
      "next line:     mid = len(nums) // 2\n",
      "\u001b[32m[Duck] \u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m>>> n\n",
      "> <ipython-input-70-8a37149461d4>(6)binary_search()\n",
      "-> if x == nums[mid]:\n",
      ">>> n\n",
      "> <ipython-input-70-8a37149461d4>(8)binary_search()\n",
      "-> if x > nums[mid]:\n",
      ">>> n\n",
      "> <ipython-input-70-8a37149461d4>(10)binary_search()\n",
      "-> if x < nums[mid]:\n",
      ">>> n\n",
      "> <ipython-input-70-8a37149461d4>(11)binary_search()\n",
      "-> return binary_search(x, nums[:mid])\n",
      ">>> l .\n",
      "  6  \t    if x == nums[mid]:\n",
      "  7  \t        return x\n",
      "  8  \t    if x > nums[mid]:\n",
      "  9  \t        return binary_search(x, nums[mid + 1:])\n",
      " 10  \t    if x < nums[mid]:\n",
      " 11  ->\t        return binary_search(x, nums[:mid])\n",
      "[EOF]\n",
      ">>> [dev] What wrong?\n",
      "next line:         return binary_search(x, nums[:mid])\n",
      "\u001b[31m\"\"\"ANSWER KEY\n",
      "\n",
      "This code snippet is not working as expected. Help me debug it. First read my question, then examine the snippet of code that is causing the issue and look at the values of the local and global variables. In the section titled SOLUTION PART 1, use plain English to explain what the problem is and how to fix it. In the section titled SOLUTION PART 2, write a corrected version of the input code snippet. If you don't know what the problem is, SOLUTION PART 1 should list a few possible causes or things I could try in order to identify the issue and SOLUTION PART 2 should say N/A. Be concise and use simple language because I am a beginning programmer.\n",
      "\n",
      "QUESTION:\n",
      "[dev] What wrong?\n",
      "\n",
      "CURRENT CODE SNIPPET:\n",
      "def binary_search(x, nums):\n",
      "    if not nums:\n",
      "        return -1\n",
      "    mid = len(nums) // 2\n",
      "    if x == nums[mid]:\n",
      "        return x\n",
      "    if x > nums[mid]:\n",
      "        return binary_search(x, nums[mid + 1:])\n",
      "    if x < nums[mid]:\n",
      "        return binary_search(x, nums[:mid])\n",
      "\n",
      "LOCAL VARIABLES:\n",
      "{\n",
      "    'x': 3,   # type: int\n",
      "    'nums': [33, 44, 55, 66, 77, 88, 99, 111],   # type: list\n",
      "    'mid': 4,   # type: int\n",
      "}\n",
      "\n",
      "GLOBAL VARIABLES:\n",
      "{\n",
      "}\n",
      "\n",
      "SOLUTION PART 1:\u001b[0m\n",
      "\u001b[32m[Duck] \u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m>>> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-1d506c8d773a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbinary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-8a37149461d4>\u001b[0m in \u001b[0;36mbinary_search\u001b[0;34m(x, nums)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmid\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-8a37149461d4>\u001b[0m in \u001b[0;36mbinary_search\u001b[0;34m(x, nums)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmid\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "binary_search(3, nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T02:39:22.174903Z",
     "start_time": "2023-03-23T02:39:22.130813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_search(33, nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T02:39:26.415594Z",
     "start_time": "2023-03-23T02:39:26.371426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_search(39, nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T02:39:40.877084Z",
     "start_time": "2023-03-23T02:39:40.824221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_search(111, nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T02:39:44.851555Z",
     "start_time": "2023-03-23T02:39:44.810780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_search(112, nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T04:06:26.680330Z",
     "start_time": "2023-03-23T04:06:25.828803Z"
    }
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    for i in range(5):\n",
    "        print(i)\n",
    "        duck(backend='repeat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-24T02:44:35.865038Z",
     "start_time": "2023-03-23T04:06:29.000714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "> <ipython-input-73-943befe6b744>(2)test()\n",
      "-> for i in range(5):\n",
      ">>> i\n",
      "0\n",
      ">>> l .\n",
      "  1  \tdef test():\n",
      "  2  ->\t    for i in range(5):\n",
      "  3  \t        print(i)\n",
      "  4  \t        duck(backend='repeat')\n",
      "[EOF]\n",
      ">>> y?\n",
      "frmae_id 140192236901280\n",
      "next line:     for i in range(5):\n",
      "\u001b[32m[Duck] \u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m>>> n\n",
      "> <ipython-input-73-943befe6b744>(3)test()\n",
      "-> print(i)\n",
      ">>> i\n",
      "1\n",
      ">>> y?\n",
      "frmae_id 140192236901280\n",
      "next line:         print(i)\n",
      "\u001b[32m[Duck] \u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m>>> n\n",
      "1\n",
      "> <ipython-input-73-943befe6b744>(4)test()\n",
      "-> duck(backend='repeat')\n",
      ">>> i\n",
      "1\n",
      ">>> n\n",
      "> <ipython-input-73-943befe6b744>(2)test()\n",
      "-> for i in range(5):\n",
      ">>> i\n",
      "1\n",
      ">>> l .\n",
      "  1  \tdef test():\n",
      "  2  ->\t    for i in range(5):\n",
      "  3  \t        print(i)\n",
      "  4  \t        duck(backend='repeat')\n",
      "[EOF]\n",
      ">>> i\n",
      "1\n",
      ">>> y?\n",
      "frmae_id 140192236901280\n",
      "next line:     for i in range(5):\n",
      "\u001b[32m[Duck] \u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m>>> n\n",
      "> <ipython-input-73-943befe6b744>(3)test()\n",
      "-> print(i)\n",
      ">>> l .\n",
      "  1  \tdef test():\n",
      "  2  \t    for i in range(5):\n",
      "  3  ->\t        print(i)\n",
      "  4  \t        duck(backend='repeat')\n",
      "[EOF]\n",
      ">>> y?\n",
      "frmae_id 140192236901280\n",
      "next line:         print(i)\n",
      "\u001b[32m[Duck] \u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m>>> i\n",
      "2\n",
      ">>> n\n",
      "2\n",
      "> <ipython-input-73-943befe6b744>(4)test()\n",
      "-> duck(backend='repeat')\n",
      ">>> n\n",
      "> <ipython-input-73-943befe6b744>(2)test()\n",
      "-> for i in range(5):\n",
      ">>> n\n",
      "> <ipython-input-73-943befe6b744>(3)test()\n",
      "-> print(i)\n",
      ">>> i\n",
      "3\n",
      ">>> n\n",
      "3\n",
      "> <ipython-input-73-943befe6b744>(4)test()\n",
      "-> duck(backend='repeat')\n",
      ">>> n\n",
      "> <ipython-input-73-943befe6b744>(2)test()\n",
      "-> for i in range(5):\n",
      ">>> i\n",
      "3\n",
      ">>> n\n",
      "> <ipython-input-73-943befe6b744>(3)test()\n",
      "-> print(i)\n",
      ">>> i\n",
      "4\n",
      ">>> y?\n",
      "frmae_id 140192236901280\n",
      "next line:         print(i)\n",
      "\u001b[32m[Duck] \u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m>>> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-fbd55f77ab7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-943befe6b744>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mduck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'repeat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-943befe6b744>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mduck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'repeat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
