{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:19.036395Z",
     "start_time": "2023-03-25T06:53:19.023220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:23.800279Z",
     "start_time": "2023-03-25T06:53:19.629429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from /Users/hmamin/jabberwocky/data/misc/gooseai_sample_responses.pkl.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, \\\n",
    "    HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from htools import *\n",
    "from jabberwocky.openai_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:24.951063Z",
     "start_time": "2023-03-25T06:53:24.915433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/hmamin/roboduck\n"
     ]
    }
   ],
   "source": [
    "cd_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:25.386364Z",
     "start_time": "2023-03-25T06:53:25.353025Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = api_key = load_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:26.226263Z",
     "start_time": "2023-03-25T06:53:26.174407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: Could try davinci text as well but codex is free for now. You may want to strip triple double-quotes from the end in case codex generates them (we don't include that as a stop phrase because codex might generate a docstring as part of a correct code snippet).\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "\"\"\"ANSWER KEY\n",
      "\n",
      "This code snippet is not working as expected. Help me debug it. First read my question, then examine the snippet of code that is causing the issue and look at the values of the local and global variables. In the section titled SOLUTION PART 1, use plain English to explain what the problem is and how to fix it. In the section titled SOLUTION PART 2, write a corrected version of the input code snippet. If you don't know what the problem is, SOLUTION PART 1 should list a few possible causes or things I could try in order to identify the issue and SOLUTION PART 2 should say N/A. Be concise and use simple language because I am a beginning programmer.\n",
      "\n",
      "QUESTION:\n",
      "{question}\n",
      "\n",
      "CURRENT CODE SNIPPET:\n",
      "{code}\n",
      "\n",
      "LOCAL VARIABLES:\n",
      "{local_vars}\n",
      "\n",
      "GLOBAL VARIABLES:\n",
      "{global_vars}\n",
      "\n",
      "SOLUTION PART 1:\n"
     ]
    }
   ],
   "source": [
    "print(load_prompt('debug')['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:29.030576Z",
     "start_time": "2023-03-25T06:53:29.000618Z"
    }
   },
   "outputs": [],
   "source": [
    "system_prompt_text = \"\"\"You are an incredibly effective AI programming assistant. You have in-depth knowledge across a broad range of sub-fields within computer science, software development, and data science, and your goal is to help Python programmers resolve their most challenging bugs.\n",
    "\"\"\"\n",
    "system_prompt = SystemMessage(content=system_prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:29.208500Z",
     "start_time": "2023-03-25T06:53:29.172102Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "user_prompt_text = \"\"\"This code snippet is not working as expected. Help me debug it. First read my question, then examine the snippet of code that is causing the issue and look at the values of the local and global variables. Your response must have exactly two parts. In the section titled SOLUTION PART 1, use plain English to explain what the problem is and how to fix it (if you don't know what the problem is, SOLUTION PART 1 should instead list a few possible causes or things I could try in order to identify the issue). In the section titled SOLUTION PART 2, write a corrected version of the input code snippet (if you don't know, SOLUTION PART 2 should say None). SOLUTION PART 2 must contain only python code - there must not be any English explanation outside of code comments or docstrings. Be concise and use simple language because I am a beginning programmer.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "CURRENT CODE SNIPPET:\n",
    "{code}\n",
    "\n",
    "LOCAL VARIABLES:\n",
    "{local_vars}\n",
    "\n",
    "GLOBAL VARIABLES:\n",
    "{global_vars}\"\"\"\n",
    "user_prompt_template = HumanMessagePromptTemplate.from_template(\n",
    "    user_prompt_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:29.812462Z",
     "start_time": "2023-03-25T06:53:29.778952Z"
    }
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'question': 'Why will this throw an index error soon?',\n",
    "    'code': \"\"\"def bubble_sort(nums):\n",
    "    for i in range(len(nums)):\n",
    "        for j in range(len(nums)):\n",
    "            if nums[j] > nums[j + 1]:\n",
    "                nums[j + 1], nums[j] = nums[j], nums[j + 1]\n",
    "    return nums\"\"\",\n",
    "    'local_vars': \"\"\"{\n",
    "    'nums': [3, 4, 2, 1, 5, 9],   # type: list\n",
    "    'i': 0,   # type: int\n",
    "    'j': 4,   # type: int\n",
    "}\"\"\",\n",
    "    'global_vars': \"\"\"{\n",
    "}\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:30.186584Z",
     "start_time": "2023-03-25T06:53:30.155314Z"
    }
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    system_prompt,\n",
    "    user_prompt_template.format(**kwargs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:30.591338Z",
     "start_time": "2023-03-25T06:53:30.553451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an incredibly effective AI programming assistant. You have in-depth knowledge across a broad range of sub-fields within computer science, software development, and data science, and your goal is to help Python programmers resolve their most challenging bugs.\n",
      "\n",
      "This code snippet is not working as expected. Help me debug it. First read my question, then examine the snippet of code that is causing the issue and look at the values of the local and global variables. Your response must have exactly two parts. In the section titled SOLUTION PART 1, use plain English to explain what the problem is and how to fix it (if you don't know what the problem is, SOLUTION PART 1 should instead list a few possible causes or things I could try in order to identify the issue). In the section titled SOLUTION PART 2, write a corrected version of the input code snippet (if you don't know, SOLUTION PART 2 should say None). SOLUTION PART 2 must contain only python code - there must not be any English explanation outside of code comments or docstrings. Be concise and use simple language because I am a beginning programmer.\n",
      "\n",
      "QUESTION:\n",
      "Why will this throw an index error soon?\n",
      "\n",
      "CURRENT CODE SNIPPET:\n",
      "def bubble_sort(nums):\n",
      "    for i in range(len(nums)):\n",
      "        for j in range(len(nums)):\n",
      "            if nums[j] > nums[j + 1]:\n",
      "                nums[j + 1], nums[j] = nums[j], nums[j + 1]\n",
      "    return nums\n",
      "\n",
      "LOCAL VARIABLES:\n",
      "{\n",
      "    'nums': [3, 4, 2, 1, 5, 9],   # type: list\n",
      "    'i': 0,   # type: int\n",
      "    'j': 4,   # type: int\n",
      "}\n",
      "\n",
      "GLOBAL VARIABLES:\n",
      "{\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(m.content for m in messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:28:43.050948Z",
     "start_time": "2023-03-25T06:28:42.350904Z"
    }
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T04:06:34.986994Z",
     "start_time": "2023-03-22T04:06:34.949026Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOLUTION PART 1:\n",
      "The code will throw an index error soon because the inner loop is iterating up to the length of the list, which means that on the last iteration, `nums[j + 1]` will be out of range. To fix this, we need to change the range of the inner loop to `range(len(nums) - i - 1)`.\n",
      "\n",
      "SOLUTION PART 2:\n",
      "\n",
      "```\n",
      "def bubble_sort(nums):\n",
      "    for i in range(len(nums)):\n",
      "        for j in range(len(nums) - i - 1):\n",
      "            if nums[j] > nums[j + 1]:\n",
      "                nums[j + 1], nums[j] = nums[j], nums[j + 1]\n",
      "    return nums\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "res = chat(messages)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T04:11:21.695628Z",
     "start_time": "2023-03-22T04:11:21.649258Z"
    }
   },
   "outputs": [],
   "source": [
    "messages.append(res)\n",
    "messages.append(\n",
    "    user_prompt_template.format(\n",
    "        **{**kwargs, \n",
    "           'question': 'Can you revise your solution so you only find the length of nums once?'}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-22T04:11:55.671084Z",
     "start_time": "2023-03-22T04:11:49.538517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOLUTION PART 1:\n",
      "The problem with the current code is that it is calling `len(nums)` twice in the inner loop, which is inefficient. To fix this, we can store the length of `nums` in a variable before the loop and use that variable instead.\n",
      "\n",
      "SOLUTION PART 2:\n",
      "\n",
      "```\n",
      "def bubble_sort(nums):\n",
      "    n = len(nums)\n",
      "    for i in range(n):\n",
      "        for j in range(n - i - 1):\n",
      "            if nums[j] > nums[j + 1]:\n",
      "                nums[j + 1], nums[j] = nums[j], nums[j + 1]\n",
      "    return nums\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "res = chat(messages)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took first stab at storing this info in a file (py for now). Try loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:38.166047Z",
     "start_time": "2023-03-25T06:53:38.077507Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "from langchain.schema import AIMessage\n",
    "from roboduck.prompts.chat import debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T07:00:09.588314Z",
     "start_time": "2023-03-25T07:00:09.461824Z"
    }
   },
   "outputs": [],
   "source": [
    "ChatOpenAI.__call__??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:53:39.363775Z",
     "start_time": "2023-03-25T06:53:39.333223Z"
    }
   },
   "outputs": [],
   "source": [
    "class DummyChatModel:\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def __call__(self, messages, stop=None):\n",
    "        return AIMessage(content=messages[-1].content.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:56:05.056343Z",
     "start_time": "2023-03-25T06:56:05.003401Z"
    }
   },
   "outputs": [],
   "source": [
    "class Chat:\n",
    "    \n",
    "    # Completion kwarg names that langchain requires you to pass in separately\n",
    "    # from other model_kwargs when creating ChatOpenAI object (or similar).\n",
    "    # Don't include kwargs like 'streaming' or 'n' here,\n",
    "    # which shouldn't really be specified at the config level in most cases.\n",
    "    # Not sure how consistent this interface will be for non-openai models but\n",
    "    # I guess I'm putting my faith in langchain so might as well embrace it.\n",
    "    _non_model_kwargs = {'max_tokens'}\n",
    "    \n",
    "    def __init__(self, system_text, user_text, model_name='gpt-3.5-turbo',\n",
    "                 model_kwargs=None, chat_kwargs=None, chat_class=ChatOpenAI,\n",
    "                 history=()):\n",
    "        # chat_kwargs are those we unpack in our chat_class instantiation.\n",
    "        # model_kwargs are the model_kwargs arg we pass to that instantiation,\n",
    "        # not unpacked. E.g. chat_kwargs contains things like \n",
    "        # `callback_manager` or `verbose`, model_kwargs contains things like\n",
    "        # `temperature` or `top_p`.\n",
    "        self.model_kwargs, self.chat_kwargs = self._separate_chat_kwargs(\n",
    "            model_kwargs, chat_kwargs\n",
    "        )\n",
    "        self.chat = chat_class(**self.chat_kwargs, \n",
    "                               model_kwargs=self.model_kwargs)\n",
    "        self.system_message = SystemMessage(content=system_text)\n",
    "        if isinstance(user_text, str):\n",
    "            user_text = {'reply': user_text}\n",
    "        self.user_templates = {\n",
    "            k: HumanMessagePromptTemplate.from_template(v)\n",
    "            for k, v in user_text.items()\n",
    "        }\n",
    "        self.default_user_key = next(iter(self.user_templates))\n",
    "        self._history = list(history) or [self.system_message]\n",
    "        \n",
    "    @classmethod\n",
    "    def load_template(cls, prompt_name, **extra_kwargs):\n",
    "        # TODO: maybe let user modify defaults and/or pass in other init \n",
    "        # kwargs like verbose=False, ideally without copying signature\n",
    "        # defaults from init manual (hard to maintain).\n",
    "        # TODO: maybe just import prompts.chat upfront.\n",
    "        module = importlib.import_module(\n",
    "            f'roboduck.prompts.chat.{prompt_name}'\n",
    "        )\n",
    "        kwargs = {\n",
    "            'system_text': module.system, \n",
    "            'user_text': module.user, \n",
    "            'model_name': module.model_name, \n",
    "            'model_kwargs': module.kwargs,\n",
    "        }\n",
    "        kwargs.update(extra_kwargs)\n",
    "        return cls(**kwargs)\n",
    "    \n",
    "    def _separate_chat_kwargs(self, model_kwargs=None, chat_kwargs=None):\n",
    "        chat_kwargs = dict(chat_kwargs or {})\n",
    "        model_kwargs = dict(model_kwargs or {})\n",
    "        keys_to_move = set(model_kwargs) & self._non_model_kwargs\n",
    "        for key in keys_to_move:\n",
    "            chat_kwargs[key] = model_kwargs.pop(key)\n",
    "        return model_kwargs, chat_kwargs\n",
    "        \n",
    "    def _user_message(self, *, key='', **kwargs):\n",
    "        key = key or self.default_user_key\n",
    "        template = self.user_templates[key]\n",
    "        return template.format(**kwargs)\n",
    "    \n",
    "    def reply(self, *, key='', **kwargs):\n",
    "        user_message = self._user_message(key=key, **kwargs)\n",
    "        self._history.append(user_message)\n",
    "        try:\n",
    "            response = self.chat(self._history)\n",
    "        except Exception as e:\n",
    "            self._history.pop(-1)\n",
    "            raise e\n",
    "        self._history.append(response)\n",
    "        return response\n",
    "    \n",
    "    def history(self, sep='\\n\\n', speaker_prefix=True):\n",
    "        \"\"\"Return chat history as a single string.\"\"\"\n",
    "        res = []\n",
    "        for row in self._history:\n",
    "            reply = row.content\n",
    "            if speaker_prefix:\n",
    "                speaker = type(row).__name__.split('Message')[0]\n",
    "                reply = f'{speaker}: {reply}'\n",
    "            res.append(reply)\n",
    "        return sep.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:56:06.734153Z",
     "start_time": "2023-03-25T06:56:06.700897Z"
    }
   },
   "outputs": [],
   "source": [
    "chat = Chat.load_template('debug', chat_class=DummyChatModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:56:06.943806Z",
     "start_time": "2023-03-25T06:56:06.902294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DummyChatModel at 0x7fed6d3c3580>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:56:07.276816Z",
     "start_time": "2023-03-25T06:56:07.242388Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = chat._user_message(\n",
    "    code='a = 3\\nb = 4', question='Why?', local_vars='{3: 4}',\n",
    "    global_vars='{True: False}', next_line='b = 4'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:56:07.912577Z",
     "start_time": "2023-03-25T06:56:07.881220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code snippet is not working as expected. Help me debug it. First read my question, then examine the snippet of code that is causing the issue and look at the values of the local and global variables. Your response must have exactly two parts. In the section titled SOLUTION PART 1, use plain English to explain what the problem is and how to fix it (if you don't know what the problem is, SOLUTION PART 1 should instead list a few possible causes or things I could try in order to identify the issue). In the section titled SOLUTION PART 2, write a corrected version of the input code snippet (if you don't know, SOLUTION PART 2 should say None). SOLUTION PART 2 must contain only python code - there must not be any English explanation outside of code comments or docstrings. Be concise and use simple language because I am a beginning programmer.\n",
      "\n",
      "QUESTION:\n",
      "Why?\n",
      "\n",
      "CURRENT CODE SNIPPET:\n",
      "a = 3\n",
      "b = 4\n",
      "\n",
      "NEXT LINE:\n",
      "b = 4\n",
      "\n",
      "LOCAL VARIABLES:\n",
      "{3: 4}\n",
      "\n",
      "GLOBAL VARIABLES:\n",
      "{True: False}\n"
     ]
    }
   ],
   "source": [
    "print(tmp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:56:08.219954Z",
     "start_time": "2023-03-25T06:56:08.189072Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = chat._user_message(\n",
    "    key='contextless',\n",
    "    question='Why?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:56:08.659776Z",
     "start_time": "2023-03-25T06:56:08.605478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      "Why?\n"
     ]
    }
   ],
   "source": [
    "print(tmp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:56:09.678631Z",
     "start_time": "2023-03-25T06:56:09.636156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DummyChatModel at 0x7fed6d3c3580>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:56:10.086149Z",
     "start_time": "2023-03-25T06:56:10.049509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='QUESTION:\\nHOW ARE YOU?', additional_kwargs={})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(key='contextless', question='How are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:56:11.501904Z",
     "start_time": "2023-03-25T06:56:11.463211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an incredibly effective AI programming assistant. You have in-depth knowledge across a broad range of sub-fields within computer science, software development, and data science, and your goal is to help Python programmers resolve their most challenging bugs.\n",
      "\n",
      "Human: QUESTION:\n",
      "How are you?\n",
      "\n",
      "AI: QUESTION:\n",
      "HOW ARE YOU?\n"
     ]
    }
   ],
   "source": [
    "print(chat.history())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:57:35.482438Z",
     "start_time": "2023-03-25T06:57:35.426085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an incredibly effective AI programming assistant. You have in-depth knowledge across a broad range of sub-fields within computer science, software development, and data science, and your goal is to help Python programmers resolve their most challenging bugs.\n",
      "\n",
      "QUESTION:\n",
      "How are you?\n",
      "\n",
      "QUESTION:\n",
      "HOW ARE YOU?\n"
     ]
    }
   ],
   "source": [
    "# This would make more sense if our messages included speakers, i.e. if a\n",
    "# user_message looked like 'Me: {reply}' and gpt was prompted to reply like\n",
    "# 'Robert Sapolsky: {reply}' (for example).\n",
    "print(chat.history(speaker_prefix=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error when using real ChatOpenAI obj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:54:05.425907Z",
     "start_time": "2023-03-25T06:54:05.390695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x7fed643756d0>, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', model_kwargs={'temperature': 0.0, 'top_p': 0.99, 'frequency_penalty': 0.2, 'presence_penalty': 0.0, 'logit_bias': {37811: -100, 27901: -50}, 'stop': ['QUESTION', 'SOLUTION PART 1', 'SOLUTION PART 2']}, openai_api_key=None, request_timeout=60, max_retries=6, streaming=False, n=1, max_tokens=512)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = Chat.load_template('debug')\n",
    "chat.chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:54:11.564709Z",
     "start_time": "2023-03-25T06:54:08.716102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI language model, I don't have feelings, but I'm functioning properly and ready to assist you with any programming-related questions you may have. How can I help you today?\", additional_kwargs={})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.reply(key='contextless', question='How are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T06:54:36.688799Z",
     "start_time": "2023-03-25T06:54:36.602569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an incredibly effective AI programming assistant. You have in-depth knowledge across a broad range of sub-fields within computer science, software development, and data science, and your goal is to help Python programmers resolve their most challenging bugs.\n",
      "\n",
      "Human: QUESTION:\n",
      "How are you?\n",
      "\n",
      "AI: As an AI language model, I don't have feelings, but I'm functioning properly and ready to assist you with any programming-related questions you may have. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "print(chat.history())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Debug scratch\n",
    "\n",
    "See if we can use frames to identify whether we need to provide context for a user message (i.e. if frame has changed since we last did)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T02:35:33.486423Z",
     "start_time": "2023-03-23T02:35:33.415676Z"
    }
   },
   "outputs": [],
   "source": [
    "from roboduck.debugger import duck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T04:02:00.648795Z",
     "start_time": "2023-03-23T04:01:59.817553Z"
    }
   },
   "outputs": [],
   "source": [
    "def binary_search(x, nums):\n",
    "    if not nums:\n",
    "        return -1\n",
    "    duck(backend='repeat')\n",
    "    mid = len(nums) // 2\n",
    "    if x == nums[mid]:\n",
    "        return x\n",
    "    if x > nums[mid]:\n",
    "        return binary_search(x, nums[mid + 1:])\n",
    "    if x < nums[mid]:\n",
    "        return binary_search(x, nums[:mid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T04:02:00.686427Z",
     "start_time": "2023-03-23T04:02:00.651642Z"
    }
   },
   "outputs": [],
   "source": [
    "nums = [33, 44, 55, 66, 77, 88, 99, 111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T04:02:44.774242Z",
     "start_time": "2023-03-23T04:02:00.695613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-70-8a37149461d4>(5)binary_search()\n",
      "-> mid = len(nums) // 2\n",
      ">>> l .\n",
      "  1  \tdef binary_search(x, nums):\n",
      "  2  \t    if not nums:\n",
      "  3  \t        return -1\n",
      "  4  \t    duck(backend='repeat')\n",
      "  5  ->\t    mid = len(nums) // 2\n",
      "  6  \t    if x == nums[mid]:\n",
      "  7  \t        return x\n",
      "  8  \t    if x > nums[mid]:\n",
      "  9  \t        return binary_search(x, nums[mid + 1:])\n",
      " 10  \t    if x < nums[mid]:\n",
      " 11  \t        return binary_search(x, nums[:mid])\n",
      ">>> y?\n",
      "next line:     mid = len(nums) // 2\n",
      "\u001b[32m[Duck] \u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m>>> n\n",
      "> <ipython-input-70-8a37149461d4>(6)binary_search()\n",
      "-> if x == nums[mid]:\n",
      ">>> n\n",
      "> <ipython-input-70-8a37149461d4>(8)binary_search()\n",
      "-> if x > nums[mid]:\n",
      ">>> n\n",
      "> <ipython-input-70-8a37149461d4>(10)binary_search()\n",
      "-> if x < nums[mid]:\n",
      ">>> n\n",
      "> <ipython-input-70-8a37149461d4>(11)binary_search()\n",
      "-> return binary_search(x, nums[:mid])\n",
      ">>> l .\n",
      "  6  \t    if x == nums[mid]:\n",
      "  7  \t        return x\n",
      "  8  \t    if x > nums[mid]:\n",
      "  9  \t        return binary_search(x, nums[mid + 1:])\n",
      " 10  \t    if x < nums[mid]:\n",
      " 11  ->\t        return binary_search(x, nums[:mid])\n",
      "[EOF]\n",
      ">>> [dev] What wrong?\n",
      "next line:         return binary_search(x, nums[:mid])\n",
      "\u001b[31m\"\"\"ANSWER KEY\n",
      "\n",
      "This code snippet is not working as expected. Help me debug it. First read my question, then examine the snippet of code that is causing the issue and look at the values of the local and global variables. In the section titled SOLUTION PART 1, use plain English to explain what the problem is and how to fix it. In the section titled SOLUTION PART 2, write a corrected version of the input code snippet. If you don't know what the problem is, SOLUTION PART 1 should list a few possible causes or things I could try in order to identify the issue and SOLUTION PART 2 should say N/A. Be concise and use simple language because I am a beginning programmer.\n",
      "\n",
      "QUESTION:\n",
      "[dev] What wrong?\n",
      "\n",
      "CURRENT CODE SNIPPET:\n",
      "def binary_search(x, nums):\n",
      "    if not nums:\n",
      "        return -1\n",
      "    mid = len(nums) // 2\n",
      "    if x == nums[mid]:\n",
      "        return x\n",
      "    if x > nums[mid]:\n",
      "        return binary_search(x, nums[mid + 1:])\n",
      "    if x < nums[mid]:\n",
      "        return binary_search(x, nums[:mid])\n",
      "\n",
      "LOCAL VARIABLES:\n",
      "{\n",
      "    'x': 3,   # type: int\n",
      "    'nums': [33, 44, 55, 66, 77, 88, 99, 111],   # type: list\n",
      "    'mid': 4,   # type: int\n",
      "}\n",
      "\n",
      "GLOBAL VARIABLES:\n",
      "{\n",
      "}\n",
      "\n",
      "SOLUTION PART 1:\u001b[0m\n",
      "\u001b[32m[Duck] \u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m>>> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-1d506c8d773a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbinary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-8a37149461d4>\u001b[0m in \u001b[0;36mbinary_search\u001b[0;34m(x, nums)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmid\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-8a37149461d4>\u001b[0m in \u001b[0;36mbinary_search\u001b[0;34m(x, nums)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmid\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "binary_search(3, nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T02:39:22.174903Z",
     "start_time": "2023-03-23T02:39:22.130813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_search(33, nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T02:39:26.415594Z",
     "start_time": "2023-03-23T02:39:26.371426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_search(39, nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T02:39:40.877084Z",
     "start_time": "2023-03-23T02:39:40.824221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_search(111, nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T02:39:44.851555Z",
     "start_time": "2023-03-23T02:39:44.810780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_search(112, nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-23T04:06:26.680330Z",
     "start_time": "2023-03-23T04:06:25.828803Z"
    }
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    for i in range(5):\n",
    "        print(i)\n",
    "        duck(backend='repeat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-24T02:44:35.865038Z",
     "start_time": "2023-03-23T04:06:29.000714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "> <ipython-input-73-943befe6b744>(2)test()\n",
      "-> for i in range(5):\n",
      ">>> i\n",
      "0\n",
      ">>> l .\n",
      "  1  \tdef test():\n",
      "  2  ->\t    for i in range(5):\n",
      "  3  \t        print(i)\n",
      "  4  \t        duck(backend='repeat')\n",
      "[EOF]\n",
      ">>> y?\n",
      "frmae_id 140192236901280\n",
      "next line:     for i in range(5):\n",
      "\u001b[32m[Duck] \u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m>>> n\n",
      "> <ipython-input-73-943befe6b744>(3)test()\n",
      "-> print(i)\n",
      ">>> i\n",
      "1\n",
      ">>> y?\n",
      "frmae_id 140192236901280\n",
      "next line:         print(i)\n",
      "\u001b[32m[Duck] \u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m>>> n\n",
      "1\n",
      "> <ipython-input-73-943befe6b744>(4)test()\n",
      "-> duck(backend='repeat')\n",
      ">>> i\n",
      "1\n",
      ">>> n\n",
      "> <ipython-input-73-943befe6b744>(2)test()\n",
      "-> for i in range(5):\n",
      ">>> i\n",
      "1\n",
      ">>> l .\n",
      "  1  \tdef test():\n",
      "  2  ->\t    for i in range(5):\n",
      "  3  \t        print(i)\n",
      "  4  \t        duck(backend='repeat')\n",
      "[EOF]\n",
      ">>> i\n",
      "1\n",
      ">>> y?\n",
      "frmae_id 140192236901280\n",
      "next line:     for i in range(5):\n",
      "\u001b[32m[Duck] \u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m>>> n\n",
      "> <ipython-input-73-943befe6b744>(3)test()\n",
      "-> print(i)\n",
      ">>> l .\n",
      "  1  \tdef test():\n",
      "  2  \t    for i in range(5):\n",
      "  3  ->\t        print(i)\n",
      "  4  \t        duck(backend='repeat')\n",
      "[EOF]\n",
      ">>> y?\n",
      "frmae_id 140192236901280\n",
      "next line:         print(i)\n",
      "\u001b[32m[Duck] \u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m>>> i\n",
      "2\n",
      ">>> n\n",
      "2\n",
      "> <ipython-input-73-943befe6b744>(4)test()\n",
      "-> duck(backend='repeat')\n",
      ">>> n\n",
      "> <ipython-input-73-943befe6b744>(2)test()\n",
      "-> for i in range(5):\n",
      ">>> n\n",
      "> <ipython-input-73-943befe6b744>(3)test()\n",
      "-> print(i)\n",
      ">>> i\n",
      "3\n",
      ">>> n\n",
      "3\n",
      "> <ipython-input-73-943befe6b744>(4)test()\n",
      "-> duck(backend='repeat')\n",
      ">>> n\n",
      "> <ipython-input-73-943befe6b744>(2)test()\n",
      "-> for i in range(5):\n",
      ">>> i\n",
      "3\n",
      ">>> n\n",
      "> <ipython-input-73-943befe6b744>(3)test()\n",
      "-> print(i)\n",
      ">>> i\n",
      "4\n",
      ">>> y?\n",
      "frmae_id 140192236901280\n",
      "next line:         print(i)\n",
      "\u001b[32m[Duck] \u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m\"\u001b[0m>>> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-fbd55f77ab7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-943befe6b744>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mduck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'repeat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-943befe6b744>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mduck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'repeat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
